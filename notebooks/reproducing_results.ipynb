{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A two-stage cyber attack detection and classification system for smart grids\n",
    "https://www.sciencedirect.com/science/article/pii/S2542660523002494#b47"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology\n",
    "- Read all DNP3 parsed data. i.e. unbalanced\n",
    "- Make two copies i.e. one for attack detection (attack vs bengin) another for attack classification (only contains attack data)\n",
    "- For each copies, perform random oversampling to handle class imbalance.\n",
    "- Perform Recursive Feature Elimination (RFE) to get 13 features from 96. Use Random Forest Classifier to do so.\n",
    "- Train RF, LR, DT, GNB, XGB for both steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data\n",
    "- First copy all CSV files into a local folder to make it easier to run.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from loguru import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-18 17:46:24.021\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mData root: E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:24.029\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m25\u001b[0m - \u001b[1mFound 71 files in E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:24.030\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200508_DNP3_Disable_Unsolicited_Messages_Attack_UOWM_DNP3_Dataset_Slave_05.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:24.089\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200514_Disable_Unsolicited_Messages_Attack_UOWM_DNP3_Dataset_Attacker_01.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:24.139\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200514_Disable_Unsolicited_Messages_Attack_UOWM_DNP3_Dataset_Attacker_02.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:24.193\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200514_Disable_Unsolicited_Messages_Attack_UOWM_DNP3_Dataset_Attacker_03.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:24.272\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200514_Disable_Unsolicited_Messages_Attack_UOWM_DNP3_Dataset_Master.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:24.330\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200514_Disable_Unsolicited_Messages_Attack_UOWM_DNP3_Dataset_Slave_01.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:24.383\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200514_Disable_Unsolicited_Messages_Attack_UOWM_DNP3_Dataset_Slave_02.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:24.419\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200514_Disable_Unsolicited_Messages_Attack_UOWM_DNP3_Dataset_Slave_03.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:24.452\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200514_Disable_Unsolicited_Messages_Attack_UOWM_DNP3_Dataset_Slave_06.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:24.489\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200514_DNP3_Disable_Unsolicited_Messages_Attack_UOWM_DNP3_Dataset_Slave_04.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:24.524\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200514_DNP3_Disable_Unsolicited_Messages_Attack_UOWM_DNP3_Dataset_Slave_07.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:24.557\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200514_DNP3_Disable_Unsolicited_Messages_Attack_UOWM_DNP3_Dataset_Slave_08.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:24.612\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200515_Cold_Restart_Attack_UOWM_DNP3_Dataset_Slave_01.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:24.645\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200515_Cold_Restart_Attack_UOWM_DNP3_Dataset_Slave_02.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:24.680\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200515_Cold_Restart_Attack_UOWM_DNP3_Dataset_Slave_03.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:24.733\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200515_DNP3_Cold_Restart_Attack_UOWM_DNP3_Dataset_Attacker_01.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:24.796\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200515_DNP3_Cold_Restart_Attack_UOWM_DNP3_Dataset_Attacker_02.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:24.845\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200515_DNP3_Cold_Restart_Attack_UOWM_DNP3_Dataset_Attacker_03.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:24.918\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200515_DNP3_Cold_Restart_Attack_UOWM_DNP3_Dataset_Master.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:24.966\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200515_DNP3_Cold_Restart_Attack_UOWM_DNP3_Dataset_Slave_04.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:24.998\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200515_DNP3_Cold_Restart_Attack_UOWM_DNP3_Dataset_Slave_05.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:25.031\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200515_DNP3_Cold_Restart_Attack_UOWM_DNP3_Dataset_Slave_06.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:25.064\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200515_DNP3_Cold_Restart_Attack_UOWM_DNP3_Dataset_Slave_07.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:25.111\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200515_DNP3_Cold_Restart_Attack_UOWM_DNP3_Dataset_Slave_08.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:25.143\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200515_DNP3_Warm_Restart_Attack_UOWM_DNP3_Dataset_Attacker_01.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:25.201\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200515_DNP3_Warm_Restart_Attack_UOWM_DNP3_Dataset_Attacker_03.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:25.251\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200515_DNP3_Warm_Restart_Attack_UOWM_DNP3_Dataset_Master.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:25.302\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200515_DNP3_Warm_Restart_Attack_UOWM_DNP3_Dataset_Slave_01.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:25.351\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200515_DNP3_Warm_Restart_Attack_UOWM_DNP3_Dataset_Slave_02.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:25.383\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200515_DNP3_Warm_Restart_Attack_UOWM_DNP3_Dataset_Slave_03.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:25.415\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200515_DNP3_Warm_Restart_Attack_UOWM_DNP3_Dataset_Slave_04.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:25.453\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200515_DNP3_Warm_Restart_Attack_UOWM_DNP3_Dataset_Slave_05.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:25.495\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200515_DNP3_Warm_Restart_Attack_UOWM_DNP3_Dataset_Slave_06.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:25.540\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200515_DNP3_Warm_Restart_Attack_UOWM_DNP3_Dataset_Slave_07.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:25.571\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200515_DNP3_Warm_Restart_Attack_UOWM_DNP3_Dataset_Slave_08.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:25.604\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200515_Warm_Restart_Attack_UOWM_DNP3_Dataset_Attacker_02.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:25.652\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200516_DNP3_Enumerate_UOWM_DNP3_Dataset_Attacker_01.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:25.682\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200516_DNP3_Enumerate_UOWM_DNP3_Dataset_Attacker_02.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:25.717\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200516_DNP3_Enumerate_UOWM_DNP3_Dataset_Attacker_03.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:25.765\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200516_DNP3_Enumerate_UOWM_DNP3_Dataset_Master.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:25.845\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200516_DNP3_Enumerate_UOWM_DNP3_Dataset_Slave_01.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:25.889\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200516_DNP3_Enumerate_UOWM_DNP3_Dataset_Slave_02.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:25.938\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200516_DNP3_Enumerate_UOWM_DNP3_Dataset_Slave_03.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:25.998\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200516_DNP3_info_UOWM_DNP3_Dataset_Attacker_01.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:26.025\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200516_DNP3_info_UOWM_DNP3_Dataset_Attacker_02.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:26.055\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200516_DNP3_info_UOWM_DNP3_Dataset_Attacker_03.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:26.084\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200516_DNP3_info_UOWM_DNP3_Dataset_Master.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:26.158\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200516_DNP3_info_UOWM_DNP3_Dataset_Slave_01.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:26.223\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200516_DNP3_info_UOWM_DNP3_Dataset_Slave_02.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:26.289\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200516_DNP3_info_UOWM_DNP3_Dataset_Slave_03.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:26.346\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200518_Initialize_Data_Attack_UOWM_DNP3_Dataset_Attacker_01.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:26.388\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200518_Initialize_Data_Attack_UOWM_DNP3_Dataset_Attacker_02.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:26.414\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200518_Initialize_Data_Attack_UOWM_DNP3_Dataset_Attacker_03.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:26.486\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200518_Initialize_Data_Attack_UOWM_DNP3_Dataset_Master.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:26.513\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200518_Initialize_Data_Attack_UOWM_DNP3_Dataset_Slave_01.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:26.553\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200518_Initialize_Data_Attack_UOWM_DNP3_Dataset_Slave_02.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:26.589\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200518_Initialize_Data_Attack_UOWM_DNP3_Dataset_Slave_03.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:26.628\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200518_Replay_UOWM_DNP3_Dataset_Attacker_01.pcapDNP3_FLOWLABELEDLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:26.647\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200518_Replay_UOWM_DNP3_Dataset_Attacker_02.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:26.686\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200518_Replay_UOWM_DNP3_Dataset_Attacker_03.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:26.716\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200518_Replay_UOWM_DNP3_Dataset_Master.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:26.748\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200518_Replay_UOWM_DNP3_Dataset_Slave_01.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:26.775\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200518_Replay_UOWM_DNP3_Dataset_Slave_02.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:26.809\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200518_Replay_UOWM_DNP3_Dataset_Slave_03.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:26.838\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200519_Stop_Application_Attack_UOWM_DNP3_Dataset_Attacker_01.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:26.870\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200519_Stop_Application_Attack_UOWM_DNP3_Dataset_Attacker_02.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:26.892\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200519_Stop_Application_Attack_UOWM_DNP3_Dataset_Attacker_03.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:26.925\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200519_Stop_Application_Attack_UOWM_DNP3_Dataset_Master.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:26.953\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200519_Stop_Application_Attack_UOWM_DNP3_Dataset_Slave_01.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:26.977\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200519_Stop_Application_Attack_UOWM_DNP3_Dataset_Slave_02.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:27.000\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200519_Stop_Application_Attack_UOWM_DNP3_Dataset_Slave_03.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:27.079\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m28\u001b[0m - \u001b[1mCombined DataFrame shape: (40420, 103)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def load_csv_files(all_files: list[Path]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load all CSV files into a single DataFrame.\n",
    "    \"\"\"\n",
    "    if len(all_files) == 0:\n",
    "        logger.warning(\"No CSV files found.\")\n",
    "        return pd.DataFrame()\n",
    "    dataframes = []\n",
    "    for file in all_files:\n",
    "        logger.info(f\"Loading {file}\")\n",
    "\n",
    "        df = pd.read_csv(file, low_memory=False)\n",
    "        if \"Label\" in df.columns:\n",
    "            if \"No Label\" in df[\"Label\"].unique():\n",
    "                del df[\"Label\"]\n",
    "        df.columns = [c.strip() for c in df.columns]\n",
    "        dataframes.append(df)\n",
    "    combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "    return combined_df\n",
    "\n",
    "\n",
    "data_root = Path(r\"E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\")\n",
    "logger.info(f\"Data root: {data_root}\")\n",
    "all_files = list(data_root.glob(\"*.csv\"))\n",
    "logger.info(f\"Found {len(all_files)} files in {data_root}\")\n",
    "\n",
    "combined_df = load_csv_files(all_files)\n",
    "logger.info(f\"Combined DataFrame shape: {combined_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert `firstPacketDIR` to binary\n",
    "- 1 if Master 0 otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "firstPacketDIR\n",
       "MASTER        31878\n",
       "OUTSTATION     8542\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.firstPacketDIR.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "firstPacketDIR\n",
       "1    31878\n",
       "0     8542\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.firstPacketDIR = combined_df[\"firstPacketDIR\"].apply(\n",
    "    lambda x: 1 if x == \"MASTER\" else 0\n",
    ")\n",
    "combined_df.firstPacketDIR.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "protocol\n",
       "6    40420\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.protocol.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Unwanted Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_columns = [\n",
    "    \"File\",\n",
    "    \"flow ID\",\n",
    "    \"binary_label\",\n",
    "    \"Timestamp\",\n",
    "    \"source IP\",\n",
    "    \"destination IP\",\n",
    "    \"date\",\n",
    "    \"Unnamed: 0\",\n",
    "    \"Unnamed: 0.1\",\n",
    "]\n",
    "combined_df = combined_df[[c for c in combined_df.columns if c not in ignore_columns]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clone and oversample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-18 17:46:27.360\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m48\u001b[0m - \u001b[1mclf_df shape: (26040, 97)\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:27.362\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m49\u001b[0m - \u001b[1mdet_df shape: (40420, 97)\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:27.368\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36moversample_class\u001b[0m:\u001b[36m5\u001b[0m - \u001b[1mBefore oversampling: Label\n",
      "DISABLE_UNSOLICITED    5760\n",
      "COLD_RESTART           5760\n",
      "WARM_RESTART           5760\n",
      "DNP3_ENUMERATE         3380\n",
      "DNP3_INFO              3342\n",
      "INIT_DATA               692\n",
      "STOP_APP                680\n",
      "REPLAY                  666\n",
      "Name: count, dtype: int64\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:27.373\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36moversample_class\u001b[0m:\u001b[36m12\u001b[0m - \u001b[1mLabel DNP3_ENUMERATE needs 2380 samples\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:27.398\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36moversample_class\u001b[0m:\u001b[36m12\u001b[0m - \u001b[1mLabel DNP3_INFO needs 2418 samples\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:27.421\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36moversample_class\u001b[0m:\u001b[36m12\u001b[0m - \u001b[1mLabel INIT_DATA needs 5068 samples\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:27.438\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36moversample_class\u001b[0m:\u001b[36m12\u001b[0m - \u001b[1mLabel STOP_APP needs 5080 samples\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:27.464\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36moversample_class\u001b[0m:\u001b[36m12\u001b[0m - \u001b[1mLabel REPLAY needs 5094 samples\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:27.561\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36moversample_class\u001b[0m:\u001b[36m18\u001b[0m - \u001b[1mAfter oversampling: Label\n",
      "DNP3_INFO              5760\n",
      "REPLAY                 5760\n",
      "STOP_APP               5760\n",
      "DNP3_ENUMERATE         5760\n",
      "DISABLE_UNSOLICITED    5760\n",
      "INIT_DATA              5760\n",
      "WARM_RESTART           5760\n",
      "COLD_RESTART           5760\n",
      "Name: count, dtype: int64\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:27.567\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36moversample_class\u001b[0m:\u001b[36m5\u001b[0m - \u001b[1mBefore oversampling: Label\n",
      "MALICIOUS    26040\n",
      "NORMAL       14380\n",
      "Name: count, dtype: int64\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:27.570\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36moversample_class\u001b[0m:\u001b[36m12\u001b[0m - \u001b[1mLabel NORMAL needs 11660 samples\u001b[0m\n",
      "\u001b[32m2025-05-18 17:46:27.676\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36moversample_class\u001b[0m:\u001b[36m18\u001b[0m - \u001b[1mAfter oversampling: Label\n",
      "NORMAL       26040\n",
      "MALICIOUS    26040\n",
      "Name: count, dtype: int64\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def oversample_class(df: pd.DataFrame, label: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Oversample the specified class in the DataFrame.\n",
    "    \"\"\"\n",
    "    logger.info(f\"Before oversampling: {df[label].value_counts()}\")\n",
    "    label_counts = df[label].value_counts()\n",
    "    max_count = label_counts.max()\n",
    "    for lbl in label_counts.index:\n",
    "        count = label_counts[lbl]\n",
    "        if count < max_count:\n",
    "            needed = max_count - count\n",
    "            logger.info(f\"Label {lbl} needs {needed} samples\")\n",
    "            oversample_df = df[df[label] == lbl].sample(needed, replace=True)\n",
    "            df = pd.concat([df, oversample_df], ignore_index=True)\n",
    "\n",
    "    # Shuffle the DataFrame\n",
    "    df = df.sample(frac=1, random_state=42, replace=False).reset_index(drop=True)\n",
    "    logger.info(f\"After oversampling: {df[label].value_counts()}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def undersample_class(df: pd.DataFrame, label: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Undersample the specified class in the DataFrame.\n",
    "    \"\"\"\n",
    "    logger.info(f\"Before undersampling: {df[label].value_counts()}\")\n",
    "    label_counts = df[label].value_counts()\n",
    "    min_count = label_counts.min()\n",
    "    for lbl in label_counts.index:\n",
    "        count = label_counts[lbl]\n",
    "        if count > min_count:\n",
    "            needed = count - min_count\n",
    "            logger.info(f\"Label {lbl} needs to be reduced by {needed} samples\")\n",
    "            undersample_df = df[df[label] == lbl].sample(needed, replace=False)\n",
    "            df = df.drop(undersample_df.index)\n",
    "\n",
    "    # Shuffle the DataFrame\n",
    "    df = df.sample(frac=1, random_state=42, replace=False).reset_index(drop=True)\n",
    "    logger.info(f\"After undersampling: {df[label].value_counts()}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "clf_df = combined_df.query('Label!=\"NORMAL\"').copy()\n",
    "det_df = combined_df.copy()\n",
    "det_df[\"Label\"] = det_df[\"Label\"].apply(\n",
    "    lambda x: \"NORMAL\" if x == \"NORMAL\" else \"MALICIOUS\"\n",
    ")\n",
    "logger.info(f\"clf_df shape: {clf_df.shape}\")\n",
    "logger.info(f\"det_df shape: {det_df.shape}\")\n",
    "\n",
    "clf_df = oversample_class(clf_df, \"Label\")\n",
    "det_df = oversample_class(det_df, \"Label\")\n",
    "# det_df = undersample_class(det_df, \"Label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Label\n",
       " DNP3_INFO              5760\n",
       " REPLAY                 5760\n",
       " STOP_APP               5760\n",
       " DNP3_ENUMERATE         5760\n",
       " DISABLE_UNSOLICITED    5760\n",
       " INIT_DATA              5760\n",
       " WARM_RESTART           5760\n",
       " COLD_RESTART           5760\n",
       " Name: count, dtype: int64,\n",
       " Label\n",
       " NORMAL       26040\n",
       " MALICIOUS    26040\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_df.Label.value_counts(), det_df.Label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RFE on Detection Dataset\n",
    "- Authors mentioned that they used RF, LR, DT, GNB and XGB first on original data. \n",
    "- Then found RF got the best F1-Score. So they used RF for feature selection.\n",
    "- Nothing has been mentioned about the preprocessing of the data i.e. scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Label'>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "det_df.Label.value_counts().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from loguru import logger\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "\n",
    "class RFE:\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: ClassifierMixin,\n",
    "        train_features: pd.DataFrame,\n",
    "        train_labels: pd.Series,\n",
    "        test_features: pd.DataFrame,\n",
    "        test_labels: pd.Series,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the Recursive Feature Elimination (RFE) class with the given model and dataset.\n",
    "            A scikit-learn compatible classifier model to be used for feature elimination.\n",
    "            The training dataset features.\n",
    "            The training dataset labels.\n",
    "        test_features : pd.DataFrame\n",
    "            The testing dataset features.\n",
    "        test_labels : pd.Series\n",
    "            The testing dataset labels.\n",
    "        Attributes\n",
    "            The classifier model provided for feature elimination.\n",
    "        train_features : np.ndarray\n",
    "            Scaled training dataset features.\n",
    "            The training dataset labels.\n",
    "        test_features : np.ndarray\n",
    "            Scaled testing dataset features.\n",
    "        test_labels : pd.Series\n",
    "            The testing dataset labels.\n",
    "        result : list\n",
    "            A list to store the results of the feature elimination process.\n",
    "        curr_step : int\n",
    "            Tracks the current step in the feature elimination process.\n",
    "        feature_mask : np.ndarray or None\n",
    "            A mask indicating the selected features after elimination.\n",
    "        orig_feature_names : list\n",
    "            The original feature names from the training dataset.\n",
    "        scaler : MinMaxScaler\n",
    "            A MinMaxScaler instance used to scale the features.\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.train_features = train_features\n",
    "        self.train_labels = train_labels\n",
    "        self.test_features = test_features\n",
    "        self.test_labels = test_labels\n",
    "        self.curr_step = 0\n",
    "        self.feature_mask = None\n",
    "\n",
    "        self.orig_feature_names = train_features.columns.tolist()\n",
    "\n",
    "        # self.scaler = MinMaxScaler()\n",
    "        # self.scaler.fit(self.train_features)\n",
    "        # self.train_features = self.scaler.transform(self.train_features)\n",
    "        # self.test_features = self.scaler.transform(self.test_features)\n",
    "        self._result = []\n",
    "\n",
    "    @property\n",
    "    def result(self):\n",
    "        \"\"\"\n",
    "        Returns the result of the feature elimination process.\n",
    "        \"\"\"\n",
    "        cols = [\n",
    "            \"Step\",\n",
    "            \"Removed Feature\",\n",
    "            \"Max Feature\",\n",
    "            \"Min Feature\",\n",
    "            \"Max Importance\",\n",
    "            \"Min Importance\",\n",
    "            \"Score\",\n",
    "            \"Num Features\",\n",
    "        ]\n",
    "        if len(self._result) == 0:\n",
    "            logger.warning(\"No results available. Please run the fit method first.\")\n",
    "            return pd.DataFrame(columns=cols)\n",
    "        df = pd.DataFrame(self._result, columns=cols)\n",
    "        return df\n",
    "\n",
    "    def fit(self, feature_names: list | None = None):\n",
    "        if feature_names is None:\n",
    "            feature_names = self.orig_feature_names\n",
    "        # init feat mask\n",
    "        feature_mask = np.array([f in feature_names for f in self.orig_feature_names])\n",
    "\n",
    "        if isinstance(self.train_features, pd.DataFrame):\n",
    "            self.train_features = self.train_features.to_numpy()\n",
    "        if isinstance(self.test_features, pd.DataFrame):\n",
    "            self.test_features = self.test_features.to_numpy()\n",
    "\n",
    "        x_train_sel = self.train_features[:, feature_mask]\n",
    "        x_test_sel = self.test_features[:, feature_mask]\n",
    "        current_indices = np.flatnonzero(feature_mask)\n",
    "        current_feature_names = [self.orig_feature_names[i] for i in current_indices]\n",
    "        logger.info(f\"Step: {self.curr_step}, Feature Shape: {x_train_sel.shape}\")\n",
    "        model = clone(self.model)\n",
    "        t0 = time.perf_counter()\n",
    "        model.fit(x_train_sel, self.train_labels)\n",
    "        # test_results = permutation_importance(\n",
    "        #     model,\n",
    "        #     x_test_sel,\n",
    "        #     self.test_labels,\n",
    "        #     n_repeats=10,\n",
    "        #     random_state=42,\n",
    "        #     n_jobs=-1,\n",
    "        #     scoring=\"f1\",\n",
    "        # )\n",
    "\n",
    "        # Evaluate on F1 score\n",
    "        score = f1_score(self.test_labels, model.predict(x_test_sel), average=\"binary\")\n",
    "        # score = model.score(x_test_sel, self.test_labels)\n",
    "        logger.info(\n",
    "            f\"Training time: {time.perf_counter() - t0:.4f}s, Score: {score:.4f}\"\n",
    "        )\n",
    "        try:\n",
    "            importances = model.feature_importances_\n",
    "        except AttributeError:\n",
    "            importances = model.coef_.flatten()\n",
    "        # importances = test_results.importances_mean\n",
    "        max_i = importances.argmax()\n",
    "        min_i = importances.argmin()\n",
    "\n",
    "        if feature_mask.sum() == 1:\n",
    "            logger.info(\"Only one feature left, stopping\")\n",
    "            return self.result, self.current_feature_names\n",
    "        # Eliminate least important feature\n",
    "        remove_global_idx = current_indices[min_i]\n",
    "        removed_feature_name = self.orig_feature_names[remove_global_idx]\n",
    "        feature_mask[remove_global_idx] = False\n",
    "        logger.info(\n",
    "            f\"Sum Imp. {sum(importances)} Max importance ({max_i}): {importances[max_i]:.4f} ({current_feature_names[max_i]}), Min importance ({min_i}): {importances[min_i]:.4f} ({current_feature_names[min_i]}), Removed feature: {removed_feature_name}\"\n",
    "        )\n",
    "        self._result.append(\n",
    "            [\n",
    "                self.curr_step,\n",
    "                removed_feature_name,\n",
    "                current_feature_names[max_i],\n",
    "                current_feature_names[min_i],\n",
    "                importances[max_i],\n",
    "                importances[min_i],\n",
    "                score,\n",
    "                x_test_sel.shape[1],\n",
    "            ]\n",
    "        )\n",
    "        self.curr_step += 1\n",
    "        self.current_feature_names = [\n",
    "            self.orig_feature_names[i] for i in np.flatnonzero(feature_mask)\n",
    "        ]\n",
    "        self.feature_mask = feature_mask\n",
    "        return self.result, self.current_feature_names\n",
    "\n",
    "    def project(self, data: pd.DataFrame):\n",
    "\n",
    "        data = data[:, self.feature_mask]\n",
    "\n",
    "        return data\n",
    "\n",
    "    def plot_results(self, fig_size: tuple = (10, 6)):\n",
    "        \"\"\"\n",
    "        Plot the results of the RFE process.\n",
    "        Parameters\n",
    "        ----------\n",
    "        fig_size : tuple\n",
    "            The size of the figure to be plotted.\n",
    "        \"\"\"\n",
    "        import matplotlib.pyplot as plt\n",
    "        import seaborn as sns\n",
    "\n",
    "        df = self.result\n",
    "        # Sort normally\n",
    "        df = df.sort_values(\n",
    "            \"Num Features\", ascending=True\n",
    "        )  # ascending=True so larger numbers are on the left\n",
    "        max_score = df[\"Score\"].max()\n",
    "        max_score_idx = df[\"Score\"].idxmax()\n",
    "\n",
    "        # Plot with numeric x-axis\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.lineplot(data=df, x=\"Num Features\", y=\"Score\")\n",
    "        # Highlight the maximum score point\n",
    "        plt.scatter(\n",
    "            df.loc[max_score_idx, \"Num Features\"],\n",
    "            max_score,\n",
    "            color=\"red\",\n",
    "            label=f\"Max Score: {max_score:.4f}\",\n",
    "        )\n",
    "        # annotate the max score point little below\n",
    "        ann_txt = (df.loc[max_score_idx, \"Num Features\"] - 1, max_score - 0.001)\n",
    "        plt.annotate(\n",
    "            f\"F1: {max_score:.4f}\\nFeatures: {df.loc[max_score_idx, 'Num Features']}\",\n",
    "            xy=(df.loc[max_score_idx, \"Num Features\"], max_score),\n",
    "            xytext=(df.loc[max_score_idx, \"Num Features\"] - 1.5, max_score - 0.002),\n",
    "            arrowprops=dict(arrowstyle=\"->\", color=\"gray\"),\n",
    "            fontsize=10,\n",
    "            bbox=dict(\n",
    "                boxstyle=\"round,pad=0.3\", edgecolor=\"gray\", facecolor=\"white\", alpha=0.8\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        # Reverse the x-axis\n",
    "        plt.gca().invert_xaxis()\n",
    "\n",
    "        plt.title(\n",
    "            f\"F1 Score vs Number of Features for ({self.model.__class__.__name__})\"\n",
    "        )\n",
    "        plt.xlabel(\"Number of Features (Descending Order)\")\n",
    "        plt.ylabel(\"F1 Score\")\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-18 18:21:56.610\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 0, Feature Shape: (39060, 96)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:21:57.453\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.8420s, Score: 0.9975\u001b[0m\n",
      "\u001b[32m2025-05-18 18:21:57.454\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999999999998 Max importance (50): 0.6247 (bwdIAT_MEAN), Min importance (2): 0.0000 (protocol), Removed feature: protocol\u001b[0m\n",
      "\u001b[32m2025-05-18 18:21:57.468\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 1, Feature Shape: (39060, 95)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:21:58.308\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.8384s, Score: 0.9972\u001b[0m\n",
      "\u001b[32m2025-05-18 18:21:58.309\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000000000002 Max importance (49): 0.6248 (bwdIAT_MEAN), Min importance (0): 0.0000 (source port), Removed feature: source port\u001b[0m\n",
      "\u001b[32m2025-05-18 18:21:58.322\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 2, Feature Shape: (39060, 94)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:21:59.110\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.7866s, Score: 0.9977\u001b[0m\n",
      "\u001b[32m2025-05-18 18:21:59.111\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000000000002 Max importance (48): 0.6246 (bwdIAT_MEAN), Min importance (3): 0.0000 (TotalBwdPkts), Removed feature: TotalBwdPkts\u001b[0m\n",
      "\u001b[32m2025-05-18 18:21:59.124\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 3, Feature Shape: (39060, 93)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:21:59.898\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.7730s, Score: 0.9976\u001b[0m\n",
      "\u001b[32m2025-05-18 18:21:59.899\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999999999999 Max importance (47): 0.6248 (bwdIAT_MEAN), Min importance (3): 0.0000 (TotLenfwdDL), Removed feature: TotLenfwdDL\u001b[0m\n",
      "\u001b[32m2025-05-18 18:21:59.912\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 4, Feature Shape: (39060, 92)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:00.695\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.7819s, Score: 0.9972\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:00.696\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000000000002 Max importance (46): 0.6249 (bwdIAT_MEAN), Min importance (2): 0.0000 (TotalFwdPkts), Removed feature: TotalFwdPkts\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:00.711\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 5, Feature Shape: (39060, 91)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:01.500\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.7884s, Score: 0.9969\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:01.501\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999999999998 Max importance (45): 0.6246 (bwdIAT_MEAN), Min importance (2): 0.0000 (TotLenfwdTR), Removed feature: TotLenfwdTR\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:01.518\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 6, Feature Shape: (39060, 90)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:02.270\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.7505s, Score: 0.9975\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:02.271\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999999999999 Max importance (44): 0.6265 (bwdIAT_MEAN), Min importance (4): 0.0000 (TotLenbwdTR), Removed feature: TotLenbwdTR\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:02.285\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 7, Feature Shape: (39060, 89)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:03.046\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.7609s, Score: 0.9971\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:03.048\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000000000002 Max importance (43): 0.6264 (bwdIAT_MEAN), Min importance (5): 0.0000 (DLfwdPktLenMAX), Removed feature: DLfwdPktLenMAX\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:03.060\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 8, Feature Shape: (39060, 88)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:03.814\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.7528s, Score: 0.9972\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:03.815\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0 Max importance (42): 0.6246 (bwdIAT_MEAN), Min importance (5): 0.0000 (DLfwdPktLenMIN), Removed feature: DLfwdPktLenMIN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:03.828\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 9, Feature Shape: (39060, 87)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:04.597\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.7678s, Score: 0.9969\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:04.599\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000000000002 Max importance (41): 0.6250 (bwdIAT_MEAN), Min importance (6): 0.0000 (DLfwdPktLenSTD), Removed feature: DLfwdPktLenSTD\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:04.613\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 10, Feature Shape: (39060, 86)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:05.377\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.7629s, Score: 0.9972\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:05.379\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000000000002 Max importance (40): 0.6264 (bwdIAT_MEAN), Min importance (2): 0.0000 (TotLenfwdAPP), Removed feature: TotLenfwdAPP\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:05.391\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 11, Feature Shape: (39060, 85)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:06.128\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.7359s, Score: 0.9973\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:06.129\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0 Max importance (39): 0.6247 (bwdIAT_MEAN), Min importance (3): 0.0000 (TotLenbwdAPP), Removed feature: TotLenbwdAPP\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:06.142\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 12, Feature Shape: (39060, 84)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:06.877\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.7339s, Score: 0.9975\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:06.878\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000000000004 Max importance (38): 0.6264 (bwdIAT_MEAN), Min importance (0): 0.0000 (destination port), Removed feature: destination port\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:06.889\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 13, Feature Shape: (39060, 83)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:07.597\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.7068s, Score: 0.9973\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:07.598\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0 Max importance (37): 0.6265 (bwdIAT_MEAN), Min importance (3): 0.0000 (TRfwdPktLenMAX), Removed feature: TRfwdPktLenMAX\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:07.611\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 14, Feature Shape: (39060, 82)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:08.321\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.7089s, Score: 0.9971\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:08.322\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000000000002 Max importance (36): 0.6249 (bwdIAT_MEAN), Min importance (4): 0.0000 (TRfwdPktLenMEAN), Removed feature: TRfwdPktLenMEAN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:08.333\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 15, Feature Shape: (39060, 81)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:09.043\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.7093s, Score: 0.9973\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:09.044\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0 Max importance (35): 0.6265 (bwdIAT_MEAN), Min importance (5): 0.0000 (APPfwdPktLenMAX), Removed feature: APPfwdPktLenMAX\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:09.057\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 16, Feature Shape: (39060, 80)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:09.765\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.7069s, Score: 0.9973\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:09.766\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999999999999 Max importance (34): 0.6247 (bwdIAT_MEAN), Min importance (5): 0.0000 (APPfwdPktLenMIN), Removed feature: APPfwdPktLenMIN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:09.779\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 17, Feature Shape: (39060, 79)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:10.477\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.6961s, Score: 0.9969\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:10.478\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000000000002 Max importance (33): 0.6264 (bwdIAT_MEAN), Min importance (2): 0.0000 (DLfwdPktLenMEAN), Removed feature: DLfwdPktLenMEAN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:10.491\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 18, Feature Shape: (39060, 78)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:11.191\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.6994s, Score: 0.9971\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:11.193\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000000000002 Max importance (32): 0.6247 (bwdIAT_MEAN), Min importance (3): 0.0000 (TRfwdPktLenSTD), Removed feature: TRfwdPktLenSTD\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:11.205\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 19, Feature Shape: (39060, 77)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:11.897\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.6907s, Score: 0.9969\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:11.898\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999999999999 Max importance (31): 0.6247 (bwdIAT_MEAN), Min importance (5): 0.0000 (DLbwdPktLenMAX), Removed feature: DLbwdPktLenMAX\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:11.910\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 20, Feature Shape: (39060, 76)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:12.603\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.6921s, Score: 0.9975\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:12.604\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000000000002 Max importance (30): 0.6265 (bwdIAT_MEAN), Min importance (5): 0.0000 (DLbwdPktLenMIN), Removed feature: DLbwdPktLenMIN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:12.617\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 21, Feature Shape: (39060, 75)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:13.314\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.6952s, Score: 0.9973\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:13.315\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000000000002 Max importance (29): 0.6264 (bwdIAT_MEAN), Min importance (7): 0.0000 (TRbwdPktLenMAX), Removed feature: TRbwdPktLenMAX\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:13.325\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 22, Feature Shape: (39060, 74)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:14.014\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.6886s, Score: 0.9972\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:14.015\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999999999999 Max importance (28): 0.6265 (bwdIAT_MEAN), Min importance (9): 0.0000 (TRbwdPktLenSTD), Removed feature: TRbwdPktLenSTD\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:14.025\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 23, Feature Shape: (39060, 73)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:14.713\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.6868s, Score: 0.9971\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:14.714\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000000000002 Max importance (27): 0.6249 (bwdIAT_MEAN), Min importance (9): 0.0000 (APPbwdPktLenMAX), Removed feature: APPbwdPktLenMAX\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:14.728\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 24, Feature Shape: (39060, 72)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:15.424\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.6945s, Score: 0.9972\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:15.425\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0 Max importance (26): 0.6247 (bwdIAT_MEAN), Min importance (9): 0.0000 (APPbwdPktLenMIN), Removed feature: APPbwdPktLenMIN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:15.439\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 25, Feature Shape: (39060, 71)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:16.122\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.6818s, Score: 0.9970\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:16.122\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000000000002 Max importance (25): 0.6263 (bwdIAT_MEAN), Min importance (12): 0.0000 (TRflowBytes/sec), Removed feature: TRflowBytes/sec\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:16.132\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 26, Feature Shape: (39060, 70)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:16.785\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.6513s, Score: 0.9973\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:16.786\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0 Max importance (24): 0.6267 (bwdIAT_MEAN), Min importance (5): 0.0000 (DLbwdPktLenMEAN), Removed feature: DLbwdPktLenMEAN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:16.796\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 27, Feature Shape: (39060, 69)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:17.452\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.6556s, Score: 0.9972\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:17.454\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000000000002 Max importance (23): 0.6267 (bwdIAT_MEAN), Min importance (9): 0.0000 (APPbwdPktLenSTD), Removed feature: APPbwdPktLenSTD\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:17.466\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 28, Feature Shape: (39060, 68)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:18.114\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.6476s, Score: 0.9974\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:18.115\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000000000002 Max importance (22): 0.6246 (bwdIAT_MEAN), Min importance (7): 0.0000 (TRbwdPktLenMEAN), Removed feature: TRbwdPktLenMEAN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:18.125\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 29, Feature Shape: (39060, 67)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:18.766\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.6398s, Score: 0.9974\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:18.767\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000000000002 Max importance (21): 0.6249 (bwdIAT_MEAN), Min importance (12): 0.0000 (FlowIAT_STD), Removed feature: FlowIAT_STD\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:18.776\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 30, Feature Shape: (39060, 66)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:19.384\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.6071s, Score: 0.9975\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:19.385\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000000000002 Max importance (20): 0.6247 (bwdIAT_MEAN), Min importance (9): 0.0000 (APPflowBytes/sec), Removed feature: APPflowBytes/sec\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:19.397\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 31, Feature Shape: (39060, 65)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:20.007\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.6089s, Score: 0.9976\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:20.009\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999999999997 Max importance (19): 0.6246 (bwdIAT_MEAN), Min importance (8): 0.0000 (DLflowBytes/sec), Removed feature: DLflowBytes/sec\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:20.024\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 32, Feature Shape: (39060, 64)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:20.600\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.5743s, Score: 0.9972\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:20.601\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999999999998 Max importance (18): 0.6265 (bwdIAT_MEAN), Min importance (9): 0.0000 (FlowIAT_MEAN), Removed feature: FlowIAT_MEAN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:20.613\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 33, Feature Shape: (39060, 63)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:21.145\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.5313s, Score: 0.9975\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:21.146\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999999999997 Max importance (17): 0.6265 (bwdIAT_MEAN), Min importance (14): 0.0000 (fwdIAT_MAX), Removed feature: fwdIAT_MAX\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:21.155\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 34, Feature Shape: (39060, 62)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:21.667\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.5108s, Score: 0.9972\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:21.667\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999999999997 Max importance (16): 0.6264 (bwdIAT_MEAN), Min importance (20): 0.0000 (DLfwdHdrLen), Removed feature: DLfwdHdrLen\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:21.677\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 35, Feature Shape: (39060, 61)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:22.187\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.5085s, Score: 0.9971\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:22.188\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999999999999 Max importance (16): 0.6250 (bwdIAT_MEAN), Min importance (20): 0.0000 (TRfwdHdrLen), Removed feature: TRfwdHdrLen\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:22.199\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 36, Feature Shape: (39060, 60)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:22.713\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.5130s, Score: 0.9972\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:22.714\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999999999999 Max importance (16): 0.6248 (bwdIAT_MEAN), Min importance (20): 0.0000 (APPfwdHdrLen), Removed feature: APPfwdHdrLen\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:22.724\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 37, Feature Shape: (39060, 59)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:23.229\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.5036s, Score: 0.9973\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:23.230\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999999999999 Max importance (16): 0.6268 (bwdIAT_MEAN), Min importance (20): 0.0000 (DLbwdHdrLen), Removed feature: DLbwdHdrLen\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:23.239\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 38, Feature Shape: (39060, 58)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:23.742\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.5023s, Score: 0.9975\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:23.743\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999999999999 Max importance (16): 0.6247 (bwdIAT_MEAN), Min importance (24): 0.0000 (DLpktLenMEAN), Removed feature: DLpktLenMEAN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:23.753\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 39, Feature Shape: (39060, 57)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:24.251\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.4971s, Score: 0.9975\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:24.252\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999999999998 Max importance (16): 0.6265 (bwdIAT_MEAN), Min importance (21): 0.0000 (APPbwdHdrLen), Removed feature: APPbwdHdrLen\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:24.260\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 40, Feature Shape: (39060, 56)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:24.758\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.4966s, Score: 0.9969\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:24.759\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000000000002 Max importance (16): 0.6267 (bwdIAT_MEAN), Min importance (12): 0.0000 (fwdIAT_MEAN), Removed feature: fwdIAT_MEAN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:24.768\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 41, Feature Shape: (39060, 55)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:25.239\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.4704s, Score: 0.9972\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:25.240\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000000000002 Max importance (15): 0.6248 (bwdIAT_MEAN), Min importance (12): 0.0000 (fwdIAT_STD), Removed feature: fwdIAT_STD\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:25.249\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 42, Feature Shape: (39060, 54)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:25.686\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.4360s, Score: 0.9972\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:25.687\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999999999997 Max importance (14): 0.6247 (bwdIAT_MEAN), Min importance (19): 0.0000 (fwdPkts/sec), Removed feature: fwdPkts/sec\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:25.696\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 43, Feature Shape: (39060, 53)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:26.110\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.4136s, Score: 0.9971\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:26.111\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000000000002 Max importance (14): 0.6272 (bwdIAT_MEAN), Min importance (18): 0.0000 (TRbwdHdrLen), Removed feature: TRbwdHdrLen\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:26.120\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 44, Feature Shape: (39060, 52)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:26.535\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.4141s, Score: 0.9973\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:26.536\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000000000002 Max importance (14): 0.6251 (bwdIAT_MEAN), Min importance (19): 0.0000 (DLpktLenMIN), Removed feature: DLpktLenMIN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:26.545\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 45, Feature Shape: (39060, 51)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:26.953\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.4074s, Score: 0.9972\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:26.954\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999999999999 Max importance (14): 0.6263 (bwdIAT_MEAN), Min importance (19): 0.0000 (DLpktLenMAX), Removed feature: DLpktLenMAX\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:26.961\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 46, Feature Shape: (39060, 50)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:27.374\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.4113s, Score: 0.9974\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:27.375\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000000000002 Max importance (14): 0.6249 (bwdIAT_MEAN), Min importance (19): 0.0000 (DLpktLenSTD), Removed feature: DLpktLenSTD\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:27.384\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 47, Feature Shape: (39060, 49)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:27.786\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.4009s, Score: 0.9975\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:27.787\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0 Max importance (14): 0.6264 (bwdIAT_MEAN), Min importance (21): 0.0000 (TRpktLenMIN), Removed feature: TRpktLenMIN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:27.794\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 48, Feature Shape: (39060, 48)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:28.201\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.4060s, Score: 0.9973\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:28.203\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999999999997 Max importance (14): 0.6247 (bwdIAT_MEAN), Min importance (20): 0.0000 (TRpktLenMEAN), Removed feature: TRpktLenMEAN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:28.210\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 49, Feature Shape: (39060, 47)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:28.602\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.3910s, Score: 0.9972\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:28.603\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999999999999 Max importance (14): 0.6248 (bwdIAT_MEAN), Min importance (24): 0.0000 (APPpktLenMIN), Removed feature: APPpktLenMIN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:28.612\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 50, Feature Shape: (39060, 46)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:29.008\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.3944s, Score: 0.9974\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:29.009\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000000000002 Max importance (14): 0.6266 (bwdIAT_MEAN), Min importance (20): 0.0000 (TRpktLenMAX), Removed feature: TRpktLenMAX\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:29.015\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 51, Feature Shape: (39060, 45)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:29.410\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.3937s, Score: 0.9971\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:29.411\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0 Max importance (14): 0.6265 (bwdIAT_MEAN), Min importance (32): 0.0000 (IdleMAX), Removed feature: IdleMAX\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:29.419\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 52, Feature Shape: (39060, 44)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:29.810\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.3906s, Score: 0.9972\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:29.811\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999999999999 Max importance (14): 0.6266 (bwdIAT_MEAN), Min importance (22): 0.0000 (APPpktLenMEAN), Removed feature: APPpktLenMEAN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:29.818\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 53, Feature Shape: (39060, 43)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:30.203\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.3837s, Score: 0.9972\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:30.203\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0 Max importance (14): 0.6249 (bwdIAT_MEAN), Min importance (20): 0.0000 (TRpktLenSTD), Removed feature: TRpktLenSTD\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:30.210\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 54, Feature Shape: (39060, 42)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:30.597\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.3859s, Score: 0.9969\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:30.598\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000000000002 Max importance (14): 0.6264 (bwdIAT_MEAN), Min importance (19): 0.0000 (DLpktLenVAR), Removed feature: DLpktLenVAR\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:30.606\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 55, Feature Shape: (39060, 41)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:30.989\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.3817s, Score: 0.9970\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:30.990\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999999999999 Max importance (14): 0.6263 (bwdIAT_MEAN), Min importance (20): 0.0000 (APPpktLenMAX), Removed feature: APPpktLenMAX\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:30.997\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 56, Feature Shape: (39060, 40)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:31.374\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.3756s, Score: 0.9972\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:31.375\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999999999999 Max importance (14): 0.6246 (bwdIAT_MEAN), Min importance (20): 0.0000 (APPpktLenSTD), Removed feature: APPpktLenSTD\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:31.382\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 57, Feature Shape: (39060, 39)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:31.751\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.3676s, Score: 0.9975\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:31.751\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000000000002 Max importance (14): 0.6267 (bwdIAT_MEAN), Min importance (21): 0.0000 (ActiveMEAN), Removed feature: ActiveMEAN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:31.757\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 58, Feature Shape: (39060, 38)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:32.127\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.3688s, Score: 0.9974\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:32.128\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0 Max importance (14): 0.6249 (bwdIAT_MEAN), Min importance (25): 0.0000 (IdleSTD), Removed feature: IdleSTD\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:32.135\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 59, Feature Shape: (39060, 37)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:32.500\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.3638s, Score: 0.9971\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:32.501\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0 Max importance (14): 0.6267 (bwdIAT_MEAN), Min importance (22): 0.0000 (ActiveMAX), Removed feature: ActiveMAX\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:32.507\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 60, Feature Shape: (39060, 36)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:32.870\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.3624s, Score: 0.9970\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:32.871\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999999999999 Max importance (14): 0.6247 (bwdIAT_MEAN), Min importance (26): 0.0000 (frameDst), Removed feature: frameDst\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:32.877\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 61, Feature Shape: (39060, 35)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:33.237\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.3595s, Score: 0.9972\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:33.239\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0 Max importance (14): 0.6248 (bwdIAT_MEAN), Min importance (27): 0.0000 (firstPacketDIR), Removed feature: firstPacketDIR\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:33.244\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 62, Feature Shape: (39060, 34)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:33.598\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.3532s, Score: 0.9970\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:33.599\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999999999999 Max importance (14): 0.6250 (bwdIAT_MEAN), Min importance (26): 0.0000 (TotPktsInFlow), Removed feature: TotPktsInFlow\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:33.605\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 63, Feature Shape: (39060, 33)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:33.959\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.3527s, Score: 0.9971\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:33.959\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999999999999 Max importance (14): 0.6250 (bwdIAT_MEAN), Min importance (19): 0.0000 (TRpktLenVAR), Removed feature: TRpktLenVAR\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:33.964\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 64, Feature Shape: (39060, 32)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:34.312\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.3469s, Score: 0.9970\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:34.314\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999999999999 Max importance (14): 0.6266 (bwdIAT_MEAN), Min importance (25): 0.0000 (mostCommonREQ_FUNC_CODE), Removed feature: mostCommonREQ_FUNC_CODE\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:34.321\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 65, Feature Shape: (39060, 31)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:34.667\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.3455s, Score: 0.9973\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:34.668\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0 Max importance (14): 0.6250 (bwdIAT_MEAN), Min importance (26): 0.0000 (corruptConfigFragments), Removed feature: corruptConfigFragments\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:34.673\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 66, Feature Shape: (39060, 30)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:35.019\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.3455s, Score: 0.9974\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:35.020\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0 Max importance (14): 0.6250 (bwdIAT_MEAN), Min importance (26): 0.0000 (deviceTroubleFragments), Removed feature: deviceTroubleFragments\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:35.025\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 67, Feature Shape: (39060, 29)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:35.375\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.3492s, Score: 0.9975\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:35.376\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000000000002 Max importance (14): 0.6247 (bwdIAT_MEAN), Min importance (26): 0.0000 (deviceRestartFragments), Removed feature: deviceRestartFragments\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:35.382\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 68, Feature Shape: (39060, 28)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:35.729\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.3455s, Score: 0.9973\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:35.730\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0 Max importance (14): 0.6267 (bwdIAT_MEAN), Min importance (27): 0.0000 (pktsFromSLAVE), Removed feature: pktsFromSLAVE\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:35.734\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 69, Feature Shape: (39060, 27)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:36.079\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.3433s, Score: 0.9975\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:36.080\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0 Max importance (14): 0.6249 (bwdIAT_MEAN), Min importance (25): 0.0001 (mostCommonRESP_FUNC_CODE), Removed feature: mostCommonRESP_FUNC_CODE\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:36.084\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 70, Feature Shape: (39060, 26)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:36.431\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.3455s, Score: 0.9972\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:36.432\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0 Max importance (14): 0.6266 (bwdIAT_MEAN), Min importance (5): 0.0001 (DLbwdPktLenSTD), Removed feature: DLbwdPktLenSTD\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:36.437\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 71, Feature Shape: (39060, 25)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:36.781\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.3431s, Score: 0.9972\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:36.782\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000000000002 Max importance (13): 0.6264 (bwdIAT_MEAN), Min importance (24): 0.0001 (pktsFromMASTER), Removed feature: pktsFromMASTER\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:36.787\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 72, Feature Shape: (39060, 24)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:37.118\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.3297s, Score: 0.9970\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:37.119\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0 Max importance (13): 0.6250 (bwdIAT_MEAN), Min importance (7): 0.0001 (FlowPkts/sec), Removed feature: FlowPkts/sec\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:37.124\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 73, Feature Shape: (39060, 23)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:37.436\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.3104s, Score: 0.9975\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:37.437\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0 Max importance (12): 0.6264 (bwdIAT_MEAN), Min importance (4): 0.0002 (APPfwdPktLenSTD), Removed feature: APPfwdPktLenSTD\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:37.442\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 74, Feature Shape: (39060, 22)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:37.745\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.3020s, Score: 0.9969\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:37.746\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0 Max importance (11): 0.6264 (bwdIAT_MEAN), Min importance (21): 0.0005 (frameSrc), Removed feature: frameSrc\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:37.749\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 75, Feature Shape: (39060, 21)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:38.053\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.3024s, Score: 0.9972\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:38.054\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000000000002 Max importance (11): 0.6248 (bwdIAT_MEAN), Min importance (2): 0.0006 (TRfwdPktLenMIN), Removed feature: TRfwdPktLenMIN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:38.059\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 76, Feature Shape: (39060, 20)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:38.361\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.3011s, Score: 0.9972\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:38.362\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0 Max importance (10): 0.6254 (bwdIAT_MEAN), Min importance (12): 0.0002 (bwdIAT_MAX), Removed feature: bwdIAT_MAX\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:38.367\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 77, Feature Shape: (39060, 19)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:38.643\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.2749s, Score: 0.9969\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:38.644\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0 Max importance (10): 0.6268 (bwdIAT_MEAN), Min importance (14): 0.0005 (APPpktLenVAR), Removed feature: APPpktLenVAR\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:38.647\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 78, Feature Shape: (39060, 18)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:38.919\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.2710s, Score: 0.9971\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:38.920\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0 Max importance (10): 0.6255 (bwdIAT_MEAN), Min importance (9): 0.0006 (TotalBwdIAT), Removed feature: TotalBwdIAT\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:38.924\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 79, Feature Shape: (39060, 17)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:39.173\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.2473s, Score: 0.9969\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:39.174\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000000000002 Max importance (9): 0.6264 (bwdIAT_MEAN), Min importance (13): 0.0008 (ActiveSTD), Removed feature: ActiveSTD\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:39.178\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 80, Feature Shape: (39060, 16)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:39.426\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.2467s, Score: 0.9965\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:39.427\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999999999999 Max importance (9): 0.6268 (bwdIAT_MEAN), Min importance (10): 0.0010 (bwdIAT_STD), Removed feature: bwdIAT_STD\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:39.430\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 81, Feature Shape: (39060, 15)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:39.645\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.2135s, Score: 0.9963\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:39.646\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0 Max importance (9): 0.6273 (bwdIAT_MEAN), Min importance (7): 0.0004 (TotalFwdIAT), Removed feature: TotalFwdIAT\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:39.649\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 82, Feature Shape: (39060, 14)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:39.829\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.1797s, Score: 0.9965\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:39.830\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0 Max importance (8): 0.6267 (bwdIAT_MEAN), Min importance (10): 0.0008 (bwdPkts/sec), Removed feature: bwdPkts/sec\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:39.834\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 83, Feature Shape: (39060, 13)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:39.991\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.1562s, Score: 0.9966\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:39.992\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999999999999 Max importance (8): 0.6269 (bwdIAT_MEAN), Min importance (10): 0.0012 (ActiveMIN), Removed feature: ActiveMIN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:39.996\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 84, Feature Shape: (39060, 12)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:40.155\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.1583s, Score: 0.9972\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:40.156\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999999999999 Max importance (8): 0.6269 (bwdIAT_MEAN), Min importance (10): 0.0012 (IdleMEAN), Removed feature: IdleMEAN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:40.159\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 85, Feature Shape: (39060, 11)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:40.346\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.1864s, Score: 0.9965\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:40.347\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0 Max importance (8): 0.6275 (bwdIAT_MEAN), Min importance (9): 0.0014 (bwdIAT_MIN), Removed feature: bwdIAT_MIN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:40.350\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 86, Feature Shape: (39060, 10)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:40.485\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.1337s, Score: 0.9964\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:40.486\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0 Max importance (8): 0.6272 (bwdIAT_MEAN), Min importance (2): 0.0014 (APPfwdPktLenMEAN), Removed feature: APPfwdPktLenMEAN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:40.488\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 87, Feature Shape: (39060, 9)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:40.621\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.1313s, Score: 0.9968\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:40.622\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999999999999 Max importance (7): 0.6275 (bwdIAT_MEAN), Min importance (4): 0.0029 (FlowIAT_MAX), Removed feature: FlowIAT_MAX\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:40.625\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 88, Feature Shape: (39060, 8)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:40.743\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.1177s, Score: 0.9966\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:40.745\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999999999999 Max importance (6): 0.6257 (bwdIAT_MEAN), Min importance (7): 0.0033 (IdleMIN), Removed feature: IdleMIN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:40.747\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 89, Feature Shape: (39060, 7)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:40.858\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.1105s, Score: 0.9969\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:40.859\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0 Max importance (6): 0.6276 (bwdIAT_MEAN), Min importance (5): 0.0038 (fwdIAT_MIN), Removed feature: fwdIAT_MIN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:40.861\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 90, Feature Shape: (39060, 6)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:40.945\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.0826s, Score: 0.9958\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:40.946\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0 Max importance (5): 0.6295 (bwdIAT_MEAN), Min importance (3): 0.0065 (APPbwdPktLenMEAN), Removed feature: APPbwdPktLenMEAN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:40.948\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 91, Feature Shape: (39060, 5)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:41.032\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.0832s, Score: 0.9958\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:41.033\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0 Max importance (4): 0.6290 (bwdIAT_MEAN), Min importance (1): 0.0298 (TotLenbwdDL), Removed feature: TotLenbwdDL\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:41.035\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 92, Feature Shape: (39060, 4)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:41.105\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.0699s, Score: 0.9968\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:41.106\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0 Max importance (3): 0.6505 (bwdIAT_MEAN), Min importance (2): 0.0248 (FlowIAT_MIN), Removed feature: FlowIAT_MIN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:41.108\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 93, Feature Shape: (39060, 3)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:41.160\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.0520s, Score: 0.9921\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:41.161\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0 Max importance (2): 0.6659 (bwdIAT_MEAN), Min importance (0): 0.1302 (duration), Removed feature: duration\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:41.163\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 94, Feature Shape: (39060, 2)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:41.195\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.0317s, Score: 0.9918\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:41.196\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0 Max importance (1): 0.6939 (bwdIAT_MEAN), Min importance (0): 0.3061 (TRbwdPktLenMIN), Removed feature: TRbwdPktLenMIN\u001b[0m\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-18 18:22:41.384\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m47\u001b[0m - \u001b[1mTop 10 features: ['bwdIAT_MEAN', 'TRbwdPktLenMIN', 'duration', 'FlowIAT_MIN', 'TotLenbwdDL', 'APPbwdPktLenMEAN', 'fwdIAT_MIN', 'IdleMIN', 'FlowIAT_MAX', 'APPfwdPktLenMEAN', 'bwdIAT_MIN']\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import sys\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"sklearn\")\n",
    "\n",
    "# sys.path.append(os.path.abspath(r\"E:\\MSc Works\\IDS\"))\n",
    "# from ids_expt.data.rfe import RFE\n",
    "\n",
    "\n",
    "# shuffle the data\n",
    "ddf = det_df.copy().sample(frac=1.0, random_state=42, replace=False)\n",
    "\n",
    "# Binary encode labels (MALICIOUS = 1, others = 0)\n",
    "ddf[\"Label\"] = ddf[\"Label\"].apply(lambda x: 1 if x == \"MALICIOUS\" else 0)\n",
    "\n",
    "# Stratified split\n",
    "train_df, test_df = train_test_split(\n",
    "    ddf, test_size=0.25, random_state=42, stratify=ddf[\"Label\"]\n",
    ")\n",
    "\n",
    "X_train = train_df.drop(columns=[\"Label\"])\n",
    "y_train = train_df[\"Label\"]\n",
    "X_test = test_df.drop(columns=[\"Label\"])\n",
    "y_test = test_df[\"Label\"]\n",
    "\n",
    "\n",
    "# Initialize RFE\n",
    "rfe = RFE(\n",
    "    model=DecisionTreeClassifier(),  # Increase from default 100\n",
    "    train_features=X_train,\n",
    "    train_labels=y_train,\n",
    "    test_features=X_test,\n",
    "    test_labels=y_test,\n",
    ")\n",
    "\n",
    "final_features = 1  # Target number of features\n",
    "curr_features = X_train.columns.tolist()\n",
    "\n",
    "for i in range(X_train.shape[1]):\n",
    "    res, curr_features = rfe.fit(feature_names=curr_features)\n",
    "    if len(curr_features) <= final_features:\n",
    "        break\n",
    "rfe.plot_results()\n",
    "logger.info(\n",
    "    f'Top 10 features: {curr_features + rfe.result[\"Removed Feature\"].tolist()[::-1][:10]}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-18 18:22:41.552\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 0, Feature Shape: (39060, 96)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:46.510\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 4.9571s, Score: 0.9982\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:46.523\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999999999998 Max importance (50): 0.0580 (bwdIAT_MEAN), Min importance (2): 0.0000 (protocol), Removed feature: protocol\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:46.538\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 1, Feature Shape: (39060, 95)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:51.554\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 5.0142s, Score: 0.9979\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:51.565\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000000000002 Max importance (40): 0.0642 (FlowIAT_STD), Min importance (90): 0.0000 (corruptConfigFragments), Removed feature: corruptConfigFragments\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:51.579\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 2, Feature Shape: (39060, 94)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:56.503\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 4.9226s, Score: 0.9980\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:56.515\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000000000002 Max importance (49): 0.0655 (bwdIAT_MEAN), Min importance (91): 0.0000 (deviceRestartFragments), Removed feature: deviceRestartFragments\u001b[0m\n",
      "\u001b[32m2025-05-18 18:22:56.530\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 3, Feature Shape: (39060, 93)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:23:01.571\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 5.0399s, Score: 0.9982\u001b[0m\n",
      "\u001b[32m2025-05-18 18:23:01.583\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000000000002 Max importance (40): 0.0595 (FlowIAT_STD), Min importance (72): 0.0000 (APPpktLenMIN), Removed feature: APPpktLenMIN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:23:01.600\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 4, Feature Shape: (39060, 92)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:23:06.810\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 5.2090s, Score: 0.9979\u001b[0m\n",
      "\u001b[32m2025-05-18 18:23:06.819\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999999999999 Max importance (49): 0.0680 (bwdIAT_MEAN), Min importance (88): 0.0000 (mostCommonRESP_FUNC_CODE), Removed feature: mostCommonRESP_FUNC_CODE\u001b[0m\n",
      "\u001b[32m2025-05-18 18:23:06.834\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 5, Feature Shape: (39060, 91)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:23:12.031\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 5.1961s, Score: 0.9982\u001b[0m\n",
      "\u001b[32m2025-05-18 18:23:12.043\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999999999996 Max importance (36): 0.0629 (TRflowBytes/sec), Min importance (88): 0.0000 (deviceTroubleFragments), Removed feature: deviceTroubleFragments\u001b[0m\n",
      "\u001b[32m2025-05-18 18:23:12.058\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 6, Feature Shape: (39060, 90)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:23:17.264\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 5.2040s, Score: 0.9979\u001b[0m\n",
      "\u001b[32m2025-05-18 18:23:17.275\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999999999997 Max importance (54): 0.0787 (TRfwdHdrLen), Min importance (20): 0.0000 (APPfwdPktLenMIN), Removed feature: APPfwdPktLenMIN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:23:17.289\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 7, Feature Shape: (39060, 89)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:23:22.589\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 5.2987s, Score: 0.9984\u001b[0m\n",
      "\u001b[32m2025-05-18 18:23:22.597\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999999999999 Max importance (48): 0.1019 (bwdIAT_MEAN), Min importance (31): 0.0000 (APPbwdPktLenMIN), Removed feature: APPbwdPktLenMIN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:23:22.610\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 8, Feature Shape: (39060, 88)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:23:27.890\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 5.2793s, Score: 0.9982\u001b[0m\n",
      "\u001b[32m2025-05-18 18:23:27.903\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999999999999 Max importance (47): 0.0532 (bwdIAT_MEAN), Min importance (22): 0.0001 (DLbwdPktLenMAX), Removed feature: DLbwdPktLenMAX\u001b[0m\n",
      "\u001b[32m2025-05-18 18:23:27.916\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 9, Feature Shape: (39060, 87)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:23:33.158\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 5.2407s, Score: 0.9982\u001b[0m\n",
      "\u001b[32m2025-05-18 18:23:33.168\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0 Max importance (46): 0.0762 (bwdIAT_MEAN), Min importance (15): 0.0001 (TRfwdPktLenMAX), Removed feature: TRfwdPktLenMAX\u001b[0m\n",
      "\u001b[32m2025-05-18 18:23:33.180\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 10, Feature Shape: (39060, 86)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:23:38.534\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 5.3525s, Score: 0.9982\u001b[0m\n",
      "\u001b[32m2025-05-18 18:23:38.543\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0 Max importance (45): 0.1012 (bwdIAT_MEAN), Min importance (83): 0.0001 (mostCommonREQ_FUNC_CODE), Removed feature: mostCommonREQ_FUNC_CODE\u001b[0m\n",
      "\u001b[32m2025-05-18 18:23:38.556\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 11, Feature Shape: (39060, 85)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:23:43.899\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 5.3425s, Score: 0.9983\u001b[0m\n",
      "\u001b[32m2025-05-18 18:23:43.908\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999999999997 Max importance (31): 0.0732 (DLflowBytes/sec), Min importance (11): 0.0001 (DLfwdPktLenMAX), Removed feature: DLfwdPktLenMAX\u001b[0m\n",
      "\u001b[32m2025-05-18 18:23:43.920\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 12, Feature Shape: (39060, 84)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:23:49.592\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 5.6707s, Score: 0.9983\u001b[0m\n",
      "\u001b[32m2025-05-18 18:23:49.600\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999999999994 Max importance (35): 0.0701 (FlowIAT_STD), Min importance (58): 0.0003 (DLpktLenMAX), Removed feature: DLpktLenMAX\u001b[0m\n",
      "\u001b[32m2025-05-18 18:23:49.614\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 13, Feature Shape: (39060, 83)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:23:55.121\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 5.5062s, Score: 0.9983\u001b[0m\n",
      "\u001b[32m2025-05-18 18:23:55.130\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999999999998 Max importance (44): 0.0838 (bwdIAT_MEAN), Min importance (78): 0.0002 (frameDst), Removed feature: frameDst\u001b[0m\n",
      "\u001b[32m2025-05-18 18:23:55.143\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 14, Feature Shape: (39060, 82)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:24:00.668\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 5.5241s, Score: 0.9984\u001b[0m\n",
      "\u001b[32m2025-05-18 18:24:00.678\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999999999998 Max importance (30): 0.0784 (DLflowBytes/sec), Min importance (23): 0.0001 (TRbwdPktLenMAX), Removed feature: TRbwdPktLenMAX\u001b[0m\n",
      "\u001b[32m2025-05-18 18:24:00.691\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 15, Feature Shape: (39060, 81)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:24:06.281\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 5.5890s, Score: 0.9980\u001b[0m\n",
      "\u001b[32m2025-05-18 18:24:06.290\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000000000002 Max importance (29): 0.0744 (DLflowBytes/sec), Min importance (73): 0.0003 (IdleSTD), Removed feature: IdleSTD\u001b[0m\n",
      "\u001b[32m2025-05-18 18:24:06.302\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 16, Feature Shape: (39060, 80)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:24:11.345\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 5.0420s, Score: 0.9979\u001b[0m\n",
      "\u001b[32m2025-05-18 18:24:11.355\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0 Max importance (43): 0.0659 (bwdIAT_MEAN), Min importance (17): 0.0002 (APPfwdPktLenMAX), Removed feature: APPfwdPktLenMAX\u001b[0m\n",
      "\u001b[32m2025-05-18 18:24:11.366\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 17, Feature Shape: (39060, 79)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:24:16.481\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 5.1138s, Score: 0.9984\u001b[0m\n",
      "\u001b[32m2025-05-18 18:24:16.492\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000000000002 Max importance (75): 0.0910 (TotPktsInFlow), Min importance (64): 0.0003 (APPpktLenMAX), Removed feature: APPpktLenMAX\u001b[0m\n",
      "\u001b[32m2025-05-18 18:24:16.505\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 18, Feature Shape: (39060, 78)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:24:21.573\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 5.0668s, Score: 0.9982\u001b[0m\n",
      "\u001b[32m2025-05-18 18:24:21.584\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999999999999 Max importance (42): 0.0889 (bwdIAT_MEAN), Min importance (25): 0.0002 (APPbwdPktLenMAX), Removed feature: APPbwdPktLenMAX\u001b[0m\n",
      "\u001b[32m2025-05-18 18:24:21.595\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 19, Feature Shape: (39060, 77)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:24:26.881\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 5.2849s, Score: 0.9981\u001b[0m\n",
      "\u001b[32m2025-05-18 18:24:26.890\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0 Max importance (32): 0.0817 (FlowIAT_STD), Min importance (58): 0.0002 (TRpktLenMIN), Removed feature: TRpktLenMIN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:24:26.902\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 20, Feature Shape: (39060, 76)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:24:32.185\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 5.2821s, Score: 0.9982\u001b[0m\n",
      "\u001b[32m2025-05-18 18:24:32.194\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000000000002 Max importance (41): 0.0717 (bwdIAT_MEAN), Min importance (64): 0.0003 (ActiveMEAN), Removed feature: ActiveMEAN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:24:32.206\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 21, Feature Shape: (39060, 75)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:24:37.451\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 5.2432s, Score: 0.9980\u001b[0m\n",
      "\u001b[32m2025-05-18 18:24:37.459\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999999999998 Max importance (41): 0.0722 (bwdIAT_MEAN), Min importance (64): 0.0004 (ActiveSTD), Removed feature: ActiveSTD\u001b[0m\n",
      "\u001b[32m2025-05-18 18:24:37.471\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 22, Feature Shape: (39060, 74)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:24:42.906\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 5.4329s, Score: 0.9983\u001b[0m\n",
      "\u001b[32m2025-05-18 18:24:42.914\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999999999999 Max importance (27): 0.0679 (DLflowBytes/sec), Min importance (7): 0.0004 (TotLenfwdAPP), Removed feature: TotLenfwdAPP\u001b[0m\n",
      "\u001b[32m2025-05-18 18:24:42.925\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 23, Feature Shape: (39060, 73)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:24:48.435\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 5.5088s, Score: 0.9979\u001b[0m\n",
      "\u001b[32m2025-05-18 18:24:48.444\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999999999999 Max importance (31): 0.0757 (FlowIAT_STD), Min importance (25): 0.0005 (APPbwdPktLenSTD), Removed feature: APPbwdPktLenSTD\u001b[0m\n",
      "\u001b[32m2025-05-18 18:24:48.458\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 24, Feature Shape: (39060, 72)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:24:53.862\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 5.4028s, Score: 0.9983\u001b[0m\n",
      "\u001b[32m2025-05-18 18:24:53.871\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000000000002 Max importance (39): 0.0799 (bwdIAT_MEAN), Min importance (62): 0.0005 (ActiveMAX), Removed feature: ActiveMAX\u001b[0m\n",
      "\u001b[32m2025-05-18 18:24:53.884\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 25, Feature Shape: (39060, 71)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:24:59.392\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 5.5074s, Score: 0.9983\u001b[0m\n",
      "\u001b[32m2025-05-18 18:24:59.401\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0 Max importance (39): 0.0703 (bwdIAT_MEAN), Min importance (56): 0.0003 (TRpktLenMAX), Removed feature: TRpktLenMAX\u001b[0m\n",
      "\u001b[32m2025-05-18 18:24:59.413\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 26, Feature Shape: (39060, 70)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:25:04.967\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 5.5529s, Score: 0.9981\u001b[0m\n",
      "\u001b[32m2025-05-18 18:25:04.979\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000000000002 Max importance (39): 0.0769 (bwdIAT_MEAN), Min importance (61): 0.0006 (ActiveMIN), Removed feature: ActiveMIN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:25:04.992\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 27, Feature Shape: (39060, 69)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:25:10.981\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 5.9883s, Score: 0.9978\u001b[0m\n",
      "\u001b[32m2025-05-18 18:25:10.992\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0 Max importance (39): 0.0756 (bwdIAT_MEAN), Min importance (62): 0.0004 (IdleMAX), Removed feature: IdleMAX\u001b[0m\n",
      "\u001b[32m2025-05-18 18:25:11.005\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 28, Feature Shape: (39060, 68)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:25:16.733\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 5.7266s, Score: 0.9982\u001b[0m\n",
      "\u001b[32m2025-05-18 18:25:16.743\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000000000002 Max importance (39): 0.0940 (bwdIAT_MEAN), Min importance (54): 0.0006 (DLpktLenVAR), Removed feature: DLpktLenVAR\u001b[0m\n",
      "\u001b[32m2025-05-18 18:25:16.754\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 29, Feature Shape: (39060, 67)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:25:22.568\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 5.8124s, Score: 0.9978\u001b[0m\n",
      "\u001b[32m2025-05-18 18:25:22.578\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000000000002 Max importance (44): 0.0672 (TRfwdHdrLen), Min importance (22): 0.0006 (TRbwdPktLenMEAN), Removed feature: TRbwdPktLenMEAN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:25:22.588\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 30, Feature Shape: (39060, 66)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:25:28.167\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 5.5777s, Score: 0.9979\u001b[0m\n",
      "\u001b[32m2025-05-18 18:25:28.177\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0 Max importance (38): 0.0750 (bwdIAT_MEAN), Min importance (10): 0.0008 (DLfwdPktLenMIN), Removed feature: DLfwdPktLenMIN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:25:28.190\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 31, Feature Shape: (39060, 65)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:25:33.932\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 5.7406s, Score: 0.9980\u001b[0m\n",
      "\u001b[32m2025-05-18 18:25:33.941\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0 Max importance (28): 0.0815 (FlowIAT_STD), Min importance (15): 0.0005 (APPfwdPktLenMEAN), Removed feature: APPfwdPktLenMEAN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:25:33.950\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 32, Feature Shape: (39060, 64)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:25:39.707\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 5.7558s, Score: 0.9978\u001b[0m\n",
      "\u001b[32m2025-05-18 18:25:39.715\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000000000004 Max importance (36): 0.0769 (bwdIAT_MEAN), Min importance (57): 0.0011 (IdleMEAN), Removed feature: IdleMEAN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:25:39.724\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 33, Feature Shape: (39060, 63)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:25:44.834\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 5.1082s, Score: 0.9977\u001b[0m\n",
      "\u001b[32m2025-05-18 18:25:44.844\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0 Max importance (36): 0.0835 (bwdIAT_MEAN), Min importance (20): 0.0008 (TRbwdPktLenSTD), Removed feature: TRbwdPktLenSTD\u001b[0m\n",
      "\u001b[32m2025-05-18 18:25:44.854\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 34, Feature Shape: (39060, 62)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:25:49.973\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 5.1172s, Score: 0.9979\u001b[0m\n",
      "\u001b[32m2025-05-18 18:25:49.983\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999999999996 Max importance (26): 0.0758 (FlowIAT_STD), Min importance (36): 0.0007 (bwdIAT_STD), Removed feature: bwdIAT_STD\u001b[0m\n",
      "\u001b[32m2025-05-18 18:25:49.992\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 35, Feature Shape: (39060, 61)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:25:55.086\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 5.0938s, Score: 0.9982\u001b[0m\n",
      "\u001b[32m2025-05-18 18:25:55.095\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0 Max importance (35): 0.0955 (bwdIAT_MEAN), Min importance (47): 0.0005 (DLpktLenMIN), Removed feature: DLpktLenMIN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:25:55.103\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 36, Feature Shape: (39060, 60)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:26:00.227\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 5.1223s, Score: 0.9979\u001b[0m\n",
      "\u001b[32m2025-05-18 18:26:00.238\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000000000002 Max importance (21): 0.0831 (DLflowBytes/sec), Min importance (12): 0.0010 (TRfwdPktLenMIN), Removed feature: TRfwdPktLenMIN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:26:00.247\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 37, Feature Shape: (39060, 59)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:26:05.340\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 5.0923s, Score: 0.9981\u001b[0m\n",
      "\u001b[32m2025-05-18 18:26:05.352\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0 Max importance (20): 0.0964 (DLflowBytes/sec), Min importance (19): 0.0007 (APPbwdPktLenMEAN), Removed feature: APPbwdPktLenMEAN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:26:05.361\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 38, Feature Shape: (39060, 58)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:26:10.566\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 5.2034s, Score: 0.9980\u001b[0m\n",
      "\u001b[32m2025-05-18 18:26:10.577\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999999999998 Max importance (33): 0.0639 (bwdIAT_MEAN), Min importance (12): 0.0007 (TRfwdPktLenMEAN), Removed feature: TRfwdPktLenMEAN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:26:10.586\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 39, Feature Shape: (39060, 57)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:26:15.681\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 5.0931s, Score: 0.9983\u001b[0m\n",
      "\u001b[32m2025-05-18 18:26:15.689\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000000000002 Max importance (23): 0.0858 (FlowIAT_STD), Min importance (52): 0.0007 (frameSrc), Removed feature: frameSrc\u001b[0m\n",
      "\u001b[32m2025-05-18 18:26:15.697\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 40, Feature Shape: (39060, 56)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:26:20.980\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 5.2815s, Score: 0.9978\u001b[0m\n",
      "\u001b[32m2025-05-18 18:26:20.989\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0 Max importance (23): 0.0875 (FlowIAT_STD), Min importance (5): 0.0007 (TotLenfwdDL), Removed feature: TotLenfwdDL\u001b[0m\n",
      "\u001b[32m2025-05-18 18:26:20.999\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 41, Feature Shape: (39060, 55)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:26:26.465\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 5.4642s, Score: 0.9981\u001b[0m\n",
      "\u001b[32m2025-05-18 18:26:26.473\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0 Max importance (31): 0.0664 (bwdIAT_MEAN), Min importance (50): 0.0011 (IdleMIN), Removed feature: IdleMIN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:26:26.481\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 42, Feature Shape: (39060, 54)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:26:32.019\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 5.5370s, Score: 0.9982\u001b[0m\n",
      "\u001b[32m2025-05-18 18:26:32.027\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0 Max importance (31): 0.1155 (bwdIAT_MEAN), Min importance (1): 0.0002 (destination port), Removed feature: destination port\u001b[0m\n",
      "\u001b[32m2025-05-18 18:26:32.036\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 43, Feature Shape: (39060, 53)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:26:37.729\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 5.6917s, Score: 0.9978\u001b[0m\n",
      "\u001b[32m2025-05-18 18:26:37.737\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0 Max importance (21): 0.0994 (FlowIAT_STD), Min importance (14): 0.0013 (DLbwdPktLenSTD), Removed feature: DLbwdPktLenSTD\u001b[0m\n",
      "\u001b[32m2025-05-18 18:26:37.745\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 44, Feature Shape: (39060, 52)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:26:43.208\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 5.4620s, Score: 0.9979\u001b[0m\n",
      "\u001b[32m2025-05-18 18:26:43.216\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0 Max importance (29): 0.1011 (bwdIAT_MEAN), Min importance (49): 0.0013 (firstPacketDIR), Removed feature: firstPacketDIR\u001b[0m\n",
      "\u001b[32m2025-05-18 18:26:43.225\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 45, Feature Shape: (39060, 51)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:26:48.813\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 5.5868s, Score: 0.9979\u001b[0m\n",
      "\u001b[32m2025-05-18 18:26:48.824\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999999999997 Max importance (29): 0.1177 (bwdIAT_MEAN), Min importance (40): 0.0013 (DLpktLenMEAN), Removed feature: DLpktLenMEAN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:26:48.833\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 46, Feature Shape: (39060, 50)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:26:54.971\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 6.1362s, Score: 0.9980\u001b[0m\n",
      "\u001b[32m2025-05-18 18:26:54.980\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999999999998 Max importance (29): 0.0905 (bwdIAT_MEAN), Min importance (8): 0.0011 (DLfwdPktLenMEAN), Removed feature: DLfwdPktLenMEAN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:26:54.990\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 47, Feature Shape: (39060, 49)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:27:00.814\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 5.8229s, Score: 0.9979\u001b[0m\n",
      "\u001b[32m2025-05-18 18:27:00.822\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999999999999 Max importance (28): 0.1040 (bwdIAT_MEAN), Min importance (12): 0.0011 (DLbwdPktLenMEAN), Removed feature: DLbwdPktLenMEAN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:27:00.831\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 48, Feature Shape: (39060, 48)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:27:05.984\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 5.1515s, Score: 0.9978\u001b[0m\n",
      "\u001b[32m2025-05-18 18:27:05.995\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000000000002 Max importance (27): 0.0795 (bwdIAT_MEAN), Min importance (44): 0.0015 (APPpktLenVAR), Removed feature: APPpktLenVAR\u001b[0m\n",
      "\u001b[32m2025-05-18 18:27:06.004\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 49, Feature Shape: (39060, 47)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:27:11.006\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 5.0015s, Score: 0.9980\u001b[0m\n",
      "\u001b[32m2025-05-18 18:27:11.016\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0 Max importance (18): 0.0816 (FlowIAT_STD), Min importance (4): 0.0017 (TotLenfwdTR), Removed feature: TotLenfwdTR\u001b[0m\n",
      "\u001b[32m2025-05-18 18:27:11.023\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 50, Feature Shape: (39060, 46)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:27:16.499\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 5.4747s, Score: 0.9978\u001b[0m\n",
      "\u001b[32m2025-05-18 18:27:16.508\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000000000002 Max importance (17): 0.0725 (FlowIAT_STD), Min importance (4): 0.0010 (TotLenbwdDL), Removed feature: TotLenbwdDL\u001b[0m\n",
      "\u001b[32m2025-05-18 18:27:16.519\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 51, Feature Shape: (39060, 45)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:27:21.848\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 5.3272s, Score: 0.9978\u001b[0m\n",
      "\u001b[32m2025-05-18 18:27:21.858\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000000000004 Max importance (25): 0.0993 (bwdIAT_MEAN), Min importance (41): 0.0015 (APPpktLenSTD), Removed feature: APPpktLenSTD\u001b[0m\n",
      "\u001b[32m2025-05-18 18:27:21.866\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 52, Feature Shape: (39060, 44)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:27:27.319\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 5.4516s, Score: 0.9980\u001b[0m\n",
      "\u001b[32m2025-05-18 18:27:27.328\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999999999998 Max importance (25): 0.1156 (bwdIAT_MEAN), Min importance (23): 0.0016 (fwdIAT_MIN), Removed feature: fwdIAT_MIN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:27:27.336\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 53, Feature Shape: (39060, 43)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:27:32.458\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 5.1207s, Score: 0.9978\u001b[0m\n",
      "\u001b[32m2025-05-18 18:27:32.469\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000000000002 Max importance (24): 0.0885 (bwdIAT_MEAN), Min importance (37): 0.0041 (TRpktLenSTD), Removed feature: TRpktLenSTD\u001b[0m\n",
      "\u001b[32m2025-05-18 18:27:32.478\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 54, Feature Shape: (39060, 42)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:27:37.739\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 5.2597s, Score: 0.9978\u001b[0m\n",
      "\u001b[32m2025-05-18 18:27:37.748\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0 Max importance (24): 0.1146 (bwdIAT_MEAN), Min importance (37): 0.0013 (TRpktLenVAR), Removed feature: TRpktLenVAR\u001b[0m\n",
      "\u001b[32m2025-05-18 18:27:37.755\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 55, Feature Shape: (39060, 41)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:27:43.257\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 5.5008s, Score: 0.9977\u001b[0m\n",
      "\u001b[32m2025-05-18 18:27:43.266\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0 Max importance (24): 0.0954 (bwdIAT_MEAN), Min importance (36): 0.0057 (TRpktLenMEAN), Removed feature: TRpktLenMEAN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:27:43.274\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 56, Feature Shape: (39060, 40)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:27:48.611\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 5.3357s, Score: 0.9975\u001b[0m\n",
      "\u001b[32m2025-05-18 18:27:48.619\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999999999998 Max importance (24): 0.1077 (bwdIAT_MEAN), Min importance (15): 0.0022 (FlowIAT_MEAN), Removed feature: FlowIAT_MEAN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:27:48.625\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 57, Feature Shape: (39060, 39)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:27:53.888\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 5.2615s, Score: 0.9978\u001b[0m\n",
      "\u001b[32m2025-05-18 18:27:53.897\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999999999999 Max importance (23): 0.1207 (bwdIAT_MEAN), Min importance (20): 0.0029 (fwdIAT_STD), Removed feature: fwdIAT_STD\u001b[0m\n",
      "\u001b[32m2025-05-18 18:27:53.903\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 58, Feature Shape: (39060, 38)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:27:58.986\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 5.0817s, Score: 0.9977\u001b[0m\n",
      "\u001b[32m2025-05-18 18:27:58.997\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999999999999 Max importance (15): 0.0935 (FlowIAT_STD), Min importance (19): 0.0027 (fwdIAT_MEAN), Removed feature: fwdIAT_MEAN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:27:59.003\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 59, Feature Shape: (39060, 37)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:28:03.987\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 4.9836s, Score: 0.9978\u001b[0m\n",
      "\u001b[32m2025-05-18 18:28:03.996\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0 Max importance (15): 0.0997 (FlowIAT_STD), Min importance (29): 0.0014 (APPbwdHdrLen), Removed feature: APPbwdHdrLen\u001b[0m\n",
      "\u001b[32m2025-05-18 18:28:04.002\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 60, Feature Shape: (39060, 36)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:28:08.980\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 4.9776s, Score: 0.9979\u001b[0m\n",
      "\u001b[32m2025-05-18 18:28:08.990\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000000000002 Max importance (11): 0.0903 (DLflowBytes/sec), Min importance (30): 0.0070 (bwdPkts/sec), Removed feature: bwdPkts/sec\u001b[0m\n",
      "\u001b[32m2025-05-18 18:28:08.995\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 61, Feature Shape: (39060, 35)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:28:13.367\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 4.3712s, Score: 0.9979\u001b[0m\n",
      "\u001b[32m2025-05-18 18:28:13.375\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0 Max importance (21): 0.1309 (bwdIAT_MEAN), Min importance (28): 0.0061 (TRbwdHdrLen), Removed feature: TRbwdHdrLen\u001b[0m\n",
      "\u001b[32m2025-05-18 18:28:13.381\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 62, Feature Shape: (39060, 34)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:28:17.634\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 4.2513s, Score: 0.9977\u001b[0m\n",
      "\u001b[32m2025-05-18 18:28:17.642\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000000000002 Max importance (15): 0.1109 (FlowIAT_STD), Min importance (0): 0.0060 (source port), Removed feature: source port\u001b[0m\n",
      "\u001b[32m2025-05-18 18:28:17.648\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 63, Feature Shape: (39060, 33)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:28:22.054\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 4.4055s, Score: 0.9978\u001b[0m\n",
      "\u001b[32m2025-05-18 18:28:22.063\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000000000002 Max importance (14): 0.0937 (FlowIAT_STD), Min importance (29): 0.0044 (APPpktLenMEAN), Removed feature: APPpktLenMEAN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:28:22.069\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 64, Feature Shape: (39060, 32)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:28:26.561\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 4.4913s, Score: 0.9976\u001b[0m\n",
      "\u001b[32m2025-05-18 18:28:26.570\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0 Max importance (20): 0.1085 (bwdIAT_MEAN), Min importance (3): 0.0053 (TotLenbwdTR), Removed feature: TotLenbwdTR\u001b[0m\n",
      "\u001b[32m2025-05-18 18:28:26.576\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 65, Feature Shape: (39060, 31)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:28:31.094\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 4.5163s, Score: 0.9978\u001b[0m\n",
      "\u001b[32m2025-05-18 18:28:31.102\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0 Max importance (19): 0.1027 (bwdIAT_MEAN), Min importance (3): 0.0057 (TotLenbwdAPP), Removed feature: TotLenbwdAPP\u001b[0m\n",
      "\u001b[32m2025-05-18 18:28:31.107\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 66, Feature Shape: (39060, 30)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:28:35.661\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 4.5533s, Score: 0.9978\u001b[0m\n",
      "\u001b[32m2025-05-18 18:28:35.671\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0 Max importance (18): 0.1221 (bwdIAT_MEAN), Min importance (0): 0.0073 (duration), Removed feature: duration\u001b[0m\n",
      "\u001b[32m2025-05-18 18:28:35.677\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 67, Feature Shape: (39060, 29)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:28:40.213\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 4.5352s, Score: 0.9979\u001b[0m\n",
      "\u001b[32m2025-05-18 18:28:40.222\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000000000002 Max importance (17): 0.1328 (bwdIAT_MEAN), Min importance (25): 0.0061 (DLpktLenSTD), Removed feature: DLpktLenSTD\u001b[0m\n",
      "\u001b[32m2025-05-18 18:28:40.227\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 68, Feature Shape: (39060, 28)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:28:44.762\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 4.5335s, Score: 0.9978\u001b[0m\n",
      "\u001b[32m2025-05-18 18:28:44.773\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000000000002 Max importance (11): 0.1223 (FlowIAT_STD), Min importance (16): 0.0091 (TotalBwdIAT), Removed feature: TotalBwdIAT\u001b[0m\n",
      "\u001b[32m2025-05-18 18:28:44.778\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 69, Feature Shape: (39060, 27)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:28:49.282\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 4.5022s, Score: 0.9980\u001b[0m\n",
      "\u001b[32m2025-05-18 18:28:49.291\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0 Max importance (8): 0.1184 (TRflowBytes/sec), Min importance (13): 0.0106 (FlowIAT_MIN), Removed feature: FlowIAT_MIN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:28:49.296\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 70, Feature Shape: (39060, 26)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:28:53.814\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 4.5171s, Score: 0.9964\u001b[0m\n",
      "\u001b[32m2025-05-18 18:28:53.824\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000000000002 Max importance (15): 0.1612 (bwdIAT_MEAN), Min importance (13): 0.0096 (TotalFwdIAT), Removed feature: TotalFwdIAT\u001b[0m\n",
      "\u001b[32m2025-05-18 18:28:53.828\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 71, Feature Shape: (39060, 25)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:28:58.040\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 4.2103s, Score: 0.9964\u001b[0m\n",
      "\u001b[32m2025-05-18 18:28:58.048\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0 Max importance (14): 0.1297 (bwdIAT_MEAN), Min importance (10): 0.0128 (FlowPkts/sec), Removed feature: FlowPkts/sec\u001b[0m\n",
      "\u001b[32m2025-05-18 18:28:58.052\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 72, Feature Shape: (39060, 24)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:29:01.473\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 3.4191s, Score: 0.9964\u001b[0m\n",
      "\u001b[32m2025-05-18 18:29:01.484\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999999999999 Max importance (10): 0.1231 (FlowIAT_STD), Min importance (5): 0.0167 (DLbwdPktLenMIN), Removed feature: DLbwdPktLenMIN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:29:01.489\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 73, Feature Shape: (39060, 23)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:29:04.991\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 3.5013s, Score: 0.9963\u001b[0m\n",
      "\u001b[32m2025-05-18 18:29:05.000\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999999999998 Max importance (9): 0.1051 (FlowIAT_STD), Min importance (13): 0.0192 (bwdIAT_MAX), Removed feature: bwdIAT_MAX\u001b[0m\n",
      "\u001b[32m2025-05-18 18:29:05.004\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 74, Feature Shape: (39060, 22)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:29:08.460\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 3.4553s, Score: 0.9960\u001b[0m\n",
      "\u001b[32m2025-05-18 18:29:08.472\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000000000002 Max importance (6): 0.1106 (DLflowBytes/sec), Min importance (19): 0.0153 (TotPktsInFlow), Removed feature: TotPktsInFlow\u001b[0m\n",
      "\u001b[32m2025-05-18 18:29:08.477\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 75, Feature Shape: (39060, 21)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:29:12.023\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 3.5454s, Score: 0.9964\u001b[0m\n",
      "\u001b[32m2025-05-18 18:29:12.032\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999999999999 Max importance (12): 0.1614 (bwdIAT_MEAN), Min importance (14): 0.0157 (DLfwdHdrLen), Removed feature: DLfwdHdrLen\u001b[0m\n",
      "\u001b[32m2025-05-18 18:29:12.037\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 76, Feature Shape: (39060, 20)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:29:15.797\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 3.7596s, Score: 0.9968\u001b[0m\n",
      "\u001b[32m2025-05-18 18:29:15.806\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0 Max importance (12): 0.1585 (bwdIAT_MEAN), Min importance (5): 0.0253 (TRbwdPktLenMIN), Removed feature: TRbwdPktLenMIN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:29:15.810\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 77, Feature Shape: (39060, 19)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:29:19.690\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 3.8783s, Score: 0.9964\u001b[0m\n",
      "\u001b[32m2025-05-18 18:29:19.699\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999999999999 Max importance (11): 0.1472 (bwdIAT_MEAN), Min importance (15): 0.0177 (DLbwdHdrLen), Removed feature: DLbwdHdrLen\u001b[0m\n",
      "\u001b[32m2025-05-18 18:29:19.703\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 78, Feature Shape: (39060, 18)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:29:23.646\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 3.9412s, Score: 0.9965\u001b[0m\n",
      "\u001b[32m2025-05-18 18:29:23.654\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000000000002 Max importance (11): 0.1499 (bwdIAT_MEAN), Min importance (10): 0.0260 (fwdIAT_MAX), Removed feature: fwdIAT_MAX\u001b[0m\n",
      "\u001b[32m2025-05-18 18:29:23.658\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 79, Feature Shape: (39060, 17)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:29:27.499\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 3.8389s, Score: 0.9962\u001b[0m\n",
      "\u001b[32m2025-05-18 18:29:27.510\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999999999998 Max importance (10): 0.1080 (bwdIAT_MEAN), Min importance (1): 0.0270 (TotalBwdPkts), Removed feature: TotalBwdPkts\u001b[0m\n",
      "\u001b[32m2025-05-18 18:29:27.514\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 80, Feature Shape: (39060, 16)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:29:31.487\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 3.9712s, Score: 0.9966\u001b[0m\n",
      "\u001b[32m2025-05-18 18:29:31.495\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0 Max importance (9): 0.1976 (bwdIAT_MEAN), Min importance (15): 0.0188 (pktsFromSLAVE), Removed feature: pktsFromSLAVE\u001b[0m\n",
      "\u001b[32m2025-05-18 18:29:31.499\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 81, Feature Shape: (39060, 15)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:29:34.828\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 3.3278s, Score: 0.9959\u001b[0m\n",
      "\u001b[32m2025-05-18 18:29:34.840\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000000000002 Max importance (7): 0.1260 (FlowIAT_STD), Min importance (3): 0.0377 (APPfwdPktLenSTD), Removed feature: APPfwdPktLenSTD\u001b[0m\n",
      "\u001b[32m2025-05-18 18:29:34.844\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 82, Feature Shape: (39060, 14)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:29:38.206\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 3.3613s, Score: 0.9965\u001b[0m\n",
      "\u001b[32m2025-05-18 18:29:38.218\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0 Max importance (6): 0.1452 (FlowIAT_STD), Min importance (12): 0.0327 (fwdPkts/sec), Removed feature: fwdPkts/sec\u001b[0m\n",
      "\u001b[32m2025-05-18 18:29:38.222\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 83, Feature Shape: (39060, 13)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:29:41.475\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 3.2520s, Score: 0.9964\u001b[0m\n",
      "\u001b[32m2025-05-18 18:29:41.483\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0 Max importance (8): 0.2055 (bwdIAT_MEAN), Min importance (1): 0.0374 (DLfwdPktLenSTD), Removed feature: DLfwdPktLenSTD\u001b[0m\n",
      "\u001b[32m2025-05-18 18:29:41.486\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 84, Feature Shape: (39060, 12)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:29:44.856\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 3.3691s, Score: 0.9959\u001b[0m\n",
      "\u001b[32m2025-05-18 18:29:44.867\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000000000002 Max importance (7): 0.1610 (bwdIAT_MEAN), Min importance (0): 0.0352 (TotalFwdPkts), Removed feature: TotalFwdPkts\u001b[0m\n",
      "\u001b[32m2025-05-18 18:29:44.870\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 85, Feature Shape: (39060, 11)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:29:48.504\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 3.6327s, Score: 0.9962\u001b[0m\n",
      "\u001b[32m2025-05-18 18:29:48.514\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0 Max importance (6): 0.2115 (bwdIAT_MEAN), Min importance (7): 0.0481 (bwdIAT_MIN), Removed feature: bwdIAT_MIN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:29:48.516\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 86, Feature Shape: (39060, 10)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:29:51.780\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 3.2623s, Score: 0.9962\u001b[0m\n",
      "\u001b[32m2025-05-18 18:29:51.788\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999999999998 Max importance (6): 0.1683 (bwdIAT_MEAN), Min importance (8): 0.0464 (APPfwdHdrLen), Removed feature: APPfwdHdrLen\u001b[0m\n",
      "\u001b[32m2025-05-18 18:29:51.791\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 87, Feature Shape: (39060, 9)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:29:55.533\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 3.7402s, Score: 0.9959\u001b[0m\n",
      "\u001b[32m2025-05-18 18:29:55.544\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000000000002 Max importance (6): 0.2487 (bwdIAT_MEAN), Min importance (7): 0.0455 (TRfwdHdrLen), Removed feature: TRfwdHdrLen\u001b[0m\n",
      "\u001b[32m2025-05-18 18:29:55.546\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 88, Feature Shape: (39060, 8)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:29:58.442\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 2.8949s, Score: 0.9952\u001b[0m\n",
      "\u001b[32m2025-05-18 18:29:58.454\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000000000002 Max importance (6): 0.2030 (bwdIAT_MEAN), Min importance (5): 0.0604 (FlowIAT_MAX), Removed feature: FlowIAT_MAX\u001b[0m\n",
      "\u001b[32m2025-05-18 18:29:58.456\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 89, Feature Shape: (39060, 7)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:01.382\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 2.9250s, Score: 0.9952\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:01.390\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0 Max importance (5): 0.2084 (bwdIAT_MEAN), Min importance (3): 0.0863 (APPflowBytes/sec), Removed feature: APPflowBytes/sec\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:01.393\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 90, Feature Shape: (39060, 6)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:04.218\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 2.8240s, Score: 0.9954\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:04.227\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000000000002 Max importance (4): 0.2371 (bwdIAT_MEAN), Min importance (0): 0.1054 (TRfwdPktLenSTD), Removed feature: TRfwdPktLenSTD\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:04.230\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 91, Feature Shape: (39060, 5)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:07.306\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 3.0754s, Score: 0.9943\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:07.318\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0 Max importance (3): 0.3042 (bwdIAT_MEAN), Min importance (4): 0.1299 (pktsFromMASTER), Removed feature: pktsFromMASTER\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:07.321\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 92, Feature Shape: (39060, 4)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:11.036\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 3.7141s, Score: 0.9929\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:11.045\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999999999998 Max importance (3): 0.3821 (bwdIAT_MEAN), Min importance (1): 0.1702 (TRflowBytes/sec), Removed feature: TRflowBytes/sec\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:11.047\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 93, Feature Shape: (39060, 3)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:13.618\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 2.5700s, Score: 0.9940\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:13.629\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0 Max importance (2): 0.3780 (bwdIAT_MEAN), Min importance (1): 0.2573 (FlowIAT_STD), Removed feature: FlowIAT_STD\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:13.631\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 94, Feature Shape: (39060, 2)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:15.986\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 2.3529s, Score: 0.9934\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:15.994\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0 Max importance (0): 0.5388 (DLflowBytes/sec), Min importance (1): 0.4612 (bwdIAT_MEAN), Removed feature: bwdIAT_MEAN\u001b[0m\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-18 18:30:16.191\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mTop 10 features: ['DLflowBytes/sec', 'bwdIAT_MEAN', 'FlowIAT_STD', 'TRflowBytes/sec', 'pktsFromMASTER', 'TRfwdPktLenSTD', 'APPflowBytes/sec', 'FlowIAT_MAX', 'TRfwdHdrLen', 'APPfwdHdrLen', 'bwdIAT_MIN']\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"sklearn\")\n",
    "\n",
    "\n",
    "# shuffle the data\n",
    "ddf = det_df.copy().sample(frac=1.0, random_state=42, replace=False)\n",
    "# ddf = ddf[[c for c in ddf.columns if c not in [\"frameSrc\", \"frameDst\"]]]\n",
    "\n",
    "# Binary encode labels (MALICIOUS = 1, others = 0)\n",
    "ddf[\"Label\"] = ddf[\"Label\"].apply(lambda x: 1 if x == \"MALICIOUS\" else 0)\n",
    "\n",
    "# Stratified split\n",
    "train_df, test_df = train_test_split(\n",
    "    ddf, test_size=0.25, random_state=42, stratify=ddf[\"Label\"]\n",
    ")\n",
    "\n",
    "X_train = train_df.drop(columns=[\"Label\"])\n",
    "y_train = train_df[\"Label\"]\n",
    "X_test = test_df.drop(columns=[\"Label\"])\n",
    "y_test = test_df[\"Label\"]\n",
    "\n",
    "\n",
    "# Initialize RFE\n",
    "rfe = RFE(\n",
    "    model=RandomForestClassifier(),\n",
    "    train_features=X_train,\n",
    "    train_labels=y_train,\n",
    "    test_features=X_test,\n",
    "    test_labels=y_test,\n",
    ")\n",
    "\n",
    "final_features = 1  # Target number of features\n",
    "curr_features = X_train.columns.tolist()\n",
    "\n",
    "for i in range(X_train.shape[1]):\n",
    "    res, curr_features = rfe.fit(feature_names=curr_features)\n",
    "    if len(curr_features) <= final_features:\n",
    "        break\n",
    "rfe.plot_results()\n",
    "logger.info(\n",
    "    f'Top 10 features: {curr_features + rfe.result[\"Removed Feature\"].tolist()[::-1][:10]}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-18 20:17:23.411\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m37\u001b[0m - \u001b[1mShape: (39060, 1), Accuracy: 0.5000, F1: 0.6667\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# what happens to the accuracy and f1 if we remove the top 10 features\n",
    "# shuffle the data\n",
    "ddf = det_df.copy().sample(frac=1.0, random_state=42, replace=False)\n",
    "# top_features = curr_features + rfe.result[\"Max Feature\"].tolist()[::-1][:10]\n",
    "# top_features = top_features + ddf.columns.tolist()[:95]\n",
    "ddf[\"Label\"] = ddf[\"Label\"].apply(lambda x: 1 if x == \"MALICIOUS\" else 0)\n",
    "\n",
    "# ddf = ddf[[\"protocol\", \"Label\"]]\n",
    "# # remove the top 10 features\n",
    "# for feature in top_features:\n",
    "#     if feature in ddf.columns:\n",
    "#         del ddf[feature]\n",
    "\n",
    "\n",
    "# Stratified split\n",
    "train_df, test_df = train_test_split(\n",
    "    ddf, test_size=0.25, random_state=42, stratify=ddf[\"Label\"]\n",
    ")\n",
    "\n",
    "X_train = train_df.drop(columns=[\"Label\"])\n",
    "y_train = train_df[\"Label\"]\n",
    "X_test = test_df.drop(columns=[\"Label\"])\n",
    "y_test = test_df[\"Label\"]\n",
    "\n",
    "# scale the data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "f1 = f1_score(y_test, y_pred, average=\"binary\")\n",
    "acc = rf.score(X_test, y_test)\n",
    "logger.info(f\"Shape: {X_train.shape}, Accuracy: {acc:.4f}, F1: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    39060.000000\n",
       "mean         0.639291\n",
       "std          0.399708\n",
       "min          0.000000\n",
       "25%          0.202899\n",
       "50%          0.927536\n",
       "75%          0.971014\n",
       "max          1.000000\n",
       "Name: pktsFromSLAVE, dtype: float64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.pktsFromSLAVE.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-18 18:30:16.232\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 0, Feature Shape: (39060, 96)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:17.557\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 1.3235s, Score: 0.9284\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:17.558\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 2.3826020310274355e-05 Max importance (46): 0.0000 (fwdIAT_STD), Min importance (42): -0.0000 (FlowIAT_MAX), Removed feature: FlowIAT_MAX\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:17.573\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 1, Feature Shape: (39060, 95)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:18.414\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.8408s, Score: 0.9370\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:18.416\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.3665381130519538e-05 Max importance (45): 0.0000 (fwdIAT_STD), Min importance (41): -0.0000 (FlowIAT_STD), Removed feature: FlowIAT_STD\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:18.431\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 2, Feature Shape: (39060, 94)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:19.365\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.9329s, Score: 0.9436\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:19.366\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.4529644209887538e-05 Max importance (44): 0.0000 (fwdIAT_STD), Min importance (48): -0.0000 (bwdIAT_MEAN), Removed feature: bwdIAT_MEAN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:19.382\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 3, Feature Shape: (39060, 93)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:20.281\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.8979s, Score: 0.9313\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:20.282\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 8.990130363480055e-06 Max importance (44): 0.0000 (fwdIAT_STD), Min importance (43): -0.0000 (fwdIAT_MEAN), Removed feature: fwdIAT_MEAN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:20.298\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 4, Feature Shape: (39060, 92)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:21.267\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.9676s, Score: 0.9356\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:21.268\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.9520156770373544e-05 Max importance (43): 0.0000 (fwdIAT_STD), Min importance (40): -0.0000 (FlowIAT_MEAN), Removed feature: FlowIAT_MEAN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:21.283\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 5, Feature Shape: (39060, 91)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:22.359\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 1.0743s, Score: 0.8161\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:22.360\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 9.1945062453009e-06 Max importance (42): 0.0000 (fwdIAT_STD), Min importance (47): -0.0000 (bwdIAT_MAX), Removed feature: bwdIAT_MAX\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:22.388\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 6, Feature Shape: (39060, 90)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:23.493\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 1.1041s, Score: 0.8173\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:23.494\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.055021336885404e-05 Max importance (42): 0.0000 (fwdIAT_STD), Min importance (43): -0.0000 (fwdIAT_MAX), Removed feature: fwdIAT_MAX\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:23.508\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 7, Feature Shape: (39060, 89)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:24.356\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.8471s, Score: 0.7972\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:24.357\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 2.281883177814774e-06 Max importance (40): 0.0000 (FlowIAT_MIN), Min importance (1): -0.0000 (destination port), Removed feature: destination port\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:24.372\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 8, Feature Shape: (39060, 88)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:25.139\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.7674s, Score: 0.8002\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:25.140\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 5.210412492879104e-06 Max importance (35): 0.0000 (DLflowBytes/sec), Min importance (45): -0.0000 (bwdIAT_MIN), Removed feature: bwdIAT_MIN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:25.154\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 9, Feature Shape: (39060, 87)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:25.999\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.8438s, Score: 0.7828\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:26.000\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 6.219896008517693e-06 Max importance (35): 0.0000 (DLflowBytes/sec), Min importance (42): -0.0000 (fwdIAT_MIN), Removed feature: fwdIAT_MIN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:26.013\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 10, Feature Shape: (39060, 86)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:26.860\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.8446s, Score: 0.7726\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:26.861\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 3.257148859622364e-06 Max importance (39): 0.0000 (FlowIAT_MIN), Min importance (0): -0.0000 (source port), Removed feature: source port\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:26.874\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 11, Feature Shape: (39060, 85)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:27.704\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.8290s, Score: 0.7623\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:27.705\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 5.801385003281972e-06 Max importance (36): 0.0000 (APPflowBytes/sec), Min importance (66): -0.0000 (ActiveMEAN), Removed feature: ActiveMEAN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:27.718\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 12, Feature Shape: (39060, 84)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:28.519\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.8002s, Score: 0.7639\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:28.520\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.3211401231029767e-05 Max importance (38): 0.0000 (FlowIAT_MIN), Min importance (68): -0.0000 (ActiveMIN), Removed feature: ActiveMIN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:28.535\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 13, Feature Shape: (39060, 83)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:29.352\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.8154s, Score: 0.7618\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:29.353\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.193031313583874e-05 Max importance (38): 0.0000 (FlowIAT_MIN), Min importance (66): -0.0000 (ActiveSTD), Removed feature: ActiveSTD\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:29.366\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 14, Feature Shape: (39060, 82)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:30.130\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.7632s, Score: 0.7624\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:30.131\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.9431200684168184e-05 Max importance (38): 0.0000 (FlowIAT_MIN), Min importance (40): -0.0000 (fwdIAT_STD), Removed feature: fwdIAT_STD\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:30.145\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 15, Feature Shape: (39060, 81)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:30.994\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.8478s, Score: 0.7557\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:30.994\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 6.463937524426787e-06 Max importance (36): 0.0000 (APPflowBytes/sec), Min importance (41): -0.0000 (bwdIAT_STD), Removed feature: bwdIAT_STD\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:31.007\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 16, Feature Shape: (39060, 80)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:31.731\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.7229s, Score: 0.6654\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:31.732\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 5.358801315394466e-06 Max importance (36): 0.0000 (APPflowBytes/sec), Min importance (67): -0.0000 (IdleMAX), Removed feature: IdleMAX\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:31.744\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 17, Feature Shape: (39060, 79)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:32.587\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.8413s, Score: 0.6660\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:32.588\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 6.48063470674771e-06 Max importance (34): 0.0000 (DLflowBytes/sec), Min importance (66): -0.0000 (IdleSTD), Removed feature: IdleSTD\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:32.600\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 18, Feature Shape: (39060, 78)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:33.393\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.7915s, Score: 0.6657\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:33.394\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 4.478895976203697e-06 Max importance (34): 0.0000 (DLflowBytes/sec), Min importance (64): -0.0000 (ActiveMAX), Removed feature: ActiveMAX\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:33.406\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 19, Feature Shape: (39060, 77)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:34.267\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.8602s, Score: 0.7137\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:34.268\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 7.481958128184012e-05 Max importance (38): 0.0001 (FlowIAT_MIN), Min importance (53): -0.0000 (DLpktLenVAR), Removed feature: DLpktLenVAR\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:34.280\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 20, Feature Shape: (39060, 76)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:34.975\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.6940s, Score: 0.7133\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:34.976\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 7.85426684041883e-05 Max importance (38): 0.0001 (FlowIAT_MIN), Min importance (57): -0.0000 (TRpktLenVAR), Removed feature: TRpktLenVAR\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:34.988\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 21, Feature Shape: (39060, 75)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:35.889\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.8997s, Score: 0.6691\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:35.890\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 6.207612571944197e-05 Max importance (38): 0.0001 (FlowIAT_MIN), Min importance (61): -0.0000 (APPpktLenVAR), Removed feature: APPpktLenVAR\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:35.904\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 22, Feature Shape: (39060, 74)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:36.769\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.8639s, Score: 0.6653\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:36.770\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.925380277742585e-05 Max importance (38): 0.0000 (FlowIAT_MIN), Min importance (5): -0.0000 (TotLenfwdTR), Removed feature: TotLenfwdTR\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:36.784\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 23, Feature Shape: (39060, 73)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:37.611\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.8253s, Score: 0.6653\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:37.612\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.8937715862597985e-05 Max importance (37): 0.0000 (FlowIAT_MIN), Min importance (4): -0.0000 (TotLenfwdDL), Removed feature: TotLenfwdDL\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:37.623\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 24, Feature Shape: (39060, 72)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:38.335\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.7110s, Score: 0.6654\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:38.336\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.918695688728475e-05 Max importance (36): 0.0000 (FlowIAT_MIN), Min importance (4): -0.0000 (TotLenfwdAPP), Removed feature: TotLenfwdAPP\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:38.348\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 25, Feature Shape: (39060, 71)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:39.223\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.8734s, Score: 0.6653\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:39.224\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.8612707881201794e-05 Max importance (35): 0.0000 (FlowIAT_MIN), Min importance (7): -0.0000 (DLfwdPktLenMAX), Removed feature: DLfwdPktLenMAX\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:39.235\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 26, Feature Shape: (39060, 70)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:40.009\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.7728s, Score: 0.6656\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:40.010\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.9058550640560278e-05 Max importance (34): 0.0000 (FlowIAT_MIN), Min importance (10): -0.0000 (TRfwdPktLenMAX), Removed feature: TRfwdPktLenMAX\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:40.021\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 27, Feature Shape: (39060, 69)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:40.922\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.8993s, Score: 0.6655\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:40.924\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.6615617720922732e-05 Max importance (33): 0.0000 (FlowIAT_MIN), Min importance (13): -0.0000 (APPfwdPktLenMAX), Removed feature: APPfwdPktLenMAX\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:40.936\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 28, Feature Shape: (39060, 68)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:41.699\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.7621s, Score: 0.6653\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:41.700\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.9010839139660437e-05 Max importance (32): 0.0000 (FlowIAT_MIN), Min importance (62): -0.0000 (mostCommonRESP_FUNC_CODE), Removed feature: mostCommonRESP_FUNC_CODE\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:41.711\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 29, Feature Shape: (39060, 67)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:42.546\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.8339s, Score: 0.6655\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:42.547\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.7315133102676734e-05 Max importance (32): 0.0000 (FlowIAT_MIN), Min importance (45): -0.0000 (DLpktLenMAX), Removed feature: DLpktLenMAX\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:42.558\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 30, Feature Shape: (39060, 66)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:43.475\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.9151s, Score: 0.6636\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:43.476\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.00015552140036066998 Max importance (30): 0.0001 (APPflowBytes/sec), Min importance (48): -0.0000 (TRpktLenMAX), Removed feature: TRpktLenMAX\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:43.487\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 31, Feature Shape: (39060, 65)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:44.383\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.8951s, Score: 0.6653\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:44.384\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.9149397705315406e-05 Max importance (32): 0.0000 (FlowIAT_MIN), Min importance (51): -0.0000 (APPpktLenMAX), Removed feature: APPpktLenMAX\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:44.396\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 32, Feature Shape: (39060, 64)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:45.185\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.7880s, Score: 0.6648\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:45.187\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.7753318391903308e-05 Max importance (32): 0.0000 (FlowIAT_MIN), Min importance (31): -0.0000 (FlowPkts/sec), Removed feature: FlowPkts/sec\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:45.197\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 33, Feature Shape: (39060, 63)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:46.061\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.8629s, Score: 0.6653\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:46.062\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 2.2494188354356694e-05 Max importance (31): 0.0000 (FlowIAT_MIN), Min importance (9): -0.0000 (DLfwdPktLenSTD), Removed feature: DLfwdPktLenSTD\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:46.073\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 34, Feature Shape: (39060, 62)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:46.800\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.7262s, Score: 0.6650\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:46.801\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 2.2107459856215082e-05 Max importance (30): 0.0000 (FlowIAT_MIN), Min importance (14): -0.0000 (APPfwdPktLenSTD), Removed feature: APPfwdPktLenSTD\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:46.811\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 35, Feature Shape: (39060, 61)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:47.603\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.7906s, Score: 0.6653\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:47.604\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 2.002672724450717e-05 Max importance (29): 0.0000 (FlowIAT_MIN), Min importance (11): -0.0000 (TRfwdPktLenSTD), Removed feature: TRfwdPktLenSTD\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:47.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 36, Feature Shape: (39060, 60)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:48.333\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.7165s, Score: 0.6655\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:48.334\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.937869697206442e-05 Max importance (28): 0.0000 (FlowIAT_MIN), Min importance (37): -0.0000 (fwdPkts/sec), Removed feature: fwdPkts/sec\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:48.344\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 37, Feature Shape: (39060, 59)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:49.166\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.8212s, Score: 0.6653\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:49.167\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.9884762270812617e-05 Max importance (28): 0.0000 (FlowIAT_MIN), Min importance (37): -0.0000 (bwdPkts/sec), Removed feature: bwdPkts/sec\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:49.180\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 38, Feature Shape: (39060, 58)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:49.947\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.7661s, Score: 0.7180\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:49.948\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.0003929233002476927 Max importance (27): 0.0001 (APPflowBytes/sec), Min importance (33): -0.0000 (APPfwdHdrLen), Removed feature: APPfwdHdrLen\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:49.959\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 39, Feature Shape: (39060, 57)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:50.632\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.6712s, Score: 0.6653\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:50.633\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 2.198326311414099e-05 Max importance (28): 0.0000 (FlowIAT_MIN), Min importance (44): -0.0000 (APPpktLenSTD), Removed feature: APPpktLenSTD\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:50.643\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 40, Feature Shape: (39060, 56)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:51.206\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.5614s, Score: 0.6655\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:51.207\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.9379887030831188e-05 Max importance (28): 0.0000 (FlowIAT_MIN), Min importance (38): -0.0000 (DLpktLenSTD), Removed feature: DLpktLenSTD\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:51.217\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 41, Feature Shape: (39060, 55)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:51.961\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.7423s, Score: 0.6650\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:51.962\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.7415568803799497e-05 Max importance (28): 0.0000 (FlowIAT_MIN), Min importance (40): -0.0000 (TRpktLenSTD), Removed feature: TRpktLenSTD\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:51.972\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 42, Feature Shape: (39060, 54)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:52.586\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.6128s, Score: 0.6654\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:52.587\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 2.0197259614077015e-05 Max importance (28): 0.0000 (FlowIAT_MIN), Min importance (8): -0.0000 (DLfwdPktLenMEAN), Removed feature: DLfwdPktLenMEAN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:52.596\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 43, Feature Shape: (39060, 53)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:53.380\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.7822s, Score: 0.6655\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:53.381\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.92867633493197e-05 Max importance (27): 0.0000 (FlowIAT_MIN), Min importance (9): -0.0000 (TRfwdPktLenMEAN), Removed feature: TRfwdPktLenMEAN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:53.391\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 44, Feature Shape: (39060, 52)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:53.968\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.5754s, Score: 0.6654\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:53.969\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.0001222213710310795 Max importance (25): 0.0000 (APPflowBytes/sec), Min importance (10): -0.0000 (APPfwdPktLenMEAN), Removed feature: APPfwdPktLenMEAN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:53.978\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 45, Feature Shape: (39060, 51)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:54.652\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.6723s, Score: 0.6647\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:54.653\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 2.9122521119658713e-05 Max importance (25): 0.0000 (FlowIAT_MIN), Min importance (33): -0.0000 (DLpktLenMEAN), Removed feature: DLpktLenMEAN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:54.663\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 46, Feature Shape: (39060, 50)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:55.359\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.6954s, Score: 0.6653\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:55.360\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 2.006598246230901e-05 Max importance (25): 0.0000 (FlowIAT_MIN), Min importance (38): -0.0000 (IdleMEAN), Removed feature: IdleMEAN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:55.371\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 47, Feature Shape: (39060, 49)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:55.959\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.5863s, Score: 0.8316\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:55.959\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.018646915613072457 Max importance (4): 0.0041 (TotLenbwdDL), Min importance (22): -0.0021 (DLflowBytes/sec), Removed feature: DLflowBytes/sec\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:55.968\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 48, Feature Shape: (39060, 48)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:56.393\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.4243s, Score: 0.6645\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:56.394\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.928834196629966e-05 Max importance (24): 0.0000 (FlowIAT_MIN), Min importance (37): -0.0000 (IdleMIN), Removed feature: IdleMIN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:56.403\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 49, Feature Shape: (39060, 47)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:56.831\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.4274s, Score: 0.7855\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:56.833\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.0008074714199406647 Max importance (23): 0.0002 (APPflowBytes/sec), Min importance (33): -0.0000 (TRpktLenMEAN), Removed feature: TRpktLenMEAN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:56.840\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 50, Feature Shape: (39060, 46)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:57.253\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.4114s, Score: 0.6663\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:57.254\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 2.3406913655927464e-05 Max importance (24): 0.0000 (FlowIAT_MIN), Min importance (36): -0.0000 (frameSrc), Removed feature: frameSrc\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:57.262\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 51, Feature Shape: (39060, 45)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:57.825\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.5620s, Score: 0.6662\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:57.826\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.0002749603942349685 Max importance (4): 0.0001 (TotLenbwdDL), Min importance (22): -0.0000 (TRflowBytes/sec), Removed feature: TRflowBytes/sec\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:57.834\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 52, Feature Shape: (39060, 44)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:58.621\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.7858s, Score: 0.6667\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:58.622\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.00012751146961479038 Max importance (4): 0.0000 (TotLenbwdDL), Min importance (33): -0.0000 (APPpktLenMEAN), Removed feature: APPpktLenMEAN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:58.629\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 53, Feature Shape: (39060, 43)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:58.986\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.3562s, Score: 0.7780\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:58.987\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.00873419452878045 Max importance (23): 0.0020 (FlowIAT_MIN), Min importance (7): -0.0001 (DLfwdPktLenMIN), Removed feature: DLfwdPktLenMIN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:58.994\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 54, Feature Shape: (39060, 42)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:59.545\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.5500s, Score: 0.8452\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:59.546\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.021083749510195884 Max importance (4): 0.0046 (TotLenbwdDL), Min importance (7): -0.0002 (TRfwdPktLenMIN), Removed feature: TRfwdPktLenMIN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:59.556\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 55, Feature Shape: (39060, 41)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:59.984\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.4273s, Score: 0.8122\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:59.985\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.021885516375830357 Max importance (4): 0.0051 (TotLenbwdDL), Min importance (29): -0.0001 (DLpktLenMIN), Removed feature: DLpktLenMIN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:30:59.991\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 56, Feature Shape: (39060, 40)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:00.285\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.2931s, Score: 0.7844\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:00.286\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.020762422314101373 Max importance (4): 0.0049 (TotLenbwdDL), Min importance (0): -0.0001 (protocol), Removed feature: protocol\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:00.293\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 57, Feature Shape: (39060, 39)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:00.592\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.2981s, Score: 0.7860\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:00.593\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.012575701174369482 Max importance (3): 0.0026 (TotLenbwdDL), Min importance (9): -0.0001 (DLbwdPktLenMEAN), Removed feature: DLbwdPktLenMEAN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:00.601\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 58, Feature Shape: (39060, 38)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:00.881\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.2791s, Score: 0.6666\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:00.882\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.00014122923162938832 Max importance (19): 0.0001 (FlowIAT_MIN), Min importance (27): -0.0000 (TRpktLenMIN), Removed feature: TRpktLenMIN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:00.888\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 59, Feature Shape: (39060, 37)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:01.159\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.2697s, Score: 0.7787\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:01.160\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.013748741409216184 Max importance (19): 0.0026 (FlowIAT_MIN), Min importance (12): -0.0001 (TRbwdPktLenMEAN), Removed feature: TRbwdPktLenMEAN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:01.169\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 60, Feature Shape: (39060, 36)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:01.457\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.2878s, Score: 0.7845\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:01.458\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.01379374064108792 Max importance (3): 0.0032 (TotLenbwdDL), Min importance (8): -0.0001 (DLbwdPktLenMIN), Removed feature: DLbwdPktLenMIN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:01.464\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 61, Feature Shape: (39060, 35)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:01.736\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.2711s, Score: 0.6663\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:01.737\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 3.357446697795982e-05 Max importance (17): 0.0000 (FlowIAT_MIN), Min importance (6): -0.0000 (APPfwdPktLenMIN), Removed feature: APPfwdPktLenMIN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:01.743\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 62, Feature Shape: (39060, 34)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:02.073\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.3284s, Score: 0.7862\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:02.073\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.006418436162645612 Max importance (3): 0.0015 (TotLenbwdDL), Min importance (13): -0.0000 (APPbwdPktLenMEAN), Removed feature: APPbwdPktLenMEAN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:02.078\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 63, Feature Shape: (39060, 33)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:02.342\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.2625s, Score: 0.7410\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:02.343\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.009281768885921292 Max importance (15): 0.0024 (FlowIAT_MIN), Min importance (9): -0.0000 (TRbwdPktLenMIN), Removed feature: TRbwdPktLenMIN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:02.349\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 64, Feature Shape: (39060, 32)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:02.628\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.2780s, Score: 0.8167\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:02.629\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.015987893206167513 Max importance (3): 0.0033 (TotLenbwdDL), Min importance (22): -0.0000 (APPpktLenMIN), Removed feature: APPpktLenMIN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:02.634\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 65, Feature Shape: (39060, 31)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:02.914\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.2790s, Score: 0.7848\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:02.915\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.009213236433665383 Max importance (3): 0.0018 (TotLenbwdDL), Min importance (11): -0.0000 (APPbwdPktLenMIN), Removed feature: APPbwdPktLenMIN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:02.920\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 66, Feature Shape: (39060, 30)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:03.210\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.2884s, Score: 0.7847\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:03.211\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.020602358053395758 Max importance (3): 0.0046 (TotLenbwdDL), Min importance (24): -0.0000 (mostCommonREQ_FUNC_CODE), Removed feature: mostCommonREQ_FUNC_CODE\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:03.216\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 67, Feature Shape: (39060, 29)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:03.512\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.2946s, Score: 0.7577\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:03.513\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.007118948723459018 Max importance (13): 0.0019 (FlowIAT_MIN), Min importance (0): -0.0000 (duration), Removed feature: duration\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:03.519\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 68, Feature Shape: (39060, 28)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:03.892\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.3710s, Score: 0.8241\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:03.892\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.02144269350816076 Max importance (2): 0.0047 (TotLenbwdDL), Min importance (13): -0.0000 (TotalFwdIAT), Removed feature: TotalFwdIAT\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:03.897\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 69, Feature Shape: (39060, 27)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:04.205\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.3069s, Score: 0.7822\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:04.206\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.02271200254923725 Max importance (2): 0.0050 (TotLenbwdDL), Min importance (13): -0.0000 (TotalBwdIAT), Removed feature: TotalBwdIAT\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:04.210\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 70, Feature Shape: (39060, 26)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:04.571\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.3597s, Score: 0.7914\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:04.572\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.12929240323544894 Max importance (17): 0.1309 (APPbwdHdrLen), Min importance (15): -0.0887 (DLbwdHdrLen), Removed feature: DLbwdHdrLen\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:04.577\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 71, Feature Shape: (39060, 25)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:05.017\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.4392s, Score: 0.7840\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:05.018\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.06969953840368365 Max importance (16): 0.1301 (APPbwdHdrLen), Min importance (4): -0.0829 (TotLenbwdAPP), Removed feature: TotLenbwdAPP\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:05.022\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 72, Feature Shape: (39060, 24)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:05.381\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.3575s, Score: 0.7868\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:05.381\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.2206526490297233 Max importance (15): 0.2374 (APPbwdHdrLen), Min importance (12): -0.0511 (DLfwdHdrLen), Removed feature: DLfwdHdrLen\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:05.386\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 73, Feature Shape: (39060, 23)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:05.817\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.4291s, Score: 0.7884\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:05.818\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. -0.3426159483288624 Max importance (14): 0.1419 (APPbwdHdrLen), Min importance (16): -0.1087 (TotPktsInFlow), Removed feature: TotPktsInFlow\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:05.822\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 74, Feature Shape: (39060, 22)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:06.125\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.3019s, Score: 0.7888\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:06.126\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. -0.32580999050761233 Max importance (14): 0.1387 (APPbwdHdrLen), Min importance (21): -0.0830 (pktsFromSLAVE), Removed feature: pktsFromSLAVE\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:06.129\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 75, Feature Shape: (39060, 21)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:06.459\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.3283s, Score: 0.7877\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:06.460\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. -0.4049409688716927 Max importance (14): 0.1390 (APPbwdHdrLen), Min importance (0): -0.1056 (TotalFwdPkts), Removed feature: TotalFwdPkts\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:06.464\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 76, Feature Shape: (39060, 20)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:06.893\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.4282s, Score: 0.7878\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:06.894\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. -0.3568307224596661 Max importance (13): 0.2364 (APPbwdHdrLen), Min importance (11): -0.1723 (TRfwdHdrLen), Removed feature: TRfwdHdrLen\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:06.898\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 77, Feature Shape: (39060, 19)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:07.235\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.3353s, Score: 0.7900\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:07.236\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. -0.3895723422977492 Max importance (12): 0.1424 (APPbwdHdrLen), Min importance (0): -0.1633 (TotalBwdPkts), Removed feature: TotalBwdPkts\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:07.240\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 78, Feature Shape: (39060, 18)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:07.616\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.3759s, Score: 0.7863\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:07.617\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. -0.25177690145165577 Max importance (11): 0.2500 (APPbwdHdrLen), Min importance (10): -0.3087 (TRbwdHdrLen), Removed feature: TRbwdHdrLen\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:07.621\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 79, Feature Shape: (39060, 17)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:07.969\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.3475s, Score: 0.7877\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:07.970\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. -0.2751300747135704 Max importance (1): 0.1789 (TotLenbwdTR), Min importance (16): -0.3573 (pktsFromMASTER), Removed feature: pktsFromMASTER\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:07.973\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 80, Feature Shape: (39060, 16)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:08.345\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.3705s, Score: 0.7903\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:08.346\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.047048025393951545 Max importance (1): 0.4864 (TotLenbwdTR), Min importance (0): -0.4839 (TotLenbwdDL), Removed feature: TotLenbwdDL\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:08.349\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 81, Feature Shape: (39060, 15)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:08.661\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.3107s, Score: 0.7896\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:08.662\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. -0.20277274351093683 Max importance (5): 0.4108 (APPbwdPktLenMAX), Min importance (1): -0.2823 (DLbwdPktLenMAX), Removed feature: DLbwdPktLenMAX\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:08.665\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 82, Feature Shape: (39060, 14)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:09.080\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.4140s, Score: 0.7882\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:09.081\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. -0.11857387920451856 Max importance (4): 0.1622 (APPbwdPktLenMAX), Min importance (2): -0.0844 (TRbwdPktLenMAX), Removed feature: TRbwdPktLenMAX\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:09.083\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 83, Feature Shape: (39060, 13)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:09.359\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.2739s, Score: 0.7893\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:09.359\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. -0.05590433187478518 Max importance (3): 0.0696 (APPbwdPktLenMAX), Min importance (1): -0.0429 (DLbwdPktLenSTD), Removed feature: DLbwdPktLenSTD\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:09.362\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 84, Feature Shape: (39060, 12)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:09.631\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.2683s, Score: 0.7889\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:09.633\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. -0.06569081391833254 Max importance (2): 0.0736 (APPbwdPktLenMAX), Min importance (1): -0.0728 (TRbwdPktLenSTD), Removed feature: TRbwdPktLenSTD\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:09.636\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 85, Feature Shape: (39060, 11)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:09.967\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.3308s, Score: 0.7894\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:09.968\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. -0.0645313351707312 Max importance (1): 0.0702 (APPbwdPktLenMAX), Min importance (2): -0.1499 (APPbwdPktLenSTD), Removed feature: APPbwdPktLenSTD\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:09.971\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 86, Feature Shape: (39060, 10)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:10.267\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.2957s, Score: 0.7757\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:10.269\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.362524942130597 Max importance (5): 0.2127 (frameDst), Min importance (0): -0.0055 (TotLenbwdTR), Removed feature: TotLenbwdTR\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:10.272\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 87, Feature Shape: (39060, 9)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:10.549\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.2748s, Score: 0.8296\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:10.550\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.5854888555616792 Max importance (5): 0.5488 (firstPacketDIR), Min importance (4): -0.0082 (frameDst), Removed feature: frameDst\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:10.552\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 88, Feature Shape: (39060, 8)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:10.852\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.2985s, Score: 0.7962\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:10.853\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.10996741090240453 Max importance (4): 0.0732 (firstPacketDIR), Min importance (6): -0.0026 (deviceTroubleFragments), Removed feature: deviceTroubleFragments\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:10.855\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 89, Feature Shape: (39060, 7)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:11.137\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.2820s, Score: 0.8217\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:11.138\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.5995233610384519 Max importance (4): 0.5518 (firstPacketDIR), Min importance (5): 0.0000 (corruptConfigFragments), Removed feature: corruptConfigFragments\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:11.140\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 90, Feature Shape: (39060, 6)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:11.414\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.2724s, Score: 0.8578\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:11.415\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. -0.3382792276811586 Max importance (3): 0.0418 (APPbwdHdrLen), Min importance (4): -0.3898 (firstPacketDIR), Removed feature: firstPacketDIR\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:11.417\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 91, Feature Shape: (39060, 5)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:11.670\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.2523s, Score: 0.8367\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:11.670\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.05143864182511662 Max importance (3): 0.0387 (APPbwdHdrLen), Min importance (4): 0.0000 (deviceRestartFragments), Removed feature: deviceRestartFragments\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:11.672\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 92, Feature Shape: (39060, 4)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:11.930\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.2572s, Score: 0.8367\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:11.931\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.05143864182511662 Max importance (3): 0.0387 (APPbwdHdrLen), Min importance (1): 0.0003 (APPflowBytes/sec), Removed feature: APPflowBytes/sec\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:11.932\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 93, Feature Shape: (39060, 3)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:12.151\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.2178s, Score: 0.6903\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:12.152\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.0049220088752920214 Max importance (0): 0.0036 (APPbwdPktLenMAX), Min importance (1): 0.0004 (FlowIAT_MIN), Removed feature: FlowIAT_MIN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:12.153\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 94, Feature Shape: (39060, 2)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:12.214\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.0604s, Score: 0.6862\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:12.215\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.004472256677350182 Max importance (0): 0.0036 (APPbwdPktLenMAX), Min importance (1): 0.0008 (APPbwdHdrLen), Removed feature: APPbwdHdrLen\u001b[0m\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-18 18:31:12.412\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mTop 10 features: ['APPbwdPktLenMAX', 'APPbwdHdrLen', 'FlowIAT_MIN', 'APPflowBytes/sec', 'deviceRestartFragments', 'firstPacketDIR', 'corruptConfigFragments', 'deviceTroubleFragments', 'frameDst', 'TotLenbwdTR', 'APPbwdPktLenSTD']\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"sklearn\")\n",
    "\n",
    "# Initialize RFE\n",
    "rfe = RFE(\n",
    "    model=LogisticRegression(max_iter=100),\n",
    "    train_features=X_train,\n",
    "    train_labels=y_train,\n",
    "    test_features=X_test,\n",
    "    test_labels=y_test,\n",
    ")\n",
    "\n",
    "final_features = 1  # Target number of features\n",
    "curr_features = X_train.columns.tolist()\n",
    "\n",
    "for i in range(X_train.shape[1]):\n",
    "    res, curr_features = rfe.fit(feature_names=curr_features)\n",
    "    if len(curr_features) <= final_features:\n",
    "        break\n",
    "rfe.plot_results()\n",
    "logger.info(\n",
    "    f'Top 10 features: {curr_features + rfe.result[\"Removed Feature\"].tolist()[::-1][:10]}'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-18 18:31:13.418\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 0, Feature Shape: (39060, 96)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:14.344\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.9241s, Score: 0.9988\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:14.361\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000845921022 Max importance (50): 0.5226 (bwdIAT_MEAN), Min importance (2): 0.0000 (protocol), Removed feature: protocol\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:14.378\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 1, Feature Shape: (39060, 95)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:15.027\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.6474s, Score: 0.9988\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:15.029\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999815263436 Max importance (49): 0.5226 (bwdIAT_MEAN), Min importance (7): 0.0000 (TotLenfwdAPP), Removed feature: TotLenfwdAPP\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:15.046\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 2, Feature Shape: (39060, 94)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:15.673\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.6259s, Score: 0.9988\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:15.675\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000845921022 Max importance (48): 0.5226 (bwdIAT_MEAN), Min importance (8): 0.0000 (TotLenbwdTR), Removed feature: TotLenbwdTR\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:15.693\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 3, Feature Shape: (39060, 93)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:16.337\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.6424s, Score: 0.9988\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:16.338\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999815263436 Max importance (47): 0.5226 (bwdIAT_MEAN), Min importance (13): 0.0000 (TRfwdPktLenMAX), Removed feature: TRfwdPktLenMAX\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:16.368\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 4, Feature Shape: (39060, 92)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:17.004\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.6347s, Score: 0.9988\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:17.006\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999389019649 Max importance (46): 0.5226 (bwdIAT_MEAN), Min importance (13): 0.0000 (TRfwdPktLenMIN), Removed feature: TRfwdPktLenMIN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:17.030\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 5, Feature Shape: (39060, 91)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:17.667\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.6362s, Score: 0.9988\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:17.669\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999815263436 Max importance (45): 0.5226 (bwdIAT_MEAN), Min importance (13): 0.0000 (TRfwdPktLenMEAN), Removed feature: TRfwdPktLenMEAN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:17.685\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 6, Feature Shape: (39060, 90)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:18.351\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.6646s, Score: 0.9988\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:18.353\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999815263436 Max importance (44): 0.5226 (bwdIAT_MEAN), Min importance (13): 0.0000 (TRfwdPktLenSTD), Removed feature: TRfwdPktLenSTD\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:18.369\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 7, Feature Shape: (39060, 89)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:19.003\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.6323s, Score: 0.9988\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:19.005\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999389019649 Max importance (43): 0.5226 (bwdIAT_MEAN), Min importance (13): 0.0000 (APPfwdPktLenMAX), Removed feature: APPfwdPktLenMAX\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:19.022\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 8, Feature Shape: (39060, 88)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:19.693\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.6691s, Score: 0.9988\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:19.695\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999815263436 Max importance (42): 0.5226 (bwdIAT_MEAN), Min importance (13): 0.0000 (APPfwdPktLenMIN), Removed feature: APPfwdPktLenMIN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:19.713\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 9, Feature Shape: (39060, 87)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:20.313\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.5983s, Score: 0.9988\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:20.314\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999815263436 Max importance (41): 0.5226 (bwdIAT_MEAN), Min importance (13): 0.0000 (APPfwdPktLenMEAN), Removed feature: APPfwdPktLenMEAN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:20.330\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 10, Feature Shape: (39060, 86)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:20.942\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.6103s, Score: 0.9988\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:20.943\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000845921022 Max importance (40): 0.5226 (bwdIAT_MEAN), Min importance (13): 0.0000 (APPfwdPktLenSTD), Removed feature: APPfwdPktLenSTD\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:20.960\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 11, Feature Shape: (39060, 85)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:21.609\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.6475s, Score: 0.9988\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:21.611\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999815263436 Max importance (39): 0.5226 (bwdIAT_MEAN), Min importance (17): 0.0000 (TRbwdPktLenMAX), Removed feature: TRbwdPktLenMAX\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:21.629\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 12, Feature Shape: (39060, 84)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:22.238\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.6064s, Score: 0.9988\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:22.239\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999815263436 Max importance (38): 0.5226 (bwdIAT_MEAN), Min importance (17): 0.0000 (TRbwdPktLenMIN), Removed feature: TRbwdPktLenMIN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:22.254\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 13, Feature Shape: (39060, 83)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:22.863\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.6077s, Score: 0.9988\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:22.864\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999389019649 Max importance (37): 0.5226 (bwdIAT_MEAN), Min importance (17): 0.0000 (TRbwdPktLenMEAN), Removed feature: TRbwdPktLenMEAN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:22.880\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 14, Feature Shape: (39060, 82)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:23.451\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.5693s, Score: 0.9988\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:23.452\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000845921022 Max importance (36): 0.5226 (bwdIAT_MEAN), Min importance (17): 0.0000 (TRbwdPktLenSTD), Removed feature: TRbwdPktLenSTD\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:23.468\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 15, Feature Shape: (39060, 81)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:24.051\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.5817s, Score: 0.9988\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:24.053\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000845921022 Max importance (35): 0.5226 (bwdIAT_MEAN), Min importance (17): 0.0000 (APPbwdPktLenMAX), Removed feature: APPbwdPktLenMAX\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:24.069\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 16, Feature Shape: (39060, 80)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:24.648\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.5775s, Score: 0.9988\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:24.650\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000845921022 Max importance (34): 0.5226 (bwdIAT_MEAN), Min importance (17): 0.0000 (APPbwdPktLenMIN), Removed feature: APPbwdPktLenMIN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:24.664\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 17, Feature Shape: (39060, 79)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:25.237\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.5714s, Score: 0.9988\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:25.240\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000845921022 Max importance (33): 0.5226 (bwdIAT_MEAN), Min importance (18): 0.0000 (APPbwdPktLenSTD), Removed feature: APPbwdPktLenSTD\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:25.261\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 18, Feature Shape: (39060, 78)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:25.837\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.5744s, Score: 0.9988\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:25.839\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000845921022 Max importance (32): 0.5226 (bwdIAT_MEAN), Min importance (36): 0.0000 (DLfwdHdrLen), Removed feature: DLfwdHdrLen\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:25.853\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 19, Feature Shape: (39060, 77)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:26.393\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.5383s, Score: 0.9988\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:26.394\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000001567932486 Max importance (32): 0.5226 (bwdIAT_MEAN), Min importance (36): 0.0000 (TRfwdHdrLen), Removed feature: TRfwdHdrLen\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:26.410\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 20, Feature Shape: (39060, 76)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:26.943\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.5313s, Score: 0.9988\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:26.944\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999815263436 Max importance (32): 0.5226 (bwdIAT_MEAN), Min importance (37): 0.0000 (DLbwdHdrLen), Removed feature: DLbwdHdrLen\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:26.958\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 21, Feature Shape: (39060, 75)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:27.493\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.5334s, Score: 0.9988\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:27.495\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999815263436 Max importance (32): 0.5226 (bwdIAT_MEAN), Min importance (37): 0.0000 (TRbwdHdrLen), Removed feature: TRbwdHdrLen\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:27.507\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 22, Feature Shape: (39060, 74)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:28.038\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.5303s, Score: 0.9988\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:28.040\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000845921022 Max importance (32): 0.5226 (bwdIAT_MEAN), Min importance (44): 0.0000 (DLpktLenVAR), Removed feature: DLpktLenVAR\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:28.064\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 23, Feature Shape: (39060, 73)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:28.598\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.5328s, Score: 0.9988\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:28.599\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000845921022 Max importance (32): 0.5226 (bwdIAT_MEAN), Min importance (44): 0.0000 (TRpktLenMEAN), Removed feature: TRpktLenMEAN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:28.612\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 24, Feature Shape: (39060, 72)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:29.144\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.5307s, Score: 0.9988\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:29.146\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000845921022 Max importance (32): 0.5226 (bwdIAT_MEAN), Min importance (44): 0.0000 (TRpktLenMIN), Removed feature: TRpktLenMIN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:29.157\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 25, Feature Shape: (39060, 71)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:29.686\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.5276s, Score: 0.9988\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:29.687\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000845921022 Max importance (32): 0.5226 (bwdIAT_MEAN), Min importance (44): 0.0000 (TRpktLenMAX), Removed feature: TRpktLenMAX\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:29.702\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 26, Feature Shape: (39060, 70)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:30.224\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.5204s, Score: 0.9988\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:30.225\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000845921022 Max importance (32): 0.5226 (bwdIAT_MEAN), Min importance (44): 0.0000 (TRpktLenSTD), Removed feature: TRpktLenSTD\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:30.236\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 27, Feature Shape: (39060, 69)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:30.752\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.5148s, Score: 0.9988\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:30.754\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000845921022 Max importance (32): 0.5226 (bwdIAT_MEAN), Min importance (44): 0.0000 (TRpktLenVAR), Removed feature: TRpktLenVAR\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:30.767\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 28, Feature Shape: (39060, 68)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:31.287\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.5184s, Score: 0.9988\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:31.288\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999815263436 Max importance (32): 0.5226 (bwdIAT_MEAN), Min importance (45): 0.0000 (APPpktLenMIN), Removed feature: APPpktLenMIN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:31.302\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 29, Feature Shape: (39060, 67)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:31.821\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.5179s, Score: 0.9988\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:31.823\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999815263436 Max importance (32): 0.5226 (bwdIAT_MEAN), Min importance (45): 0.0000 (APPpktLenMAX), Removed feature: APPpktLenMAX\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:31.836\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 30, Feature Shape: (39060, 66)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:32.337\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.4998s, Score: 0.9988\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:32.339\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000845921022 Max importance (32): 0.5226 (bwdIAT_MEAN), Min importance (46): 0.0000 (APPpktLenVAR), Removed feature: APPpktLenVAR\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:32.352\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 31, Feature Shape: (39060, 65)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:32.846\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.4931s, Score: 0.9988\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:32.849\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000845921022 Max importance (32): 0.5226 (bwdIAT_MEAN), Min importance (57): 0.0000 (firstPacketDIR), Removed feature: firstPacketDIR\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:32.866\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 32, Feature Shape: (39060, 64)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:33.434\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.5605s, Score: 0.9988\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:33.436\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000845921022 Max importance (32): 0.5226 (bwdIAT_MEAN), Min importance (57): 0.0000 (mostCommonREQ_FUNC_CODE), Removed feature: mostCommonREQ_FUNC_CODE\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:33.447\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 33, Feature Shape: (39060, 63)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:33.932\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.4826s, Score: 0.9988\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:33.933\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000002014076017 Max importance (32): 0.5226 (bwdIAT_MEAN), Min importance (58): 0.0000 (corruptConfigFragments), Removed feature: corruptConfigFragments\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:33.946\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 34, Feature Shape: (39060, 62)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:34.425\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.4776s, Score: 0.9988\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:34.426\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000002014076017 Max importance (32): 0.5226 (bwdIAT_MEAN), Min importance (58): 0.0000 (deviceTroubleFragments), Removed feature: deviceTroubleFragments\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:34.437\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 35, Feature Shape: (39060, 61)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:34.915\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.4768s, Score: 0.9988\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:34.916\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000002014076017 Max importance (32): 0.5226 (bwdIAT_MEAN), Min importance (58): 0.0000 (deviceRestartFragments), Removed feature: deviceRestartFragments\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:34.928\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 36, Feature Shape: (39060, 60)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:35.415\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.4858s, Score: 0.9988\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:35.417\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000002014076017 Max importance (32): 0.5226 (bwdIAT_MEAN), Min importance (6): 0.0000 (TotLenfwdTR), Removed feature: TotLenfwdTR\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:35.427\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 37, Feature Shape: (39060, 59)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:35.926\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.4980s, Score: 0.9987\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:35.928\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999683350325 Max importance (31): 0.5135 (bwdIAT_MEAN), Min importance (14): 0.0000 (DLbwdPktLenMEAN), Removed feature: DLbwdPktLenMEAN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:35.940\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 38, Feature Shape: (39060, 58)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:36.400\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.4580s, Score: 0.9987\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:36.402\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.999999972707883 Max importance (30): 0.5162 (bwdIAT_MEAN), Min importance (15): 0.0000 (APPbwdPktLenMEAN), Removed feature: APPbwdPktLenMEAN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:36.411\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 39, Feature Shape: (39060, 57)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:36.904\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.4912s, Score: 0.9988\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:36.906\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999771034709 Max importance (29): 0.5590 (bwdIAT_MEAN), Min importance (42): 0.0000 (APPpktLenSTD), Removed feature: APPpktLenSTD\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:36.917\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 40, Feature Shape: (39060, 56)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:37.412\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.4927s, Score: 0.9988\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:37.413\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999771034709 Max importance (29): 0.5590 (bwdIAT_MEAN), Min importance (41): 0.0000 (APPpktLenMEAN), Removed feature: APPpktLenMEAN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:37.425\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 41, Feature Shape: (39060, 55)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:37.897\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.4697s, Score: 0.9988\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:37.899\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000267282303 Max importance (29): 0.5419 (bwdIAT_MEAN), Min importance (42): 0.0001 (ActiveSTD), Removed feature: ActiveSTD\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:37.912\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 42, Feature Shape: (39060, 54)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:38.358\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.4443s, Score: 0.9988\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:38.360\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000633881427 Max importance (29): 0.5711 (bwdIAT_MEAN), Min importance (50): 0.0001 (TotPktsInFlow), Removed feature: TotPktsInFlow\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:38.370\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 43, Feature Shape: (39060, 53)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:38.784\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.4127s, Score: 0.9990\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:38.785\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000001611515472 Max importance (29): 0.5034 (bwdIAT_MEAN), Min importance (12): 0.0001 (DLbwdPktLenMAX), Removed feature: DLbwdPktLenMAX\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:38.796\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 44, Feature Shape: (39060, 52)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:39.298\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.5011s, Score: 0.9988\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:39.300\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.000000091677066 Max importance (28): 0.5197 (bwdIAT_MEAN), Min importance (47): 0.0001 (frameSrc), Removed feature: frameSrc\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:39.312\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 45, Feature Shape: (39060, 51)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:39.760\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.4455s, Score: 0.9987\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:39.761\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999326901161 Max importance (28): 0.5286 (bwdIAT_MEAN), Min importance (33): 0.0001 (APPbwdHdrLen), Removed feature: APPbwdHdrLen\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:39.772\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 46, Feature Shape: (39060, 50)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:40.191\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.4180s, Score: 0.9986\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:40.193\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000828731572 Max importance (28): 0.5130 (bwdIAT_MEAN), Min importance (35): 0.0002 (DLpktLenMEAN), Removed feature: DLpktLenMEAN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:40.201\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 47, Feature Shape: (39060, 49)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:40.628\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.4254s, Score: 0.9988\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:40.630\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.000000143678335 Max importance (28): 0.5009 (bwdIAT_MEAN), Min importance (35): 0.0000 (DLpktLenMIN), Removed feature: DLpktLenMIN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:40.640\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 48, Feature Shape: (39060, 48)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:41.049\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.4079s, Score: 0.9988\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:41.051\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.00000002780871 Max importance (28): 0.5009 (bwdIAT_MEAN), Min importance (41): 0.0000 (IdleSTD), Removed feature: IdleSTD\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:41.060\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 49, Feature Shape: (39060, 47)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:41.482\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.4206s, Score: 0.9988\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:41.483\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000397267286 Max importance (28): 0.4931 (bwdIAT_MEAN), Min importance (32): 0.0001 (APPfwdHdrLen), Removed feature: APPfwdHdrLen\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:41.493\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 50, Feature Shape: (39060, 46)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:41.902\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.4079s, Score: 0.9988\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:41.903\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000311556505 Max importance (28): 0.5025 (bwdIAT_MEAN), Min importance (34): 0.0002 (DLpktLenMAX), Removed feature: DLpktLenMAX\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:41.912\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 51, Feature Shape: (39060, 45)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:42.308\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.3939s, Score: 0.9989\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:42.309\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000917825673 Max importance (28): 0.5562 (bwdIAT_MEAN), Min importance (3): 0.0000 (TotalFwdPkts), Removed feature: TotalFwdPkts\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:42.317\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 52, Feature Shape: (39060, 44)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:42.697\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.3780s, Score: 0.9988\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:42.698\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000928412192 Max importance (27): 0.5416 (bwdIAT_MEAN), Min importance (15): 0.0002 (APPflowBytes/sec), Removed feature: APPflowBytes/sec\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:42.708\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 53, Feature Shape: (39060, 43)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:43.091\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.3819s, Score: 0.9989\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:43.092\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.999999984371243 Max importance (26): 0.5652 (bwdIAT_MEAN), Min importance (4): 0.0002 (TotLenfwdDL), Removed feature: TotLenfwdDL\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:43.101\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 54, Feature Shape: (39060, 42)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:43.465\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.3626s, Score: 0.9988\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:43.466\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999552819645 Max importance (25): 0.5907 (bwdIAT_MEAN), Min importance (6): 0.0000 (DLfwdPktLenMAX), Removed feature: DLfwdPktLenMAX\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:43.474\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 55, Feature Shape: (39060, 41)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:43.839\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.3630s, Score: 0.9988\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:43.840\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000909349183 Max importance (24): 0.5513 (bwdIAT_MEAN), Min importance (32): 0.0002 (ActiveMAX), Removed feature: ActiveMAX\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:43.848\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 56, Feature Shape: (39060, 40)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:44.215\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.3650s, Score: 0.9987\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:44.216\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000394356903 Max importance (24): 0.5483 (bwdIAT_MEAN), Min importance (15): 0.0002 (FlowIAT_STD), Removed feature: FlowIAT_STD\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:44.223\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 57, Feature Shape: (39060, 39)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:44.558\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.3334s, Score: 0.9988\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:44.559\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999511928763 Max importance (23): 0.4683 (bwdIAT_MEAN), Min importance (5): 0.0002 (TotLenbwdAPP), Removed feature: TotLenbwdAPP\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:44.567\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 58, Feature Shape: (39060, 38)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:44.912\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.3440s, Score: 0.9991\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:44.914\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000440923031 Max importance (22): 0.4726 (bwdIAT_MEAN), Min importance (11): 0.0002 (TRflowBytes/sec), Removed feature: TRflowBytes/sec\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:44.923\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 59, Feature Shape: (39060, 37)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:45.255\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.3302s, Score: 0.9987\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:45.256\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.999999991938239 Max importance (21): 0.5186 (bwdIAT_MEAN), Min importance (2): 0.0003 (duration), Removed feature: duration\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:45.262\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 60, Feature Shape: (39060, 36)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:45.577\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.3134s, Score: 0.9989\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:45.578\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.000000019586878 Max importance (20): 0.5159 (bwdIAT_MEAN), Min importance (0): 0.0003 (source port), Removed feature: source port\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:45.585\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 61, Feature Shape: (39060, 35)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:45.904\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.3181s, Score: 0.9989\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:45.906\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000142026693 Max importance (19): 0.5175 (bwdIAT_MEAN), Min importance (23): 0.0002 (fwdPkts/sec), Removed feature: fwdPkts/sec\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:45.913\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 62, Feature Shape: (39060, 34)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:46.226\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.3119s, Score: 0.9988\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:46.228\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000001081207301 Max importance (19): 0.5228 (bwdIAT_MEAN), Min importance (23): 0.0004 (bwdPkts/sec), Removed feature: bwdPkts/sec\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:46.233\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 63, Feature Shape: (39060, 33)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:46.529\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.2942s, Score: 0.9987\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:46.530\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999315477908 Max importance (19): 0.5394 (bwdIAT_MEAN), Min importance (8): 0.0004 (DLflowBytes/sec), Removed feature: DLflowBytes/sec\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:46.538\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 64, Feature Shape: (39060, 32)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:46.838\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.2990s, Score: 0.9988\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:46.839\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.999999957595719 Max importance (18): 0.5059 (bwdIAT_MEAN), Min importance (23): 0.0004 (ActiveMEAN), Removed feature: ActiveMEAN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:46.846\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 65, Feature Shape: (39060, 31)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:47.141\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.2930s, Score: 0.9988\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:47.143\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000618747436 Max importance (18): 0.5485 (bwdIAT_MEAN), Min importance (9): 0.0004 (FlowIAT_MEAN), Removed feature: FlowIAT_MEAN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:47.149\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 66, Feature Shape: (39060, 30)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:47.435\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.2840s, Score: 0.9988\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:47.436\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999064020813 Max importance (17): 0.5148 (bwdIAT_MEAN), Min importance (13): 0.0005 (fwdIAT_STD), Removed feature: fwdIAT_STD\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:47.443\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 67, Feature Shape: (39060, 29)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:47.722\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.2780s, Score: 0.9988\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:47.724\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.00000012118835 Max importance (16): 0.4900 (bwdIAT_MEAN), Min importance (17): 0.0006 (bwdIAT_STD), Removed feature: bwdIAT_STD\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:47.731\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 68, Feature Shape: (39060, 28)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:48.004\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.2722s, Score: 0.9988\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:48.006\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.000000047206413 Max importance (16): 0.4725 (bwdIAT_MEAN), Min importance (23): 0.0006 (IdleMIN), Removed feature: IdleMIN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:48.011\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 69, Feature Shape: (39060, 27)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:48.267\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.2539s, Score: 0.9987\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:48.268\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000001422013156 Max importance (16): 0.4879 (bwdIAT_MEAN), Min importance (14): 0.0006 (fwdIAT_MIN), Removed feature: fwdIAT_MIN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:48.273\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 70, Feature Shape: (39060, 26)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:48.517\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.2431s, Score: 0.9985\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:48.518\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000001052976586 Max importance (15): 0.5183 (bwdIAT_MEAN), Min importance (21): 0.0003 (IdleMAX), Removed feature: IdleMAX\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:48.524\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 71, Feature Shape: (39060, 25)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:48.768\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.2420s, Score: 0.9982\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:48.769\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000935979187 Max importance (15): 0.4831 (bwdIAT_MEAN), Min importance (12): 0.0005 (fwdIAT_MEAN), Removed feature: fwdIAT_MEAN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:48.775\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 72, Feature Shape: (39060, 24)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:49.009\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.2326s, Score: 0.9983\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:49.010\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000348663889 Max importance (14): 0.4821 (bwdIAT_MEAN), Min importance (16): 0.0007 (bwdIAT_MIN), Removed feature: bwdIAT_MIN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:49.015\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 73, Feature Shape: (39060, 23)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:49.239\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.2222s, Score: 0.9979\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:49.241\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000002253218554 Max importance (6): 0.4536 (DLbwdPktLenMIN), Min importance (22): 0.0006 (pktsFromSLAVE), Removed feature: pktsFromSLAVE\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:49.245\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 74, Feature Shape: (39060, 22)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:49.460\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.2128s, Score: 0.9981\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:49.461\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000388245098 Max importance (14): 0.4755 (bwdIAT_MEAN), Min importance (19): 0.0007 (frameDst), Removed feature: frameDst\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:49.465\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 75, Feature Shape: (39060, 21)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:49.678\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.2115s, Score: 0.9980\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:49.680\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999540159479 Max importance (14): 0.4773 (bwdIAT_MEAN), Min importance (18): 0.0008 (IdleMEAN), Removed feature: IdleMEAN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:49.684\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 76, Feature Shape: (39060, 20)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:49.895\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.2093s, Score: 0.9984\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:49.896\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000174622983 Max importance (14): 0.4541 (bwdIAT_MEAN), Min importance (4): 0.0007 (DLfwdPktLenMEAN), Removed feature: DLfwdPktLenMEAN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:49.901\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 77, Feature Shape: (39060, 19)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:50.107\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.2049s, Score: 0.9978\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:50.109\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999922583811 Max importance (5): 0.4682 (DLbwdPktLenMIN), Min importance (17): 0.0010 (mostCommonRESP_FUNC_CODE), Removed feature: mostCommonRESP_FUNC_CODE\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:50.113\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 78, Feature Shape: (39060, 18)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:50.312\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.1974s, Score: 0.9978\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:50.313\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000334111974 Max importance (5): 0.4921 (DLbwdPktLenMIN), Min importance (14): 0.0010 (bwdIAT_MAX), Removed feature: bwdIAT_MAX\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:50.317\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 79, Feature Shape: (39060, 17)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:50.504\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.1858s, Score: 0.9980\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:50.505\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000018626451 Max importance (5): 0.4940 (DLbwdPktLenMIN), Min importance (14): 0.0013 (DLpktLenSTD), Removed feature: DLpktLenSTD\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:50.509\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 80, Feature Shape: (39060, 16)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:50.692\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.1817s, Score: 0.9981\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:50.693\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999998994171619 Max importance (5): 0.4655 (DLbwdPktLenMIN), Min importance (4): 0.0017 (DLfwdPktLenSTD), Removed feature: DLfwdPktLenSTD\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:50.698\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 81, Feature Shape: (39060, 15)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:50.881\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.1814s, Score: 0.9979\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:50.882\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000115251169 Max importance (4): 0.4786 (DLbwdPktLenMIN), Min importance (5): 0.0018 (DLbwdPktLenSTD), Removed feature: DLbwdPktLenSTD\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:50.886\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 82, Feature Shape: (39060, 14)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:51.063\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.1756s, Score: 0.9978\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:51.065\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999674037099 Max importance (4): 0.4855 (DLbwdPktLenMIN), Min importance (0): 0.0018 (destination port), Removed feature: destination port\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:51.068\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 83, Feature Shape: (39060, 13)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:51.240\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.1710s, Score: 0.9978\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:51.242\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.000000010477379 Max importance (3): 0.5306 (DLbwdPktLenMIN), Min importance (4): 0.0020 (FlowPkts/sec), Removed feature: FlowPkts/sec\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:51.245\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 84, Feature Shape: (39060, 12)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:51.410\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.1629s, Score: 0.9978\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:51.411\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999998721759766 Max importance (3): 0.5716 (DLbwdPktLenMIN), Min importance (10): 0.0031 (ActiveMIN), Removed feature: ActiveMIN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:51.414\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 85, Feature Shape: (39060, 11)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:51.578\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.1627s, Score: 0.9973\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:51.580\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999676365405 Max importance (3): 0.5775 (DLbwdPktLenMIN), Min importance (7): 0.0030 (fwdIAT_MAX), Removed feature: fwdIAT_MAX\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:51.584\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 86, Feature Shape: (39060, 10)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:51.740\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.1548s, Score: 0.9972\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:51.741\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999799765646 Max importance (3): 0.5860 (DLbwdPktLenMIN), Min importance (0): 0.0047 (TotalBwdPkts), Removed feature: TotalBwdPkts\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:51.744\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 87, Feature Shape: (39060, 9)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:51.897\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.1509s, Score: 0.9972\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:51.899\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.999999915715307 Max importance (2): 0.5484 (DLbwdPktLenMIN), Min importance (4): 0.0070 (FlowIAT_MIN), Removed feature: FlowIAT_MIN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:51.901\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 88, Feature Shape: (39060, 8)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:52.040\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.1375s, Score: 0.9938\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:52.042\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999208375812 Max importance (2): 0.5137 (DLbwdPktLenMIN), Min importance (4): 0.0116 (TotalFwdIAT), Removed feature: TotalFwdIAT\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:52.044\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 89, Feature Shape: (39060, 7)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:52.181\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.1346s, Score: 0.9939\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:52.182\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999776482582 Max importance (2): 0.6250 (DLbwdPktLenMIN), Min importance (0): 0.0083 (TotLenbwdDL), Removed feature: TotLenbwdDL\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:52.184\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 90, Feature Shape: (39060, 6)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:52.321\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.1353s, Score: 0.9935\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:52.322\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.000000013038516 Max importance (1): 0.6261 (DLbwdPktLenMIN), Min importance (0): 0.0114 (DLfwdPktLenMIN), Removed feature: DLfwdPktLenMIN\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:52.325\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 91, Feature Shape: (39060, 5)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:52.454\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.1280s, Score: 0.9934\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:52.456\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999720603228 Max importance (0): 0.4728 (DLbwdPktLenMIN), Min importance (4): 0.0254 (pktsFromMASTER), Removed feature: pktsFromMASTER\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:52.458\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 92, Feature Shape: (39060, 4)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:52.574\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.1151s, Score: 0.9925\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:52.575\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000335276127 Max importance (0): 0.5691 (DLbwdPktLenMIN), Min importance (1): 0.0418 (FlowIAT_MAX), Removed feature: FlowIAT_MAX\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:52.577\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 93, Feature Shape: (39060, 3)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:52.684\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.1052s, Score: 0.9906\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:52.685\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 1.0000000223517418 Max importance (0): 0.5649 (DLbwdPktLenMIN), Min importance (1): 0.0657 (TotalBwdIAT), Removed feature: TotalBwdIAT\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:52.687\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mStep: 94, Feature Shape: (39060, 2)\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:52.787\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mTraining time: 0.0991s, Score: 0.9879\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:52.789\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSum Imp. 0.9999999701976776 Max importance (0): 0.7056 (DLbwdPktLenMIN), Min importance (1): 0.2944 (bwdIAT_MEAN), Removed feature: bwdIAT_MEAN\u001b[0m\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-18 18:31:53.084\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mTop 10 features: ['DLbwdPktLenMIN', 'bwdIAT_MEAN', 'TotalBwdIAT', 'FlowIAT_MAX', 'pktsFromMASTER', 'DLfwdPktLenMIN', 'TotLenbwdDL', 'TotalFwdIAT', 'FlowIAT_MIN', 'TotalBwdPkts', 'fwdIAT_MAX']\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# XGB\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "rfe = RFE(\n",
    "    model=XGBClassifier(),\n",
    "    train_features=X_train,\n",
    "    train_labels=y_train,\n",
    "    test_features=X_test,\n",
    "    test_labels=y_test,\n",
    ")\n",
    "\n",
    "final_features = 1  # Target number of features\n",
    "curr_features = X_train.columns.tolist()\n",
    "\n",
    "for i in range(X_train.shape[1]):\n",
    "    res, curr_features = rfe.fit(feature_names=curr_features)\n",
    "    if len(curr_features) <= final_features:\n",
    "        break\n",
    "rfe.plot_results()\n",
    "logger.info(\n",
    "    f'Top 10 features: {curr_features + rfe.result[\"Removed Feature\"].tolist()[::-1][:10]}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-18 18:31:53.188\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m39\u001b[0m - \u001b[1mTraining RandomForestClassifier\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:58.233\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mRandomForestClassifier Accuracy: 0.9982334869431644\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:58.234\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m39\u001b[0m - \u001b[1mTraining DecisionTreeClassifier\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:59.017\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mDecisionTreeClassifier Accuracy: 0.9971582181259601\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:59.018\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m39\u001b[0m - \u001b[1mTraining LogisticRegression\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:59.741\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mLogisticRegression Accuracy: 0.9802611367127496\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:59.742\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m39\u001b[0m - \u001b[1mTraining GaussianNB\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:59.849\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mGaussianNB Accuracy: 0.629416282642089\u001b[0m\n",
      "\u001b[32m2025-05-18 18:31:59.850\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m39\u001b[0m - \u001b[1mTraining XGBClassifier\u001b[0m\n",
      "\u001b[32m2025-05-18 18:32:00.618\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mXGBClassifier Accuracy: 0.998694316436252\u001b[0m\n",
      "\u001b[32m2025-05-18 18:32:00.620\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mResults:\u001b[0m\n",
      "\u001b[32m2025-05-18 18:32:00.620\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m73\u001b[0m - \u001b[1mRandomForestClassifier Accuracy: 0.9982334869431644\u001b[0m\n",
      "\u001b[32m2025-05-18 18:32:00.621\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mF1 Score: 0.9982334869327436\u001b[0m\n",
      "\u001b[32m2025-05-18 18:32:00.621\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mPrecision: 0.998233498699472\u001b[0m\n",
      "\u001b[32m2025-05-18 18:32:00.622\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mRecall: 0.9982334869431644\u001b[0m\n",
      "\u001b[32m2025-05-18 18:32:00.622\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1mConfusion Matrix:\n",
      "[[6498   12]\n",
      " [  11 6499]]\u001b[0m\n",
      "\u001b[32m2025-05-18 18:32:00.623\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m73\u001b[0m - \u001b[1mDecisionTreeClassifier Accuracy: 0.9971582181259601\u001b[0m\n",
      "\u001b[32m2025-05-18 18:32:00.623\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mF1 Score: 0.9971582181091962\u001b[0m\n",
      "\u001b[32m2025-05-18 18:32:00.624\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mPrecision: 0.9971582298568957\u001b[0m\n",
      "\u001b[32m2025-05-18 18:32:00.624\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mRecall: 0.9971582181259601\u001b[0m\n",
      "\u001b[32m2025-05-18 18:32:00.624\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1mConfusion Matrix:\n",
      "[[6491   19]\n",
      " [  18 6492]]\u001b[0m\n",
      "\u001b[32m2025-05-18 18:32:00.625\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m73\u001b[0m - \u001b[1mLogisticRegression Accuracy: 0.9802611367127496\u001b[0m\n",
      "\u001b[32m2025-05-18 18:32:00.625\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mF1 Score: 0.9802586202517517\u001b[0m\n",
      "\u001b[32m2025-05-18 18:32:00.626\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mPrecision: 0.9805061398433669\u001b[0m\n",
      "\u001b[32m2025-05-18 18:32:00.626\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mRecall: 0.9802611367127496\u001b[0m\n",
      "\u001b[32m2025-05-18 18:32:00.627\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1mConfusion Matrix:\n",
      "[[6455   55]\n",
      " [ 202 6308]]\u001b[0m\n",
      "\u001b[32m2025-05-18 18:32:00.627\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m73\u001b[0m - \u001b[1mGaussianNB Accuracy: 0.629416282642089\u001b[0m\n",
      "\u001b[32m2025-05-18 18:32:00.628\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mF1 Score: 0.5759552266391283\u001b[0m\n",
      "\u001b[32m2025-05-18 18:32:00.629\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mPrecision: 0.7610759030465151\u001b[0m\n",
      "\u001b[32m2025-05-18 18:32:00.629\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mRecall: 0.629416282642089\u001b[0m\n",
      "\u001b[32m2025-05-18 18:32:00.630\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1mConfusion Matrix:\n",
      "[[6409  101]\n",
      " [4724 1786]]\u001b[0m\n",
      "\u001b[32m2025-05-18 18:32:00.631\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m73\u001b[0m - \u001b[1mXGBClassifier Accuracy: 0.998694316436252\u001b[0m\n",
      "\u001b[32m2025-05-18 18:32:00.631\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mF1 Score: 0.998694316366932\u001b[0m\n",
      "\u001b[32m2025-05-18 18:32:00.632\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mPrecision: 0.9986944223409053\u001b[0m\n",
      "\u001b[32m2025-05-18 18:32:00.632\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mRecall: 0.998694316436252\u001b[0m\n",
      "\u001b[32m2025-05-18 18:32:00.633\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1mConfusion Matrix:\n",
      "[[6500   10]\n",
      " [   7 6503]]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "# scaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# need RF, LR, DT, GNB and XGB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "class SKClassifiers:\n",
    "    def __init__(\n",
    "        self,\n",
    "        models: list[BaseEstimator],\n",
    "        train_features: pd.DataFrame,\n",
    "        train_labels: pd.Series,\n",
    "        test_features: pd.DataFrame,\n",
    "        test_labels: pd.Series,\n",
    "    ):\n",
    "\n",
    "        self.models = models\n",
    "        self.train_features = train_features\n",
    "        self.train_labels = train_labels\n",
    "        self.test_features = test_features\n",
    "        self.test_labels = test_labels\n",
    "        self.results = {}\n",
    "        self.scaler = MinMaxScaler()\n",
    "        self.scaler.fit(self.train_features)\n",
    "        self.train_features = self.scaler.transform(self.train_features)\n",
    "        self.test_features = self.scaler.transform(self.test_features)\n",
    "\n",
    "    def fit(self):\n",
    "        for model in self.models:\n",
    "            model_name = type(model).__name__\n",
    "            logger.info(f\"Training {model_name}\")\n",
    "            model.fit(self.train_features, self.train_labels)\n",
    "            y_pred = model.predict(self.test_features)\n",
    "            accuracy = accuracy_score(self.test_labels, y_pred)\n",
    "            report = classification_report(self.test_labels, y_pred, output_dict=True)\n",
    "            self.results[model_name] = {\n",
    "                \"accuracy\": accuracy,\n",
    "                \"report\": report,\n",
    "                \"confusion_matrix\": confusion_matrix(self.test_labels, y_pred),\n",
    "                \"f1_score\": report[\"weighted avg\"][\"f1-score\"],\n",
    "                \"precision\": report[\"weighted avg\"][\"precision\"],\n",
    "                \"recall\": report[\"weighted avg\"][\"recall\"],\n",
    "            }\n",
    "            logger.info(f\"{model_name} Accuracy: {accuracy}\")\n",
    "        return self.results\n",
    "\n",
    "\n",
    "clfs = [\n",
    "    RandomForestClassifier(max_depth=15, n_estimators=100),\n",
    "    DecisionTreeClassifier(max_depth=15),\n",
    "    LogisticRegression(max_iter=1000),\n",
    "    GaussianNB(),\n",
    "    XGBClassifier(max_depth=15, n_estimators=100),\n",
    "]\n",
    "clf = SKClassifiers(\n",
    "    models=clfs,\n",
    "    train_features=X_train,\n",
    "    train_labels=y_train,\n",
    "    test_features=X_test,\n",
    "    test_labels=y_test,\n",
    ")\n",
    "results = clf.fit()\n",
    "logger.info(\"Results:\")\n",
    "for model_name, result in results.items():\n",
    "    logger.info(f\"{model_name} Accuracy: {result['accuracy']}\")\n",
    "    logger.info(f\"F1 Score: {result['f1_score']}\")\n",
    "    logger.info(f\"Precision: {result['precision']}\")\n",
    "    logger.info(f\"Recall: {result['recall']}\")\n",
    "    logger.info(f\"Confusion Matrix:\\n{result['confusion_matrix']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attacking and Defending DNP3 ICS/SCADA Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-18 22:51:17.318\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mData root: E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:17.351\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m31\u001b[0m - \u001b[1mFound 71 files in E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:17.353\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200508_DNP3_Disable_Unsolicited_Messages_Attack_UOWM_DNP3_Dataset_Slave_05.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:17.927\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200514_Disable_Unsolicited_Messages_Attack_UOWM_DNP3_Dataset_Attacker_01.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:17.972\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200514_Disable_Unsolicited_Messages_Attack_UOWM_DNP3_Dataset_Attacker_02.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:18.027\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200514_Disable_Unsolicited_Messages_Attack_UOWM_DNP3_Dataset_Attacker_03.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:18.072\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200514_Disable_Unsolicited_Messages_Attack_UOWM_DNP3_Dataset_Master.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:18.108\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200514_Disable_Unsolicited_Messages_Attack_UOWM_DNP3_Dataset_Slave_01.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:18.148\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200514_Disable_Unsolicited_Messages_Attack_UOWM_DNP3_Dataset_Slave_02.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:18.171\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200514_Disable_Unsolicited_Messages_Attack_UOWM_DNP3_Dataset_Slave_03.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:18.191\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200514_Disable_Unsolicited_Messages_Attack_UOWM_DNP3_Dataset_Slave_06.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:18.213\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200514_DNP3_Disable_Unsolicited_Messages_Attack_UOWM_DNP3_Dataset_Slave_04.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:18.238\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200514_DNP3_Disable_Unsolicited_Messages_Attack_UOWM_DNP3_Dataset_Slave_07.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:18.259\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200514_DNP3_Disable_Unsolicited_Messages_Attack_UOWM_DNP3_Dataset_Slave_08.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:18.313\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200515_Cold_Restart_Attack_UOWM_DNP3_Dataset_Slave_01.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:18.336\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200515_Cold_Restart_Attack_UOWM_DNP3_Dataset_Slave_02.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:18.356\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200515_Cold_Restart_Attack_UOWM_DNP3_Dataset_Slave_03.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:18.441\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200515_DNP3_Cold_Restart_Attack_UOWM_DNP3_Dataset_Attacker_01.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:18.474\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200515_DNP3_Cold_Restart_Attack_UOWM_DNP3_Dataset_Attacker_02.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:18.506\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200515_DNP3_Cold_Restart_Attack_UOWM_DNP3_Dataset_Attacker_03.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:18.566\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200515_DNP3_Cold_Restart_Attack_UOWM_DNP3_Dataset_Master.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:18.603\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200515_DNP3_Cold_Restart_Attack_UOWM_DNP3_Dataset_Slave_04.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:18.625\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200515_DNP3_Cold_Restart_Attack_UOWM_DNP3_Dataset_Slave_05.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:18.645\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200515_DNP3_Cold_Restart_Attack_UOWM_DNP3_Dataset_Slave_06.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:18.666\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200515_DNP3_Cold_Restart_Attack_UOWM_DNP3_Dataset_Slave_07.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:18.717\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200515_DNP3_Cold_Restart_Attack_UOWM_DNP3_Dataset_Slave_08.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:18.746\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200515_DNP3_Warm_Restart_Attack_UOWM_DNP3_Dataset_Attacker_01.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:18.822\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200515_DNP3_Warm_Restart_Attack_UOWM_DNP3_Dataset_Attacker_03.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:18.856\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200515_DNP3_Warm_Restart_Attack_UOWM_DNP3_Dataset_Master.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:18.891\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200515_DNP3_Warm_Restart_Attack_UOWM_DNP3_Dataset_Slave_01.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:18.934\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200515_DNP3_Warm_Restart_Attack_UOWM_DNP3_Dataset_Slave_02.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:18.955\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200515_DNP3_Warm_Restart_Attack_UOWM_DNP3_Dataset_Slave_03.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:18.975\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200515_DNP3_Warm_Restart_Attack_UOWM_DNP3_Dataset_Slave_04.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:18.995\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200515_DNP3_Warm_Restart_Attack_UOWM_DNP3_Dataset_Slave_05.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:19.014\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200515_DNP3_Warm_Restart_Attack_UOWM_DNP3_Dataset_Slave_06.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:19.051\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200515_DNP3_Warm_Restart_Attack_UOWM_DNP3_Dataset_Slave_07.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:19.069\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200515_DNP3_Warm_Restart_Attack_UOWM_DNP3_Dataset_Slave_08.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:19.091\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200515_Warm_Restart_Attack_UOWM_DNP3_Dataset_Attacker_02.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:19.127\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200516_DNP3_Enumerate_UOWM_DNP3_Dataset_Attacker_01.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:19.157\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200516_DNP3_Enumerate_UOWM_DNP3_Dataset_Attacker_02.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:19.182\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200516_DNP3_Enumerate_UOWM_DNP3_Dataset_Attacker_03.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:19.202\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200516_DNP3_Enumerate_UOWM_DNP3_Dataset_Master.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:19.363\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200516_DNP3_Enumerate_UOWM_DNP3_Dataset_Slave_01.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:19.403\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200516_DNP3_Enumerate_UOWM_DNP3_Dataset_Slave_02.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:19.437\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200516_DNP3_Enumerate_UOWM_DNP3_Dataset_Slave_03.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:19.477\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200516_DNP3_info_UOWM_DNP3_Dataset_Attacker_01.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:19.497\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200516_DNP3_info_UOWM_DNP3_Dataset_Attacker_02.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:19.518\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200516_DNP3_info_UOWM_DNP3_Dataset_Attacker_03.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:19.536\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200516_DNP3_info_UOWM_DNP3_Dataset_Master.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:19.585\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200516_DNP3_info_UOWM_DNP3_Dataset_Slave_01.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:19.619\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200516_DNP3_info_UOWM_DNP3_Dataset_Slave_02.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:19.672\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200516_DNP3_info_UOWM_DNP3_Dataset_Slave_03.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:19.709\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200518_Initialize_Data_Attack_UOWM_DNP3_Dataset_Attacker_01.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:19.745\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200518_Initialize_Data_Attack_UOWM_DNP3_Dataset_Attacker_02.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:19.764\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200518_Initialize_Data_Attack_UOWM_DNP3_Dataset_Attacker_03.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:19.783\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200518_Initialize_Data_Attack_UOWM_DNP3_Dataset_Master.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:19.803\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200518_Initialize_Data_Attack_UOWM_DNP3_Dataset_Slave_01.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:19.841\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200518_Initialize_Data_Attack_UOWM_DNP3_Dataset_Slave_02.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:19.869\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200518_Initialize_Data_Attack_UOWM_DNP3_Dataset_Slave_03.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:19.899\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200518_Replay_UOWM_DNP3_Dataset_Attacker_01.pcapDNP3_FLOWLABELEDLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:19.918\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200518_Replay_UOWM_DNP3_Dataset_Attacker_02.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:19.945\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200518_Replay_UOWM_DNP3_Dataset_Attacker_03.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:19.972\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200518_Replay_UOWM_DNP3_Dataset_Master.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:19.999\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200518_Replay_UOWM_DNP3_Dataset_Slave_01.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:20.083\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200518_Replay_UOWM_DNP3_Dataset_Slave_02.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:20.116\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200518_Replay_UOWM_DNP3_Dataset_Slave_03.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:20.132\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200519_Stop_Application_Attack_UOWM_DNP3_Dataset_Attacker_01.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:20.147\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200519_Stop_Application_Attack_UOWM_DNP3_Dataset_Attacker_02.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:20.163\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200519_Stop_Application_Attack_UOWM_DNP3_Dataset_Attacker_03.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:20.186\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200519_Stop_Application_Attack_UOWM_DNP3_Dataset_Master.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:20.202\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200519_Stop_Application_Attack_UOWM_DNP3_Dataset_Slave_01.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:20.216\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200519_Stop_Application_Attack_UOWM_DNP3_Dataset_Slave_02.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:20.232\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_files\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\\20200519_Stop_Application_Attack_UOWM_DNP3_Dataset_Slave_03.pcapDNP3_FLOWLABELED.csv\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:20.452\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m33\u001b[0m - \u001b[1mCombined DataFrame shape: (40420, 103)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from loguru import logger\n",
    "\n",
    "\n",
    "def load_csv_files(all_files: list[Path]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load all CSV files into a single DataFrame.\n",
    "    \"\"\"\n",
    "    if len(all_files) == 0:\n",
    "        logger.warning(\"No CSV files found.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    dataframes = []\n",
    "    for file in all_files:\n",
    "        logger.info(f\"Loading {file}\")\n",
    "        df = pd.read_csv(file, low_memory=False)\n",
    "        if \"Label\" in df.columns:\n",
    "            if \"No Label\" in df[\"Label\"].unique():\n",
    "                del df[\"Label\"]\n",
    "\n",
    "        df.columns = [c.strip() for c in df.columns]\n",
    "        dataframes.append(df)\n",
    "    combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "    return combined_df\n",
    "\n",
    "\n",
    "data_root = Path(r\"E:\\MSc Works\\IDS\\data\\Custom_DNP3_Parser\")\n",
    "logger.info(f\"Data root: {data_root}\")\n",
    "all_files = list(data_root.glob(\"*.csv\"))\n",
    "logger.info(f\"Found {len(all_files)} files in {data_root}\")\n",
    "combined_df = load_csv_files(all_files)\n",
    "logger.info(f\"Combined DataFrame shape: {combined_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_columns = [\n",
    "    \"File\",\n",
    "    \"flow ID\",\n",
    "    \"binary_label\",\n",
    "    \"Timestamp\",\n",
    "    \"source IP\",\n",
    "    \"destination IP\",\n",
    "    \"date\",\n",
    "    \"Unnamed: 0\",\n",
    "    \"Unnamed: 0.1\",\n",
    "    \"firstPacketDIR\",\n",
    "]\n",
    "combined_df = combined_df[[c for c in combined_df.columns if c not in ignore_columns]]\n",
    "# combined_df.firstPacketDIR = combined_df[\"firstPacketDIR\"].apply(\n",
    "#     lambda x: 1 if x == \"MASTER\" else 0\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversample_class(df: pd.DataFrame, label: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Oversample the specified class in the DataFrame.\n",
    "    \"\"\"\n",
    "    logger.info(f\"Before oversampling: {df[label].value_counts()}\")\n",
    "    label_counts = df[label].value_counts()\n",
    "    max_count = label_counts.max()\n",
    "    for lbl in label_counts.index:\n",
    "        count = label_counts[lbl]\n",
    "        if count < max_count:\n",
    "            needed = max_count - count\n",
    "            logger.info(f\"Label {lbl} needs {needed} samples\")\n",
    "            oversample_df = df[df[label] == lbl].sample(needed, replace=True)\n",
    "            df = pd.concat([df, oversample_df], ignore_index=True)\n",
    "\n",
    "    # Shuffle the DataFrame\n",
    "    df = df.sample(frac=1, random_state=42, replace=False).reset_index(drop=True)\n",
    "    logger.info(f\"After oversampling: {df[label].value_counts()}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def undersample_class(df: pd.DataFrame, label: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Undersample the specified class in the DataFrame.\n",
    "    \"\"\"\n",
    "    logger.info(f\"Before undersampling: {df[label].value_counts()}\")\n",
    "    label_counts = df[label].value_counts()\n",
    "    min_count = label_counts.min()\n",
    "    for lbl in label_counts.index:\n",
    "        count = label_counts[lbl]\n",
    "        if count > min_count:\n",
    "            needed = count - min_count\n",
    "            logger.info(f\"Label {lbl} needs to be reduced by {needed} samples\")\n",
    "            undersample_df = df[df[label] == lbl].sample(needed, replace=False)\n",
    "            df = df.drop(undersample_df.index)\n",
    "\n",
    "    # Shuffle the DataFrame\n",
    "    df = df.sample(frac=1, random_state=42, replace=False).reset_index(drop=True)\n",
    "    logger.info(f\"After undersampling: {df[label].value_counts()}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-18 22:51:21.106\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mTraining RandomForestClassifier\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:30.040\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m48\u001b[0m - \u001b[1mRandomForestClassifier Accuracy: 0.964745175655616\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:30.041\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m49\u001b[0m - \u001b[1mRandomForestClassifier F1 Score: 0.9648139539363886\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:30.042\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mTraining DecisionTreeClassifier\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:30.981\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m48\u001b[0m - \u001b[1mDecisionTreeClassifier Accuracy: 0.9745175655616032\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:30.982\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m49\u001b[0m - \u001b[1mDecisionTreeClassifier F1 Score: 0.9745238553739216\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:30.982\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mTraining KNeighborsClassifier\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:32.100\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m48\u001b[0m - \u001b[1mKNeighborsClassifier Accuracy: 0.9716724393864423\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:32.101\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m49\u001b[0m - \u001b[1mKNeighborsClassifier F1 Score: 0.971965316743756\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:32.102\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mTraining GaussianNB\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:32.305\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m48\u001b[0m - \u001b[1mGaussianNB Accuracy: 0.5754576942107867\u001b[0m\n",
      "\u001b[32m2025-05-18 22:51:32.306\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m49\u001b[0m - \u001b[1mGaussianNB F1 Score: 0.5571054437046411\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# DT, DNN, KNN, NB, RF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "# scaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "RF = RandomForestClassifier(random_state=42)\n",
    "DT = DecisionTreeClassifier(random_state=42)\n",
    "KNN = KNeighborsClassifier()\n",
    "NB = GaussianNB()\n",
    "models = [RF, DT, KNN, NB]\n",
    "\n",
    "# shuffle the data\n",
    "ddf = combined_df.copy().sample(frac=1.0, random_state=42, replace=False)\n",
    "\n",
    "X = ddf.drop(\"Label\", axis=1).values\n",
    "y = ddf[\"Label\"]\n",
    "\n",
    "# Normalization to [0,1] range\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# sclaer\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# fit\n",
    "for model in models:\n",
    "    model_name = type(model).__name__\n",
    "    logger.info(f\"Training {model_name}\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "    logger.info(f\"{model_name} Accuracy: {accuracy}\")\n",
    "    logger.info(f\"{model_name} F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\MSc Works\\IDS\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m937/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5056 - loss: 1.2828\n",
      "Epoch 1: val_loss improved from inf to 0.43895, saving model to dnp3_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.5074 - loss: 1.2768 - val_accuracy: 0.7590 - val_loss: 0.4389\n",
      "Epoch 2/1000\n",
      "\u001b[1m935/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7561 - loss: 0.4310\n",
      "Epoch 2: val_loss improved from 0.43895 to 0.39104, saving model to dnp3_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7562 - loss: 0.4309 - val_accuracy: 0.7818 - val_loss: 0.3910\n",
      "Epoch 3/1000\n",
      "\u001b[1m934/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7758 - loss: 0.3927\n",
      "Epoch 3: val_loss improved from 0.39104 to 0.35837, saving model to dnp3_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7759 - loss: 0.3926 - val_accuracy: 0.8005 - val_loss: 0.3584\n",
      "Epoch 4/1000\n",
      "\u001b[1m929/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7910 - loss: 0.3667\n",
      "Epoch 4: val_loss did not improve from 0.35837\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7910 - loss: 0.3667 - val_accuracy: 0.7928 - val_loss: 0.3633\n",
      "Epoch 5/1000\n",
      "\u001b[1m929/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7906 - loss: 0.3662\n",
      "Epoch 5: val_loss improved from 0.35837 to 0.33888, saving model to dnp3_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7907 - loss: 0.3661 - val_accuracy: 0.7948 - val_loss: 0.3389\n",
      "Epoch 6/1000\n",
      "\u001b[1m940/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7987 - loss: 0.3563\n",
      "Epoch 6: val_loss did not improve from 0.33888\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7987 - loss: 0.3562 - val_accuracy: 0.8139 - val_loss: 0.3499\n",
      "Epoch 7/1000\n",
      "\u001b[1m930/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8037 - loss: 0.3489\n",
      "Epoch 7: val_loss did not improve from 0.33888\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8037 - loss: 0.3490 - val_accuracy: 0.8199 - val_loss: 0.3397\n",
      "Epoch 8/1000\n",
      "\u001b[1m931/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8029 - loss: 0.3473\n",
      "Epoch 8: val_loss did not improve from 0.33888\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8028 - loss: 0.3473 - val_accuracy: 0.7189 - val_loss: 0.5305\n",
      "Epoch 9/1000\n",
      "\u001b[1m930/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8002 - loss: 0.3544\n",
      "Epoch 9: val_loss improved from 0.33888 to 0.33850, saving model to dnp3_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8003 - loss: 0.3543 - val_accuracy: 0.8168 - val_loss: 0.3385\n",
      "Epoch 10/1000\n",
      "\u001b[1m943/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8047 - loss: 0.3439\n",
      "Epoch 10: val_loss improved from 0.33850 to 0.33685, saving model to dnp3_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8047 - loss: 0.3439 - val_accuracy: 0.7941 - val_loss: 0.3369\n",
      "Epoch 11/1000\n",
      "\u001b[1m942/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8142 - loss: 0.3378\n",
      "Epoch 11: val_loss improved from 0.33685 to 0.32784, saving model to dnp3_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8141 - loss: 0.3378 - val_accuracy: 0.8234 - val_loss: 0.3278\n",
      "Epoch 12/1000\n",
      "\u001b[1m934/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8172 - loss: 0.3322\n",
      "Epoch 12: val_loss improved from 0.32784 to 0.32102, saving model to dnp3_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8172 - loss: 0.3323 - val_accuracy: 0.8323 - val_loss: 0.3210\n",
      "Epoch 13/1000\n",
      "\u001b[1m944/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8141 - loss: 0.3331\n",
      "Epoch 13: val_loss improved from 0.32102 to 0.32007, saving model to dnp3_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8141 - loss: 0.3331 - val_accuracy: 0.8332 - val_loss: 0.3201\n",
      "Epoch 14/1000\n",
      "\u001b[1m938/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8276 - loss: 0.3245\n",
      "Epoch 14: val_loss improved from 0.32007 to 0.30181, saving model to dnp3_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8276 - loss: 0.3245 - val_accuracy: 0.8467 - val_loss: 0.3018\n",
      "Epoch 15/1000\n",
      "\u001b[1m937/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8299 - loss: 0.3171\n",
      "Epoch 15: val_loss did not improve from 0.30181\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8299 - loss: 0.3171 - val_accuracy: 0.8366 - val_loss: 0.3162\n",
      "Epoch 16/1000\n",
      "\u001b[1m947/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8357 - loss: 0.3091\n",
      "Epoch 16: val_loss improved from 0.30181 to 0.28883, saving model to dnp3_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8357 - loss: 0.3091 - val_accuracy: 0.8439 - val_loss: 0.2888\n",
      "Epoch 17/1000\n",
      "\u001b[1m930/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8372 - loss: 0.3034\n",
      "Epoch 17: val_loss did not improve from 0.28883\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8372 - loss: 0.3033 - val_accuracy: 0.8526 - val_loss: 0.2934\n",
      "Epoch 18/1000\n",
      "\u001b[1m934/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8427 - loss: 0.2990\n",
      "Epoch 18: val_loss did not improve from 0.28883\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8427 - loss: 0.2991 - val_accuracy: 0.8447 - val_loss: 0.2929\n",
      "Epoch 19/1000\n",
      "\u001b[1m927/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8425 - loss: 0.2977\n",
      "Epoch 19: val_loss did not improve from 0.28883\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8424 - loss: 0.2977 - val_accuracy: 0.8402 - val_loss: 0.2996\n",
      "Epoch 20/1000\n",
      "\u001b[1m946/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8398 - loss: 0.2996\n",
      "Epoch 20: val_loss improved from 0.28883 to 0.28625, saving model to dnp3_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8398 - loss: 0.2996 - val_accuracy: 0.8538 - val_loss: 0.2862\n",
      "Epoch 21/1000\n",
      "\u001b[1m947/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8448 - loss: 0.2921\n",
      "Epoch 21: val_loss improved from 0.28625 to 0.28601, saving model to dnp3_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8448 - loss: 0.2921 - val_accuracy: 0.8683 - val_loss: 0.2860\n",
      "Epoch 22/1000\n",
      "\u001b[1m945/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8480 - loss: 0.2898\n",
      "Epoch 22: val_loss did not improve from 0.28601\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8480 - loss: 0.2898 - val_accuracy: 0.8419 - val_loss: 0.2895\n",
      "Epoch 23/1000\n",
      "\u001b[1m940/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.2883\n",
      "Epoch 23: val_loss improved from 0.28601 to 0.27986, saving model to dnp3_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.2883 - val_accuracy: 0.8510 - val_loss: 0.2799\n",
      "Epoch 24/1000\n",
      "\u001b[1m945/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.2839\n",
      "Epoch 24: val_loss did not improve from 0.27986\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8438 - loss: 0.2839 - val_accuracy: 0.8316 - val_loss: 0.3181\n",
      "Epoch 25/1000\n",
      "\u001b[1m933/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8470 - loss: 0.2862\n",
      "Epoch 25: val_loss improved from 0.27986 to 0.27130, saving model to dnp3_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8470 - loss: 0.2861 - val_accuracy: 0.8574 - val_loss: 0.2713\n",
      "Epoch 26/1000\n",
      "\u001b[1m930/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8520 - loss: 0.2772\n",
      "Epoch 26: val_loss improved from 0.27130 to 0.26991, saving model to dnp3_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8519 - loss: 0.2773 - val_accuracy: 0.8566 - val_loss: 0.2699\n",
      "Epoch 27/1000\n",
      "\u001b[1m936/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8506 - loss: 0.2795\n",
      "Epoch 27: val_loss did not improve from 0.26991\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8506 - loss: 0.2795 - val_accuracy: 0.8567 - val_loss: 0.2835\n",
      "Epoch 28/1000\n",
      "\u001b[1m942/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8531 - loss: 0.2735\n",
      "Epoch 28: val_loss did not improve from 0.26991\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8531 - loss: 0.2734 - val_accuracy: 0.8505 - val_loss: 0.2804\n",
      "Epoch 29/1000\n",
      "\u001b[1m939/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8611 - loss: 0.2691\n",
      "Epoch 29: val_loss improved from 0.26991 to 0.25091, saving model to dnp3_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8611 - loss: 0.2691 - val_accuracy: 0.8638 - val_loss: 0.2509\n",
      "Epoch 30/1000\n",
      "\u001b[1m941/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8586 - loss: 0.2680\n",
      "Epoch 30: val_loss did not improve from 0.25091\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8586 - loss: 0.2680 - val_accuracy: 0.8397 - val_loss: 0.2815\n",
      "Epoch 31/1000\n",
      "\u001b[1m940/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8634 - loss: 0.2634\n",
      "Epoch 31: val_loss did not improve from 0.25091\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8634 - loss: 0.2634 - val_accuracy: 0.8629 - val_loss: 0.2644\n",
      "Epoch 32/1000\n",
      "\u001b[1m935/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8598 - loss: 0.2661\n",
      "Epoch 32: val_loss did not improve from 0.25091\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8599 - loss: 0.2660 - val_accuracy: 0.8448 - val_loss: 0.2740\n",
      "Epoch 33/1000\n",
      "\u001b[1m944/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8624 - loss: 0.2602\n",
      "Epoch 33: val_loss improved from 0.25091 to 0.24643, saving model to dnp3_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8624 - loss: 0.2602 - val_accuracy: 0.8823 - val_loss: 0.2464\n",
      "Epoch 34/1000\n",
      "\u001b[1m941/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8691 - loss: 0.2493\n",
      "Epoch 34: val_loss improved from 0.24643 to 0.23702, saving model to dnp3_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8692 - loss: 0.2493 - val_accuracy: 0.8762 - val_loss: 0.2370\n",
      "Epoch 35/1000\n",
      "\u001b[1m942/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8680 - loss: 0.2449\n",
      "Epoch 35: val_loss did not improve from 0.23702\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8680 - loss: 0.2450 - val_accuracy: 0.8693 - val_loss: 0.2404\n",
      "Epoch 36/1000\n",
      "\u001b[1m946/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8753 - loss: 0.2365\n",
      "Epoch 36: val_loss did not improve from 0.23702\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8753 - loss: 0.2365 - val_accuracy: 0.8692 - val_loss: 0.2639\n",
      "Epoch 37/1000\n",
      "\u001b[1m947/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8725 - loss: 0.2413\n",
      "Epoch 37: val_loss improved from 0.23702 to 0.22896, saving model to dnp3_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8725 - loss: 0.2413 - val_accuracy: 0.8721 - val_loss: 0.2290\n",
      "Epoch 38/1000\n",
      "\u001b[1m945/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8769 - loss: 0.2307\n",
      "Epoch 38: val_loss improved from 0.22896 to 0.22240, saving model to dnp3_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8769 - loss: 0.2307 - val_accuracy: 0.8788 - val_loss: 0.2224\n",
      "Epoch 39/1000\n",
      "\u001b[1m947/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8781 - loss: 0.2323\n",
      "Epoch 39: val_loss did not improve from 0.22240\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8781 - loss: 0.2323 - val_accuracy: 0.8864 - val_loss: 0.2295\n",
      "Epoch 40/1000\n",
      "\u001b[1m930/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8835 - loss: 0.2165\n",
      "Epoch 40: val_loss improved from 0.22240 to 0.21579, saving model to dnp3_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8835 - loss: 0.2166 - val_accuracy: 0.8841 - val_loss: 0.2158\n",
      "Epoch 41/1000\n",
      "\u001b[1m938/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8844 - loss: 0.2222\n",
      "Epoch 41: val_loss did not improve from 0.21579\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8844 - loss: 0.2222 - val_accuracy: 0.8864 - val_loss: 0.2197\n",
      "Epoch 42/1000\n",
      "\u001b[1m931/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8861 - loss: 0.2153\n",
      "Epoch 42: val_loss improved from 0.21579 to 0.19272, saving model to dnp3_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8861 - loss: 0.2152 - val_accuracy: 0.8983 - val_loss: 0.1927\n",
      "Epoch 43/1000\n",
      "\u001b[1m940/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8916 - loss: 0.2037\n",
      "Epoch 43: val_loss did not improve from 0.19272\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8916 - loss: 0.2037 - val_accuracy: 0.8931 - val_loss: 0.2068\n",
      "Epoch 44/1000\n",
      "\u001b[1m932/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8955 - loss: 0.2020\n",
      "Epoch 44: val_loss did not improve from 0.19272\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8955 - loss: 0.2019 - val_accuracy: 0.8842 - val_loss: 0.2129\n",
      "Epoch 45/1000\n",
      "\u001b[1m944/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8982 - loss: 0.1964\n",
      "Epoch 45: val_loss improved from 0.19272 to 0.18928, saving model to dnp3_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8982 - loss: 0.1964 - val_accuracy: 0.9034 - val_loss: 0.1893\n",
      "Epoch 46/1000\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9011 - loss: 0.1939\n",
      "Epoch 46: val_loss improved from 0.18928 to 0.18341, saving model to dnp3_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9011 - loss: 0.1939 - val_accuracy: 0.9055 - val_loss: 0.1834\n",
      "Epoch 47/1000\n",
      "\u001b[1m930/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8943 - loss: 0.2029\n",
      "Epoch 47: val_loss did not improve from 0.18341\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8944 - loss: 0.2027 - val_accuracy: 0.8980 - val_loss: 0.2018\n",
      "Epoch 48/1000\n",
      "\u001b[1m933/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9085 - loss: 0.1829\n",
      "Epoch 48: val_loss did not improve from 0.18341\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9085 - loss: 0.1829 - val_accuracy: 0.9037 - val_loss: 0.1854\n",
      "Epoch 49/1000\n",
      "\u001b[1m939/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9097 - loss: 0.1768\n",
      "Epoch 49: val_loss did not improve from 0.18341\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9097 - loss: 0.1768 - val_accuracy: 0.9068 - val_loss: 0.1887\n",
      "Epoch 50/1000\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9156 - loss: 0.1756\n",
      "Epoch 50: val_loss did not improve from 0.18341\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9156 - loss: 0.1756 - val_accuracy: 0.9065 - val_loss: 0.1973\n",
      "Epoch 51/1000\n",
      "\u001b[1m944/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9114 - loss: 0.1764\n",
      "Epoch 51: val_loss improved from 0.18341 to 0.17454, saving model to dnp3_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9114 - loss: 0.1764 - val_accuracy: 0.8952 - val_loss: 0.1745\n",
      "Epoch 52/1000\n",
      "\u001b[1m936/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9175 - loss: 0.1711\n",
      "Epoch 52: val_loss did not improve from 0.17454\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9175 - loss: 0.1711 - val_accuracy: 0.9029 - val_loss: 0.1763\n",
      "Epoch 53/1000\n",
      "\u001b[1m935/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9199 - loss: 0.1631\n",
      "Epoch 53: val_loss improved from 0.17454 to 0.15623, saving model to dnp3_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9199 - loss: 0.1631 - val_accuracy: 0.9297 - val_loss: 0.1562\n",
      "Epoch 54/1000\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9209 - loss: 0.1591\n",
      "Epoch 54: val_loss did not improve from 0.15623\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9209 - loss: 0.1591 - val_accuracy: 0.9218 - val_loss: 0.1639\n",
      "Epoch 55/1000\n",
      "\u001b[1m933/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9275 - loss: 0.1535\n",
      "Epoch 55: val_loss did not improve from 0.15623\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9274 - loss: 0.1536 - val_accuracy: 0.9213 - val_loss: 0.1604\n",
      "Epoch 56/1000\n",
      "\u001b[1m943/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9237 - loss: 0.1553\n",
      "Epoch 56: val_loss did not improve from 0.15623\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9237 - loss: 0.1553 - val_accuracy: 0.9046 - val_loss: 0.2051\n",
      "Epoch 57/1000\n",
      "\u001b[1m940/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9255 - loss: 0.1513\n",
      "Epoch 57: val_loss improved from 0.15623 to 0.15305, saving model to dnp3_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9255 - loss: 0.1513 - val_accuracy: 0.9287 - val_loss: 0.1531\n",
      "Epoch 58/1000\n",
      "\u001b[1m944/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9212 - loss: 0.1612\n",
      "Epoch 58: val_loss improved from 0.15305 to 0.15169, saving model to dnp3_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9212 - loss: 0.1612 - val_accuracy: 0.9278 - val_loss: 0.1517\n",
      "Epoch 59/1000\n",
      "\u001b[1m942/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9253 - loss: 0.1538\n",
      "Epoch 59: val_loss did not improve from 0.15169\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9253 - loss: 0.1539 - val_accuracy: 0.9304 - val_loss: 0.1620\n",
      "Epoch 60/1000\n",
      "\u001b[1m943/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9209 - loss: 0.1657\n",
      "Epoch 60: val_loss did not improve from 0.15169\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9209 - loss: 0.1656 - val_accuracy: 0.9067 - val_loss: 0.2445\n",
      "Epoch 61/1000\n",
      "\u001b[1m945/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9284 - loss: 0.1474\n",
      "Epoch 61: val_loss improved from 0.15169 to 0.13209, saving model to dnp3_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9284 - loss: 0.1474 - val_accuracy: 0.9319 - val_loss: 0.1321\n",
      "Epoch 62/1000\n",
      "\u001b[1m937/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9292 - loss: 0.1462\n",
      "Epoch 62: val_loss did not improve from 0.13209\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9292 - loss: 0.1463 - val_accuracy: 0.9269 - val_loss: 0.1594\n",
      "Epoch 63/1000\n",
      "\u001b[1m946/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9357 - loss: 0.1367\n",
      "Epoch 63: val_loss did not improve from 0.13209\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9357 - loss: 0.1367 - val_accuracy: 0.9296 - val_loss: 0.1354\n",
      "Epoch 64/1000\n",
      "\u001b[1m937/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9294 - loss: 0.1436\n",
      "Epoch 64: val_loss did not improve from 0.13209\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9294 - loss: 0.1435 - val_accuracy: 0.9257 - val_loss: 0.1485\n",
      "Epoch 65/1000\n",
      "\u001b[1m929/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9328 - loss: 0.1393\n",
      "Epoch 65: val_loss improved from 0.13209 to 0.12595, saving model to dnp3_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9328 - loss: 0.1392 - val_accuracy: 0.9434 - val_loss: 0.1259\n",
      "Epoch 66/1000\n",
      "\u001b[1m931/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9434 - loss: 0.1229\n",
      "Epoch 66: val_loss did not improve from 0.12595\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9434 - loss: 0.1229 - val_accuracy: 0.9385 - val_loss: 0.1287\n",
      "Epoch 67/1000\n",
      "\u001b[1m933/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9421 - loss: 0.1232\n",
      "Epoch 67: val_loss did not improve from 0.12595\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9421 - loss: 0.1232 - val_accuracy: 0.9110 - val_loss: 0.1959\n",
      "Epoch 68/1000\n",
      "\u001b[1m928/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9412 - loss: 0.1237\n",
      "Epoch 68: val_loss improved from 0.12595 to 0.11407, saving model to dnp3_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9413 - loss: 0.1236 - val_accuracy: 0.9485 - val_loss: 0.1141\n",
      "Epoch 69/1000\n",
      "\u001b[1m941/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9431 - loss: 0.1213\n",
      "Epoch 69: val_loss did not improve from 0.11407\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9431 - loss: 0.1212 - val_accuracy: 0.9356 - val_loss: 0.1375\n",
      "Epoch 70/1000\n",
      "\u001b[1m941/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9447 - loss: 0.1200\n",
      "Epoch 70: val_loss did not improve from 0.11407\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9447 - loss: 0.1200 - val_accuracy: 0.9199 - val_loss: 0.1709\n",
      "Epoch 71/1000\n",
      "\u001b[1m947/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9493 - loss: 0.1131\n",
      "Epoch 71: val_loss did not improve from 0.11407\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9493 - loss: 0.1131 - val_accuracy: 0.9399 - val_loss: 0.1196\n",
      "Epoch 72/1000\n",
      "\u001b[1m939/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9477 - loss: 0.1128\n",
      "Epoch 72: val_loss did not improve from 0.11407\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9478 - loss: 0.1128 - val_accuracy: 0.9377 - val_loss: 0.1257\n",
      "Epoch 73/1000\n",
      "\u001b[1m944/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9458 - loss: 0.1205\n",
      "Epoch 73: val_loss improved from 0.11407 to 0.10301, saving model to dnp3_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9458 - loss: 0.1205 - val_accuracy: 0.9516 - val_loss: 0.1030\n",
      "Epoch 74/1000\n",
      "\u001b[1m935/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9504 - loss: 0.1118\n",
      "Epoch 74: val_loss did not improve from 0.10301\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9504 - loss: 0.1119 - val_accuracy: 0.8748 - val_loss: 0.2907\n",
      "Epoch 75/1000\n",
      "\u001b[1m925/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9485 - loss: 0.1122\n",
      "Epoch 75: val_loss did not improve from 0.10301\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9486 - loss: 0.1120 - val_accuracy: 0.9469 - val_loss: 0.1085\n",
      "Epoch 76/1000\n",
      "\u001b[1m947/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9524 - loss: 0.1015\n",
      "Epoch 76: val_loss did not improve from 0.10301\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9524 - loss: 0.1015 - val_accuracy: 0.9511 - val_loss: 0.1102\n",
      "Epoch 77/1000\n",
      "\u001b[1m938/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9521 - loss: 0.1124\n",
      "Epoch 77: val_loss improved from 0.10301 to 0.10210, saving model to dnp3_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9521 - loss: 0.1124 - val_accuracy: 0.9570 - val_loss: 0.1021\n",
      "Epoch 78/1000\n",
      "\u001b[1m935/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9459 - loss: 0.1192\n",
      "Epoch 78: val_loss did not improve from 0.10210\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9460 - loss: 0.1190 - val_accuracy: 0.9597 - val_loss: 0.1061\n",
      "Epoch 79/1000\n",
      "\u001b[1m938/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9531 - loss: 0.1040\n",
      "Epoch 79: val_loss did not improve from 0.10210\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9531 - loss: 0.1040 - val_accuracy: 0.9543 - val_loss: 0.1070\n",
      "Epoch 80/1000\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9530 - loss: 0.1014\n",
      "Epoch 80: val_loss did not improve from 0.10210\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9530 - loss: 0.1014 - val_accuracy: 0.9439 - val_loss: 0.1282\n",
      "Epoch 81/1000\n",
      "\u001b[1m934/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9548 - loss: 0.0964\n",
      "Epoch 81: val_loss did not improve from 0.10210\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9548 - loss: 0.0965 - val_accuracy: 0.9555 - val_loss: 0.1034\n",
      "Epoch 82/1000\n",
      "\u001b[1m946/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9544 - loss: 0.1019\n",
      "Epoch 82: val_loss did not improve from 0.10210\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9544 - loss: 0.1019 - val_accuracy: 0.9470 - val_loss: 0.1084\n",
      "Epoch 83/1000\n",
      "\u001b[1m936/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9570 - loss: 0.0982\n",
      "Epoch 83: val_loss improved from 0.10210 to 0.09641, saving model to dnp3_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9569 - loss: 0.0982 - val_accuracy: 0.9564 - val_loss: 0.0964\n",
      "Epoch 84/1000\n",
      "\u001b[1m945/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9554 - loss: 0.0990\n",
      "Epoch 84: val_loss did not improve from 0.09641\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9554 - loss: 0.0990 - val_accuracy: 0.9539 - val_loss: 0.1045\n",
      "Epoch 85/1000\n",
      "\u001b[1m933/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9603 - loss: 0.0939\n",
      "Epoch 85: val_loss did not improve from 0.09641\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9602 - loss: 0.0939 - val_accuracy: 0.8898 - val_loss: 0.3030\n",
      "Epoch 86/1000\n",
      "\u001b[1m927/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9523 - loss: 0.1017\n",
      "Epoch 86: val_loss did not improve from 0.09641\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9524 - loss: 0.1017 - val_accuracy: 0.9393 - val_loss: 0.1410\n",
      "Epoch 87/1000\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9429 - loss: 0.1530\n",
      "Epoch 87: val_loss improved from 0.09641 to 0.09266, saving model to dnp3_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9429 - loss: 0.1530 - val_accuracy: 0.9646 - val_loss: 0.0927\n",
      "Epoch 88/1000\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9559 - loss: 0.0989\n",
      "Epoch 88: val_loss did not improve from 0.09266\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9559 - loss: 0.0989 - val_accuracy: 0.9455 - val_loss: 0.1328\n",
      "Epoch 89/1000\n",
      "\u001b[1m937/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9531 - loss: 0.0988\n",
      "Epoch 89: val_loss did not improve from 0.09266\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9531 - loss: 0.0988 - val_accuracy: 0.9483 - val_loss: 0.1460\n",
      "Epoch 90/1000\n",
      "\u001b[1m924/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9578 - loss: 0.0971\n",
      "Epoch 90: val_loss did not improve from 0.09266\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9577 - loss: 0.0974 - val_accuracy: 0.9487 - val_loss: 0.1100\n",
      "Epoch 91/1000\n",
      "\u001b[1m931/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9574 - loss: 0.0925\n",
      "Epoch 91: val_loss did not improve from 0.09266\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9574 - loss: 0.0925 - val_accuracy: 0.9344 - val_loss: 0.1675\n",
      "Epoch 92/1000\n",
      "\u001b[1m931/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9538 - loss: 0.1040\n",
      "Epoch 92: val_loss did not improve from 0.09266\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9539 - loss: 0.1039 - val_accuracy: 0.9590 - val_loss: 0.0933\n",
      "Epoch 93/1000\n",
      "\u001b[1m928/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9572 - loss: 0.0963\n",
      "Epoch 93: val_loss did not improve from 0.09266\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9572 - loss: 0.0963 - val_accuracy: 0.9556 - val_loss: 0.0940\n",
      "Epoch 94/1000\n",
      "\u001b[1m931/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9484 - loss: 0.1329\n",
      "Epoch 94: val_loss did not improve from 0.09266\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9485 - loss: 0.1323 - val_accuracy: 0.9572 - val_loss: 0.1016\n",
      "Epoch 95/1000\n",
      "\u001b[1m931/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9535 - loss: 0.1044\n",
      "Epoch 95: val_loss improved from 0.09266 to 0.08613, saving model to dnp3_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9535 - loss: 0.1044 - val_accuracy: 0.9637 - val_loss: 0.0861\n",
      "Epoch 96/1000\n",
      "\u001b[1m931/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9612 - loss: 0.0864\n",
      "Epoch 96: val_loss did not improve from 0.08613\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9611 - loss: 0.0865 - val_accuracy: 0.9541 - val_loss: 0.1006\n",
      "Epoch 97/1000\n",
      "\u001b[1m940/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9564 - loss: 0.0963\n",
      "Epoch 97: val_loss did not improve from 0.08613\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9565 - loss: 0.0963 - val_accuracy: 0.9579 - val_loss: 0.0956\n",
      "Epoch 98/1000\n",
      "\u001b[1m943/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9572 - loss: 0.0951\n",
      "Epoch 98: val_loss did not improve from 0.08613\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9572 - loss: 0.0951 - val_accuracy: 0.9599 - val_loss: 0.0892\n",
      "Epoch 99/1000\n",
      "\u001b[1m943/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9564 - loss: 0.0916\n",
      "Epoch 99: val_loss did not improve from 0.08613\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9564 - loss: 0.0916 - val_accuracy: 0.9556 - val_loss: 0.1015\n",
      "Epoch 100/1000\n",
      "\u001b[1m935/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9594 - loss: 0.0884\n",
      "Epoch 100: val_loss did not improve from 0.08613\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9594 - loss: 0.0884 - val_accuracy: 0.9599 - val_loss: 0.1012\n",
      "Epoch 101/1000\n",
      "\u001b[1m944/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9581 - loss: 0.0926\n",
      "Epoch 101: val_loss did not improve from 0.08613\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9581 - loss: 0.0926 - val_accuracy: 0.9627 - val_loss: 0.1031\n",
      "Epoch 102/1000\n",
      "\u001b[1m936/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9548 - loss: 0.1031\n",
      "Epoch 102: val_loss did not improve from 0.08613\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9548 - loss: 0.1031 - val_accuracy: 0.9653 - val_loss: 0.0894\n",
      "Epoch 103/1000\n",
      "\u001b[1m939/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9595 - loss: 0.0872\n",
      "Epoch 103: val_loss did not improve from 0.08613\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9595 - loss: 0.0872 - val_accuracy: 0.9638 - val_loss: 0.0880\n",
      "Epoch 104/1000\n",
      "\u001b[1m941/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9572 - loss: 0.0934\n",
      "Epoch 104: val_loss did not improve from 0.08613\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9572 - loss: 0.0934 - val_accuracy: 0.9557 - val_loss: 0.1083\n",
      "Epoch 105/1000\n",
      "\u001b[1m941/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9602 - loss: 0.0897\n",
      "Epoch 105: val_loss did not improve from 0.08613\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9601 - loss: 0.0897 - val_accuracy: 0.9565 - val_loss: 0.0971\n",
      "Epoch 106/1000\n",
      "\u001b[1m933/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9561 - loss: 0.0978\n",
      "Epoch 106: val_loss did not improve from 0.08613\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9561 - loss: 0.0978 - val_accuracy: 0.9529 - val_loss: 0.1047\n",
      "Epoch 107/1000\n",
      "\u001b[1m935/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9589 - loss: 0.0873\n",
      "Epoch 107: val_loss did not improve from 0.08613\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9589 - loss: 0.0873 - val_accuracy: 0.9418 - val_loss: 0.1237\n",
      "Epoch 108/1000\n",
      "\u001b[1m935/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9319 - loss: 0.1779\n",
      "Epoch 108: val_loss did not improve from 0.08613\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9318 - loss: 0.1779 - val_accuracy: 0.9242 - val_loss: 0.1431\n",
      "Epoch 109/1000\n",
      "\u001b[1m946/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9381 - loss: 0.1329\n",
      "Epoch 109: val_loss did not improve from 0.08613\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9382 - loss: 0.1329 - val_accuracy: 0.9396 - val_loss: 0.1452\n",
      "Epoch 110/1000\n",
      "\u001b[1m936/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9481 - loss: 0.1120\n",
      "Epoch 110: val_loss did not improve from 0.08613\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9482 - loss: 0.1120 - val_accuracy: 0.9471 - val_loss: 0.1386\n",
      "Epoch 111/1000\n",
      "\u001b[1m935/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9557 - loss: 0.1004\n",
      "Epoch 111: val_loss did not improve from 0.08613\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9557 - loss: 0.1004 - val_accuracy: 0.9618 - val_loss: 0.1029\n",
      "Epoch 112/1000\n",
      "\u001b[1m939/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9562 - loss: 0.1015\n",
      "Epoch 112: val_loss did not improve from 0.08613\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9562 - loss: 0.1015 - val_accuracy: 0.9564 - val_loss: 0.0957\n",
      "Epoch 113/1000\n",
      "\u001b[1m946/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9563 - loss: 0.0963\n",
      "Epoch 113: val_loss did not improve from 0.08613\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9563 - loss: 0.0963 - val_accuracy: 0.9586 - val_loss: 0.1036\n",
      "Epoch 114/1000\n",
      "\u001b[1m945/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9596 - loss: 0.0891\n",
      "Epoch 114: val_loss did not improve from 0.08613\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9596 - loss: 0.0891 - val_accuracy: 0.9192 - val_loss: 0.2064\n",
      "Epoch 115/1000\n",
      "\u001b[1m932/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9543 - loss: 0.1048\n",
      "Epoch 115: val_loss did not improve from 0.08613\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9543 - loss: 0.1048 - val_accuracy: 0.9478 - val_loss: 0.1063\n",
      "Epoch 116/1000\n",
      "\u001b[1m944/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9578 - loss: 0.0895\n",
      "Epoch 116: val_loss did not improve from 0.08613\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9578 - loss: 0.0895 - val_accuracy: 0.9620 - val_loss: 0.0938\n",
      "Epoch 117/1000\n",
      "\u001b[1m928/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9597 - loss: 0.0904\n",
      "Epoch 117: val_loss did not improve from 0.08613\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9596 - loss: 0.0904 - val_accuracy: 0.9544 - val_loss: 0.1085\n",
      "Epoch 118/1000\n",
      "\u001b[1m945/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9559 - loss: 0.0957\n",
      "Epoch 118: val_loss did not improve from 0.08613\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9560 - loss: 0.0957 - val_accuracy: 0.9496 - val_loss: 0.1001\n",
      "Epoch 119/1000\n",
      "\u001b[1m943/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9601 - loss: 0.0867\n",
      "Epoch 119: val_loss did not improve from 0.08613\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9601 - loss: 0.0867 - val_accuracy: 0.9524 - val_loss: 0.1093\n",
      "Epoch 120/1000\n",
      "\u001b[1m927/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9574 - loss: 0.0980\n",
      "Epoch 120: val_loss did not improve from 0.08613\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9574 - loss: 0.0978 - val_accuracy: 0.9525 - val_loss: 0.1158\n",
      "Epoch 121/1000\n",
      "\u001b[1m941/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9627 - loss: 0.0812\n",
      "Epoch 121: val_loss did not improve from 0.08613\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9627 - loss: 0.0812 - val_accuracy: 0.9571 - val_loss: 0.0914\n",
      "Epoch 122/1000\n",
      "\u001b[1m941/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9601 - loss: 0.0886\n",
      "Epoch 122: val_loss did not improve from 0.08613\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9601 - loss: 0.0886 - val_accuracy: 0.9526 - val_loss: 0.0945\n",
      "Epoch 123/1000\n",
      "\u001b[1m934/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9627 - loss: 0.0813\n",
      "Epoch 123: val_loss did not improve from 0.08613\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9626 - loss: 0.0814 - val_accuracy: 0.9280 - val_loss: 0.1681\n",
      "Epoch 124/1000\n",
      "\u001b[1m936/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9483 - loss: 0.1238\n",
      "Epoch 124: val_loss did not improve from 0.08613\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9485 - loss: 0.1234 - val_accuracy: 0.9682 - val_loss: 0.0884\n",
      "Epoch 125/1000\n",
      "\u001b[1m942/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9632 - loss: 0.0811\n",
      "Epoch 125: val_loss improved from 0.08613 to 0.08189, saving model to dnp3_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9632 - loss: 0.0811 - val_accuracy: 0.9635 - val_loss: 0.0819\n",
      "Epoch 126/1000\n",
      "\u001b[1m942/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9612 - loss: 0.0904\n",
      "Epoch 126: val_loss did not improve from 0.08189\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9612 - loss: 0.0903 - val_accuracy: 0.9551 - val_loss: 0.1146\n",
      "Epoch 127/1000\n",
      "\u001b[1m928/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9598 - loss: 0.0847\n",
      "Epoch 127: val_loss did not improve from 0.08189\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9598 - loss: 0.0847 - val_accuracy: 0.9573 - val_loss: 0.1111\n",
      "Epoch 128/1000\n",
      "\u001b[1m940/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9584 - loss: 0.0960\n",
      "Epoch 128: val_loss did not improve from 0.08189\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9584 - loss: 0.0959 - val_accuracy: 0.9620 - val_loss: 0.0876\n",
      "Epoch 129/1000\n",
      "\u001b[1m934/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9630 - loss: 0.0807\n",
      "Epoch 129: val_loss did not improve from 0.08189\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9629 - loss: 0.0809 - val_accuracy: 0.9661 - val_loss: 0.0906\n",
      "Epoch 130/1000\n",
      "\u001b[1m937/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9635 - loss: 0.0787\n",
      "Epoch 130: val_loss did not improve from 0.08189\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9635 - loss: 0.0787 - val_accuracy: 0.9591 - val_loss: 0.0910\n",
      "Epoch 131/1000\n",
      "\u001b[1m931/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9585 - loss: 0.0877\n",
      "Epoch 131: val_loss did not improve from 0.08189\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9586 - loss: 0.0877 - val_accuracy: 0.9560 - val_loss: 0.1040\n",
      "Epoch 132/1000\n",
      "\u001b[1m929/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9626 - loss: 0.0793\n",
      "Epoch 132: val_loss did not improve from 0.08189\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9626 - loss: 0.0794 - val_accuracy: 0.9486 - val_loss: 0.1218\n",
      "Epoch 133/1000\n",
      "\u001b[1m929/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9611 - loss: 0.0834\n",
      "Epoch 133: val_loss did not improve from 0.08189\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9612 - loss: 0.0833 - val_accuracy: 0.9538 - val_loss: 0.1286\n",
      "Epoch 134/1000\n",
      "\u001b[1m939/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9628 - loss: 0.0831\n",
      "Epoch 134: val_loss did not improve from 0.08189\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9628 - loss: 0.0831 - val_accuracy: 0.9640 - val_loss: 0.0846\n",
      "Epoch 135/1000\n",
      "\u001b[1m929/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9607 - loss: 0.0821\n",
      "Epoch 135: val_loss did not improve from 0.08189\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9607 - loss: 0.0821 - val_accuracy: 0.9574 - val_loss: 0.1031\n",
      "Epoch 136/1000\n",
      "\u001b[1m945/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9630 - loss: 0.0821\n",
      "Epoch 136: val_loss did not improve from 0.08189\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9630 - loss: 0.0821 - val_accuracy: 0.9464 - val_loss: 0.1793\n",
      "Epoch 137/1000\n",
      "\u001b[1m934/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9611 - loss: 0.0846\n",
      "Epoch 137: val_loss did not improve from 0.08189\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9612 - loss: 0.0845 - val_accuracy: 0.9613 - val_loss: 0.0974\n",
      "Epoch 138/1000\n",
      "\u001b[1m931/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9595 - loss: 0.0900\n",
      "Epoch 138: val_loss did not improve from 0.08189\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9596 - loss: 0.0899 - val_accuracy: 0.9524 - val_loss: 0.1197\n",
      "Epoch 139/1000\n",
      "\u001b[1m937/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9606 - loss: 0.0843\n",
      "Epoch 139: val_loss did not improve from 0.08189\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9606 - loss: 0.0844 - val_accuracy: 0.9521 - val_loss: 0.1111\n",
      "Epoch 140/1000\n",
      "\u001b[1m941/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9607 - loss: 0.0874\n",
      "Epoch 140: val_loss did not improve from 0.08189\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9607 - loss: 0.0874 - val_accuracy: 0.9614 - val_loss: 0.0938\n",
      "Epoch 141/1000\n",
      "\u001b[1m937/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9660 - loss: 0.0733\n",
      "Epoch 141: val_loss did not improve from 0.08189\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9659 - loss: 0.0733 - val_accuracy: 0.9595 - val_loss: 0.0933\n",
      "Epoch 142/1000\n",
      "\u001b[1m937/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9629 - loss: 0.0796\n",
      "Epoch 142: val_loss did not improve from 0.08189\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9629 - loss: 0.0797 - val_accuracy: 0.9468 - val_loss: 0.1197\n",
      "Epoch 143/1000\n",
      "\u001b[1m936/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9622 - loss: 0.0780\n",
      "Epoch 143: val_loss did not improve from 0.08189\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9622 - loss: 0.0781 - val_accuracy: 0.9624 - val_loss: 0.0890\n",
      "Epoch 144/1000\n",
      "\u001b[1m937/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9619 - loss: 0.0818\n",
      "Epoch 144: val_loss did not improve from 0.08189\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9619 - loss: 0.0818 - val_accuracy: 0.9643 - val_loss: 0.0896\n",
      "Epoch 145/1000\n",
      "\u001b[1m936/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9609 - loss: 0.0867\n",
      "Epoch 145: val_loss did not improve from 0.08189\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9609 - loss: 0.0867 - val_accuracy: 0.9651 - val_loss: 0.0876\n",
      "Epoch 146/1000\n",
      "\u001b[1m943/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9630 - loss: 0.0820\n",
      "Epoch 146: val_loss did not improve from 0.08189\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9630 - loss: 0.0820 - val_accuracy: 0.9677 - val_loss: 0.0836\n",
      "Epoch 147/1000\n",
      "\u001b[1m940/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9617 - loss: 0.0841\n",
      "Epoch 147: val_loss did not improve from 0.08189\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9617 - loss: 0.0841 - val_accuracy: 0.9597 - val_loss: 0.0979\n",
      "Epoch 148/1000\n",
      "\u001b[1m946/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9636 - loss: 0.0777\n",
      "Epoch 148: val_loss did not improve from 0.08189\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9636 - loss: 0.0776 - val_accuracy: 0.9600 - val_loss: 0.0987\n",
      "Epoch 149/1000\n",
      "\u001b[1m934/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9624 - loss: 0.0822\n",
      "Epoch 149: val_loss did not improve from 0.08189\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9624 - loss: 0.0822 - val_accuracy: 0.9600 - val_loss: 0.0908\n",
      "Epoch 150/1000\n",
      "\u001b[1m933/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9606 - loss: 0.0852\n",
      "Epoch 150: val_loss did not improve from 0.08189\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9606 - loss: 0.0851 - val_accuracy: 0.9644 - val_loss: 0.0870\n",
      "Epoch 151/1000\n",
      "\u001b[1m930/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9618 - loss: 0.0809\n",
      "Epoch 151: val_loss improved from 0.08189 to 0.07981, saving model to dnp3_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9619 - loss: 0.0809 - val_accuracy: 0.9674 - val_loss: 0.0798\n",
      "Epoch 152/1000\n",
      "\u001b[1m941/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9629 - loss: 0.0803\n",
      "Epoch 152: val_loss did not improve from 0.07981\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9630 - loss: 0.0803 - val_accuracy: 0.9640 - val_loss: 0.0894\n",
      "Epoch 153/1000\n",
      "\u001b[1m938/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9644 - loss: 0.0800\n",
      "Epoch 153: val_loss did not improve from 0.07981\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9644 - loss: 0.0800 - val_accuracy: 0.9638 - val_loss: 0.0881\n",
      "Epoch 154/1000\n",
      "\u001b[1m938/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9632 - loss: 0.0823\n",
      "Epoch 154: val_loss did not improve from 0.07981\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9632 - loss: 0.0823 - val_accuracy: 0.9668 - val_loss: 0.0876\n",
      "Epoch 155/1000\n",
      "\u001b[1m941/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9607 - loss: 0.0849\n",
      "Epoch 155: val_loss did not improve from 0.07981\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9607 - loss: 0.0849 - val_accuracy: 0.9657 - val_loss: 0.0817\n",
      "Epoch 156/1000\n",
      "\u001b[1m941/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9620 - loss: 0.0829\n",
      "Epoch 156: val_loss did not improve from 0.07981\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9620 - loss: 0.0829 - val_accuracy: 0.9533 - val_loss: 0.0922\n",
      "Epoch 157/1000\n",
      "\u001b[1m931/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9608 - loss: 0.0873\n",
      "Epoch 157: val_loss did not improve from 0.07981\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9608 - loss: 0.0873 - val_accuracy: 0.9272 - val_loss: 0.2303\n",
      "Epoch 158/1000\n",
      "\u001b[1m930/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9622 - loss: 0.0837\n",
      "Epoch 158: val_loss did not improve from 0.07981\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9622 - loss: 0.0836 - val_accuracy: 0.9563 - val_loss: 0.0963\n",
      "Epoch 159/1000\n",
      "\u001b[1m934/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9594 - loss: 0.0917\n",
      "Epoch 159: val_loss did not improve from 0.07981\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9595 - loss: 0.0915 - val_accuracy: 0.9684 - val_loss: 0.0860\n",
      "Epoch 160/1000\n",
      "\u001b[1m940/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9628 - loss: 0.0841\n",
      "Epoch 160: val_loss did not improve from 0.07981\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9628 - loss: 0.0841 - val_accuracy: 0.9643 - val_loss: 0.0854\n",
      "Epoch 161/1000\n",
      "\u001b[1m943/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9664 - loss: 0.0732\n",
      "Epoch 161: val_loss did not improve from 0.07981\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9664 - loss: 0.0732 - val_accuracy: 0.9494 - val_loss: 0.1440\n",
      "Epoch 162/1000\n",
      "\u001b[1m934/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9645 - loss: 0.0775\n",
      "Epoch 162: val_loss did not improve from 0.07981\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9645 - loss: 0.0775 - val_accuracy: 0.9581 - val_loss: 0.1017\n",
      "Epoch 163/1000\n",
      "\u001b[1m935/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9622 - loss: 0.0807\n",
      "Epoch 163: val_loss did not improve from 0.07981\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9622 - loss: 0.0807 - val_accuracy: 0.9671 - val_loss: 0.0884\n",
      "Epoch 164/1000\n",
      "\u001b[1m947/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9637 - loss: 0.0797\n",
      "Epoch 164: val_loss did not improve from 0.07981\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9637 - loss: 0.0797 - val_accuracy: 0.9643 - val_loss: 0.0885\n",
      "Epoch 165/1000\n",
      "\u001b[1m942/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9661 - loss: 0.0726\n",
      "Epoch 165: val_loss did not improve from 0.07981\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9660 - loss: 0.0727 - val_accuracy: 0.9481 - val_loss: 0.1584\n",
      "Epoch 166/1000\n",
      "\u001b[1m932/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9611 - loss: 0.0861\n",
      "Epoch 166: val_loss did not improve from 0.07981\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9612 - loss: 0.0860 - val_accuracy: 0.9571 - val_loss: 0.1055\n",
      "Epoch 167/1000\n",
      "\u001b[1m931/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9691 - loss: 0.0674\n",
      "Epoch 167: val_loss did not improve from 0.07981\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9691 - loss: 0.0675 - val_accuracy: 0.9624 - val_loss: 0.0883\n",
      "Epoch 168/1000\n",
      "\u001b[1m932/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9633 - loss: 0.0770\n",
      "Epoch 168: val_loss did not improve from 0.07981\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9633 - loss: 0.0771 - val_accuracy: 0.9643 - val_loss: 0.0853\n",
      "Epoch 169/1000\n",
      "\u001b[1m939/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9655 - loss: 0.0744\n",
      "Epoch 169: val_loss did not improve from 0.07981\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9654 - loss: 0.0744 - val_accuracy: 0.9648 - val_loss: 0.0851\n",
      "Epoch 170/1000\n",
      "\u001b[1m945/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9650 - loss: 0.0753\n",
      "Epoch 170: val_loss did not improve from 0.07981\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9650 - loss: 0.0753 - val_accuracy: 0.9470 - val_loss: 0.1380\n",
      "Epoch 171/1000\n",
      "\u001b[1m934/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9650 - loss: 0.0783\n",
      "Epoch 171: val_loss did not improve from 0.07981\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9650 - loss: 0.0783 - val_accuracy: 0.9487 - val_loss: 0.1217\n",
      "Epoch 172/1000\n",
      "\u001b[1m939/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9636 - loss: 0.0838\n",
      "Epoch 172: val_loss did not improve from 0.07981\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9636 - loss: 0.0837 - val_accuracy: 0.9657 - val_loss: 0.0822\n",
      "Epoch 173/1000\n",
      "\u001b[1m934/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9629 - loss: 0.0784\n",
      "Epoch 173: val_loss did not improve from 0.07981\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9629 - loss: 0.0784 - val_accuracy: 0.9624 - val_loss: 0.0874\n",
      "Epoch 174/1000\n",
      "\u001b[1m942/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9634 - loss: 0.0762\n",
      "Epoch 174: val_loss did not improve from 0.07981\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9634 - loss: 0.0762 - val_accuracy: 0.9634 - val_loss: 0.0865\n",
      "Epoch 175/1000\n",
      "\u001b[1m939/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9663 - loss: 0.0727\n",
      "Epoch 175: val_loss did not improve from 0.07981\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9663 - loss: 0.0728 - val_accuracy: 0.9390 - val_loss: 0.1230\n",
      "Epoch 176/1000\n",
      "\u001b[1m944/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9662 - loss: 0.0718\n",
      "Epoch 176: val_loss did not improve from 0.07981\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9661 - loss: 0.0718 - val_accuracy: 0.9560 - val_loss: 0.1074\n",
      "Epoch 177/1000\n",
      "\u001b[1m942/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9623 - loss: 0.0837\n",
      "Epoch 177: val_loss did not improve from 0.07981\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9623 - loss: 0.0837 - val_accuracy: 0.9599 - val_loss: 0.0931\n",
      "Epoch 178/1000\n",
      "\u001b[1m934/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9653 - loss: 0.0760\n",
      "Epoch 178: val_loss did not improve from 0.07981\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9653 - loss: 0.0760 - val_accuracy: 0.9636 - val_loss: 0.0988\n",
      "Epoch 179/1000\n",
      "\u001b[1m938/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9629 - loss: 0.0811\n",
      "Epoch 179: val_loss did not improve from 0.07981\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9629 - loss: 0.0811 - val_accuracy: 0.9667 - val_loss: 0.0840\n",
      "Epoch 180/1000\n",
      "\u001b[1m943/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9664 - loss: 0.0769\n",
      "Epoch 180: val_loss did not improve from 0.07981\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9664 - loss: 0.0770 - val_accuracy: 0.9642 - val_loss: 0.0880\n",
      "Epoch 181/1000\n",
      "\u001b[1m946/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9615 - loss: 0.0816\n",
      "Epoch 181: val_loss did not improve from 0.07981\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9615 - loss: 0.0816 - val_accuracy: 0.9668 - val_loss: 0.0825\n",
      "Epoch 182/1000\n",
      "\u001b[1m938/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9650 - loss: 0.0759\n",
      "Epoch 182: val_loss did not improve from 0.07981\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9650 - loss: 0.0760 - val_accuracy: 0.9358 - val_loss: 0.1335\n",
      "Epoch 183/1000\n",
      "\u001b[1m932/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9642 - loss: 0.0771\n",
      "Epoch 183: val_loss did not improve from 0.07981\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9642 - loss: 0.0771 - val_accuracy: 0.9590 - val_loss: 0.0883\n",
      "Epoch 184/1000\n",
      "\u001b[1m931/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9643 - loss: 0.0748\n",
      "Epoch 184: val_loss did not improve from 0.07981\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9643 - loss: 0.0748 - val_accuracy: 0.9455 - val_loss: 0.1532\n",
      "Epoch 185/1000\n",
      "\u001b[1m940/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9625 - loss: 0.0835\n",
      "Epoch 185: val_loss did not improve from 0.07981\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9626 - loss: 0.0834 - val_accuracy: 0.9452 - val_loss: 0.1608\n",
      "Epoch 186/1000\n",
      "\u001b[1m938/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9671 - loss: 0.0710\n",
      "Epoch 186: val_loss did not improve from 0.07981\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9671 - loss: 0.0711 - val_accuracy: 0.9545 - val_loss: 0.1019\n",
      "Epoch 187/1000\n",
      "\u001b[1m947/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9641 - loss: 0.0786\n",
      "Epoch 187: val_loss did not improve from 0.07981\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9641 - loss: 0.0786 - val_accuracy: 0.9687 - val_loss: 0.0800\n",
      "Epoch 188/1000\n",
      "\u001b[1m932/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9658 - loss: 0.0718\n",
      "Epoch 188: val_loss did not improve from 0.07981\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9657 - loss: 0.0719 - val_accuracy: 0.9586 - val_loss: 0.0961\n",
      "Epoch 189/1000\n",
      "\u001b[1m947/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9667 - loss: 0.0688\n",
      "Epoch 189: val_loss did not improve from 0.07981\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9667 - loss: 0.0688 - val_accuracy: 0.9658 - val_loss: 0.0879\n",
      "Epoch 190/1000\n",
      "\u001b[1m941/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9666 - loss: 0.0730\n",
      "Epoch 190: val_loss did not improve from 0.07981\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9666 - loss: 0.0731 - val_accuracy: 0.9508 - val_loss: 0.1206\n",
      "Epoch 191/1000\n",
      "\u001b[1m927/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9643 - loss: 0.0803\n",
      "Epoch 191: val_loss did not improve from 0.07981\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9643 - loss: 0.0801 - val_accuracy: 0.9633 - val_loss: 0.0879\n",
      "Epoch 192/1000\n",
      "\u001b[1m928/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9656 - loss: 0.0732\n",
      "Epoch 192: val_loss did not improve from 0.07981\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9656 - loss: 0.0733 - val_accuracy: 0.9605 - val_loss: 0.0966\n",
      "Epoch 193/1000\n",
      "\u001b[1m929/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9645 - loss: 0.0748\n",
      "Epoch 193: val_loss did not improve from 0.07981\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9645 - loss: 0.0748 - val_accuracy: 0.9686 - val_loss: 0.0931\n",
      "Epoch 194/1000\n",
      "\u001b[1m930/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9639 - loss: 0.0761\n",
      "Epoch 194: val_loss did not improve from 0.07981\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9639 - loss: 0.0761 - val_accuracy: 0.9712 - val_loss: 0.0860\n",
      "Epoch 195/1000\n",
      "\u001b[1m944/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9671 - loss: 0.0693\n",
      "Epoch 195: val_loss did not improve from 0.07981\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9671 - loss: 0.0694 - val_accuracy: 0.9632 - val_loss: 0.0927\n",
      "Epoch 196/1000\n",
      "\u001b[1m944/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9630 - loss: 0.0822\n",
      "Epoch 196: val_loss did not improve from 0.07981\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9630 - loss: 0.0822 - val_accuracy: 0.9614 - val_loss: 0.0881\n",
      "Epoch 197/1000\n",
      "\u001b[1m943/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9649 - loss: 0.0732\n",
      "Epoch 197: val_loss improved from 0.07981 to 0.07863, saving model to dnp3_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9649 - loss: 0.0732 - val_accuracy: 0.9665 - val_loss: 0.0786\n",
      "Epoch 198/1000\n",
      "\u001b[1m947/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9637 - loss: 0.0792\n",
      "Epoch 198: val_loss did not improve from 0.07863\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9637 - loss: 0.0792 - val_accuracy: 0.9653 - val_loss: 0.0876\n",
      "Epoch 199/1000\n",
      "\u001b[1m944/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9605 - loss: 0.0889\n",
      "Epoch 199: val_loss did not improve from 0.07863\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9606 - loss: 0.0889 - val_accuracy: 0.9599 - val_loss: 0.0954\n",
      "Epoch 200/1000\n",
      "\u001b[1m938/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9683 - loss: 0.0706\n",
      "Epoch 200: val_loss did not improve from 0.07863\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9683 - loss: 0.0707 - val_accuracy: 0.9655 - val_loss: 0.0872\n",
      "Epoch 201/1000\n",
      "\u001b[1m943/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9703 - loss: 0.0644\n",
      "Epoch 201: val_loss did not improve from 0.07863\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9703 - loss: 0.0645 - val_accuracy: 0.9604 - val_loss: 0.1074\n",
      "Epoch 202/1000\n",
      "\u001b[1m934/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9684 - loss: 0.0703\n",
      "Epoch 202: val_loss did not improve from 0.07863\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9684 - loss: 0.0703 - val_accuracy: 0.9257 - val_loss: 0.1763\n",
      "Epoch 203/1000\n",
      "\u001b[1m936/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9650 - loss: 0.0771\n",
      "Epoch 203: val_loss did not improve from 0.07863\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9650 - loss: 0.0771 - val_accuracy: 0.9543 - val_loss: 0.1149\n",
      "Epoch 204/1000\n",
      "\u001b[1m935/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9621 - loss: 0.0851\n",
      "Epoch 204: val_loss did not improve from 0.07863\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9622 - loss: 0.0850 - val_accuracy: 0.9534 - val_loss: 0.1023\n",
      "Epoch 205/1000\n",
      "\u001b[1m938/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9631 - loss: 0.0785\n",
      "Epoch 205: val_loss did not improve from 0.07863\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9631 - loss: 0.0784 - val_accuracy: 0.9660 - val_loss: 0.0839\n",
      "Epoch 206/1000\n",
      "\u001b[1m945/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9694 - loss: 0.0636\n",
      "Epoch 206: val_loss did not improve from 0.07863\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9694 - loss: 0.0636 - val_accuracy: 0.9486 - val_loss: 0.1288\n",
      "Epoch 207/1000\n",
      "\u001b[1m934/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9635 - loss: 0.0830\n",
      "Epoch 207: val_loss did not improve from 0.07863\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9635 - loss: 0.0828 - val_accuracy: 0.9629 - val_loss: 0.0907\n",
      "Epoch 208/1000\n",
      "\u001b[1m946/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9638 - loss: 0.0778\n",
      "Epoch 208: val_loss did not improve from 0.07863\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9638 - loss: 0.0778 - val_accuracy: 0.9512 - val_loss: 0.1322\n",
      "Epoch 209/1000\n",
      "\u001b[1m935/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9659 - loss: 0.0741\n",
      "Epoch 209: val_loss did not improve from 0.07863\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9659 - loss: 0.0741 - val_accuracy: 0.9639 - val_loss: 0.0838\n",
      "Epoch 210/1000\n",
      "\u001b[1m931/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9685 - loss: 0.0658\n",
      "Epoch 210: val_loss did not improve from 0.07863\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9685 - loss: 0.0659 - val_accuracy: 0.9645 - val_loss: 0.0881\n",
      "Epoch 211/1000\n",
      "\u001b[1m934/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9636 - loss: 0.0788\n",
      "Epoch 211: val_loss did not improve from 0.07863\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9636 - loss: 0.0788 - val_accuracy: 0.9635 - val_loss: 0.0911\n",
      "Epoch 212/1000\n",
      "\u001b[1m933/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9653 - loss: 0.0736\n",
      "Epoch 212: val_loss did not improve from 0.07863\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9653 - loss: 0.0736 - val_accuracy: 0.9666 - val_loss: 0.0822\n",
      "Epoch 213/1000\n",
      "\u001b[1m947/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9654 - loss: 0.0743\n",
      "Epoch 213: val_loss did not improve from 0.07863\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9654 - loss: 0.0743 - val_accuracy: 0.9681 - val_loss: 0.0844\n",
      "Epoch 214/1000\n",
      "\u001b[1m939/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9660 - loss: 0.0728\n",
      "Epoch 214: val_loss did not improve from 0.07863\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9660 - loss: 0.0729 - val_accuracy: 0.9632 - val_loss: 0.0902\n",
      "Epoch 215/1000\n",
      "\u001b[1m934/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9676 - loss: 0.0667\n",
      "Epoch 215: val_loss did not improve from 0.07863\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9676 - loss: 0.0667 - val_accuracy: 0.9619 - val_loss: 0.0994\n",
      "Epoch 216/1000\n",
      "\u001b[1m940/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9643 - loss: 0.0777\n",
      "Epoch 216: val_loss did not improve from 0.07863\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9643 - loss: 0.0777 - val_accuracy: 0.9666 - val_loss: 0.0809\n",
      "Epoch 217/1000\n",
      "\u001b[1m931/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9693 - loss: 0.0661\n",
      "Epoch 217: val_loss did not improve from 0.07863\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9693 - loss: 0.0662 - val_accuracy: 0.9666 - val_loss: 0.0836\n",
      "Epoch 218/1000\n",
      "\u001b[1m928/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9665 - loss: 0.0752\n",
      "Epoch 218: val_loss did not improve from 0.07863\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9665 - loss: 0.0752 - val_accuracy: 0.9650 - val_loss: 0.0882\n",
      "Epoch 219/1000\n",
      "\u001b[1m942/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9686 - loss: 0.0683\n",
      "Epoch 219: val_loss did not improve from 0.07863\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9685 - loss: 0.0683 - val_accuracy: 0.9664 - val_loss: 0.0834\n",
      "Epoch 220/1000\n",
      "\u001b[1m944/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9634 - loss: 0.0785\n",
      "Epoch 220: val_loss did not improve from 0.07863\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9635 - loss: 0.0785 - val_accuracy: 0.9483 - val_loss: 0.1207\n",
      "Epoch 221/1000\n",
      "\u001b[1m942/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9635 - loss: 0.0749\n",
      "Epoch 221: val_loss did not improve from 0.07863\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9635 - loss: 0.0749 - val_accuracy: 0.9535 - val_loss: 0.1025\n",
      "Epoch 222/1000\n",
      "\u001b[1m926/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9647 - loss: 0.0759\n",
      "Epoch 222: val_loss did not improve from 0.07863\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9647 - loss: 0.0758 - val_accuracy: 0.9657 - val_loss: 0.0866\n",
      "Epoch 223/1000\n",
      "\u001b[1m933/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9657 - loss: 0.0722\n",
      "Epoch 223: val_loss did not improve from 0.07863\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9657 - loss: 0.0723 - val_accuracy: 0.9670 - val_loss: 0.0824\n",
      "Epoch 224/1000\n",
      "\u001b[1m934/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9683 - loss: 0.0675\n",
      "Epoch 224: val_loss did not improve from 0.07863\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9683 - loss: 0.0675 - val_accuracy: 0.9675 - val_loss: 0.0823\n",
      "Epoch 225/1000\n",
      "\u001b[1m928/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9647 - loss: 0.0777\n",
      "Epoch 225: val_loss did not improve from 0.07863\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9647 - loss: 0.0776 - val_accuracy: 0.9624 - val_loss: 0.0884\n",
      "Epoch 226/1000\n",
      "\u001b[1m929/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9701 - loss: 0.0641\n",
      "Epoch 226: val_loss did not improve from 0.07863\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9700 - loss: 0.0642 - val_accuracy: 0.9669 - val_loss: 0.0863\n",
      "Epoch 227/1000\n",
      "\u001b[1m935/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9661 - loss: 0.0763\n",
      "Epoch 227: val_loss did not improve from 0.07863\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9661 - loss: 0.0762 - val_accuracy: 0.9538 - val_loss: 0.1025\n",
      "Epoch 228/1000\n",
      "\u001b[1m941/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9623 - loss: 0.0864\n",
      "Epoch 228: val_loss did not improve from 0.07863\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9623 - loss: 0.0863 - val_accuracy: 0.9608 - val_loss: 0.1141\n",
      "Epoch 229/1000\n",
      "\u001b[1m940/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9649 - loss: 0.0773\n",
      "Epoch 229: val_loss improved from 0.07863 to 0.07857, saving model to dnp3_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9649 - loss: 0.0773 - val_accuracy: 0.9695 - val_loss: 0.0786\n",
      "Epoch 230/1000\n",
      "\u001b[1m933/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9662 - loss: 0.0720\n",
      "Epoch 230: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9662 - loss: 0.0720 - val_accuracy: 0.9681 - val_loss: 0.0812\n",
      "Epoch 231/1000\n",
      "\u001b[1m938/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9693 - loss: 0.0656\n",
      "Epoch 231: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9693 - loss: 0.0657 - val_accuracy: 0.9670 - val_loss: 0.0842\n",
      "Epoch 232/1000\n",
      "\u001b[1m934/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9668 - loss: 0.0690\n",
      "Epoch 232: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9668 - loss: 0.0690 - val_accuracy: 0.9678 - val_loss: 0.0849\n",
      "Epoch 233/1000\n",
      "\u001b[1m942/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9659 - loss: 0.0732\n",
      "Epoch 233: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9659 - loss: 0.0732 - val_accuracy: 0.9597 - val_loss: 0.1029\n",
      "Epoch 234/1000\n",
      "\u001b[1m940/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9695 - loss: 0.0663\n",
      "Epoch 234: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9695 - loss: 0.0663 - val_accuracy: 0.9643 - val_loss: 0.0867\n",
      "Epoch 235/1000\n",
      "\u001b[1m937/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9654 - loss: 0.0759\n",
      "Epoch 235: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9654 - loss: 0.0759 - val_accuracy: 0.9643 - val_loss: 0.0939\n",
      "Epoch 236/1000\n",
      "\u001b[1m940/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9683 - loss: 0.0653\n",
      "Epoch 236: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9683 - loss: 0.0654 - val_accuracy: 0.9665 - val_loss: 0.0846\n",
      "Epoch 237/1000\n",
      "\u001b[1m928/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9708 - loss: 0.0631\n",
      "Epoch 237: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9707 - loss: 0.0632 - val_accuracy: 0.9474 - val_loss: 0.1122\n",
      "Epoch 238/1000\n",
      "\u001b[1m933/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9627 - loss: 0.0832\n",
      "Epoch 238: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9627 - loss: 0.0831 - val_accuracy: 0.9686 - val_loss: 0.0853\n",
      "Epoch 239/1000\n",
      "\u001b[1m942/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9675 - loss: 0.0689\n",
      "Epoch 239: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9675 - loss: 0.0689 - val_accuracy: 0.9660 - val_loss: 0.0881\n",
      "Epoch 240/1000\n",
      "\u001b[1m944/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9694 - loss: 0.0665\n",
      "Epoch 240: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9694 - loss: 0.0665 - val_accuracy: 0.9664 - val_loss: 0.0826\n",
      "Epoch 241/1000\n",
      "\u001b[1m933/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9660 - loss: 0.0689\n",
      "Epoch 241: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9660 - loss: 0.0689 - val_accuracy: 0.9675 - val_loss: 0.0851\n",
      "Epoch 242/1000\n",
      "\u001b[1m930/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9701 - loss: 0.0656\n",
      "Epoch 242: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9700 - loss: 0.0657 - val_accuracy: 0.9669 - val_loss: 0.0854\n",
      "Epoch 243/1000\n",
      "\u001b[1m933/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9689 - loss: 0.0677\n",
      "Epoch 243: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9689 - loss: 0.0677 - val_accuracy: 0.9561 - val_loss: 0.1077\n",
      "Epoch 244/1000\n",
      "\u001b[1m944/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9655 - loss: 0.0738\n",
      "Epoch 244: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9655 - loss: 0.0738 - val_accuracy: 0.9660 - val_loss: 0.0989\n",
      "Epoch 245/1000\n",
      "\u001b[1m928/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9627 - loss: 0.0871\n",
      "Epoch 245: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9628 - loss: 0.0868 - val_accuracy: 0.9629 - val_loss: 0.0999\n",
      "Epoch 246/1000\n",
      "\u001b[1m940/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9660 - loss: 0.0697\n",
      "Epoch 246: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9660 - loss: 0.0697 - val_accuracy: 0.9700 - val_loss: 0.0822\n",
      "Epoch 247/1000\n",
      "\u001b[1m947/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9681 - loss: 0.0705\n",
      "Epoch 247: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9681 - loss: 0.0705 - val_accuracy: 0.9598 - val_loss: 0.0984\n",
      "Epoch 248/1000\n",
      "\u001b[1m944/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9652 - loss: 0.0731\n",
      "Epoch 248: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9652 - loss: 0.0731 - val_accuracy: 0.9664 - val_loss: 0.0887\n",
      "Epoch 249/1000\n",
      "\u001b[1m944/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9670 - loss: 0.0692\n",
      "Epoch 249: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9670 - loss: 0.0692 - val_accuracy: 0.9656 - val_loss: 0.0913\n",
      "Epoch 250/1000\n",
      "\u001b[1m942/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9695 - loss: 0.0661\n",
      "Epoch 250: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9695 - loss: 0.0661 - val_accuracy: 0.9629 - val_loss: 0.0947\n",
      "Epoch 251/1000\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9665 - loss: 0.0721\n",
      "Epoch 251: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9665 - loss: 0.0721 - val_accuracy: 0.9644 - val_loss: 0.0840\n",
      "Epoch 252/1000\n",
      "\u001b[1m941/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9670 - loss: 0.0676\n",
      "Epoch 252: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9669 - loss: 0.0677 - val_accuracy: 0.9626 - val_loss: 0.1047\n",
      "Epoch 253/1000\n",
      "\u001b[1m933/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9635 - loss: 0.0799\n",
      "Epoch 253: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9636 - loss: 0.0797 - val_accuracy: 0.9566 - val_loss: 0.1204\n",
      "Epoch 254/1000\n",
      "\u001b[1m929/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9673 - loss: 0.0710\n",
      "Epoch 254: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9673 - loss: 0.0709 - val_accuracy: 0.9535 - val_loss: 0.1476\n",
      "Epoch 255/1000\n",
      "\u001b[1m947/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9632 - loss: 0.0913\n",
      "Epoch 255: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9632 - loss: 0.0913 - val_accuracy: 0.9605 - val_loss: 0.1004\n",
      "Epoch 256/1000\n",
      "\u001b[1m939/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9694 - loss: 0.0654\n",
      "Epoch 256: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9694 - loss: 0.0654 - val_accuracy: 0.9667 - val_loss: 0.0857\n",
      "Epoch 257/1000\n",
      "\u001b[1m943/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9664 - loss: 0.0752\n",
      "Epoch 257: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9664 - loss: 0.0752 - val_accuracy: 0.9667 - val_loss: 0.0856\n",
      "Epoch 258/1000\n",
      "\u001b[1m945/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9659 - loss: 0.0737\n",
      "Epoch 258: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9659 - loss: 0.0737 - val_accuracy: 0.9665 - val_loss: 0.0941\n",
      "Epoch 259/1000\n",
      "\u001b[1m941/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9676 - loss: 0.0698\n",
      "Epoch 259: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9676 - loss: 0.0698 - val_accuracy: 0.9663 - val_loss: 0.0869\n",
      "Epoch 260/1000\n",
      "\u001b[1m938/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9706 - loss: 0.0622\n",
      "Epoch 260: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9706 - loss: 0.0623 - val_accuracy: 0.9668 - val_loss: 0.0818\n",
      "Epoch 261/1000\n",
      "\u001b[1m942/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9679 - loss: 0.0678\n",
      "Epoch 261: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9679 - loss: 0.0678 - val_accuracy: 0.9637 - val_loss: 0.0972\n",
      "Epoch 262/1000\n",
      "\u001b[1m940/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9674 - loss: 0.0733\n",
      "Epoch 262: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9674 - loss: 0.0733 - val_accuracy: 0.9650 - val_loss: 0.0858\n",
      "Epoch 263/1000\n",
      "\u001b[1m939/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9681 - loss: 0.0661\n",
      "Epoch 263: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9681 - loss: 0.0661 - val_accuracy: 0.9682 - val_loss: 0.0808\n",
      "Epoch 264/1000\n",
      "\u001b[1m941/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9697 - loss: 0.0654\n",
      "Epoch 264: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9697 - loss: 0.0654 - val_accuracy: 0.9693 - val_loss: 0.0847\n",
      "Epoch 265/1000\n",
      "\u001b[1m944/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9614 - loss: 0.0877\n",
      "Epoch 265: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9614 - loss: 0.0876 - val_accuracy: 0.9656 - val_loss: 0.0887\n",
      "Epoch 266/1000\n",
      "\u001b[1m942/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9677 - loss: 0.0654\n",
      "Epoch 266: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9677 - loss: 0.0654 - val_accuracy: 0.9638 - val_loss: 0.0916\n",
      "Epoch 267/1000\n",
      "\u001b[1m946/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9673 - loss: 0.0682\n",
      "Epoch 267: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9673 - loss: 0.0682 - val_accuracy: 0.9671 - val_loss: 0.0847\n",
      "Epoch 268/1000\n",
      "\u001b[1m941/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9678 - loss: 0.0692\n",
      "Epoch 268: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9678 - loss: 0.0692 - val_accuracy: 0.9535 - val_loss: 0.1210\n",
      "Epoch 269/1000\n",
      "\u001b[1m937/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9675 - loss: 0.0741\n",
      "Epoch 269: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9675 - loss: 0.0742 - val_accuracy: 0.9676 - val_loss: 0.0837\n",
      "Epoch 270/1000\n",
      "\u001b[1m944/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9692 - loss: 0.0621\n",
      "Epoch 270: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9692 - loss: 0.0621 - val_accuracy: 0.9641 - val_loss: 0.0825\n",
      "Epoch 271/1000\n",
      "\u001b[1m940/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9664 - loss: 0.0733\n",
      "Epoch 271: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9664 - loss: 0.0733 - val_accuracy: 0.9653 - val_loss: 0.0916\n",
      "Epoch 272/1000\n",
      "\u001b[1m936/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9673 - loss: 0.0691\n",
      "Epoch 272: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9673 - loss: 0.0690 - val_accuracy: 0.9659 - val_loss: 0.0913\n",
      "Epoch 273/1000\n",
      "\u001b[1m945/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9699 - loss: 0.0635\n",
      "Epoch 273: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9699 - loss: 0.0635 - val_accuracy: 0.9638 - val_loss: 0.0899\n",
      "Epoch 274/1000\n",
      "\u001b[1m944/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9688 - loss: 0.0656\n",
      "Epoch 274: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9688 - loss: 0.0656 - val_accuracy: 0.9645 - val_loss: 0.0867\n",
      "Epoch 275/1000\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9680 - loss: 0.0689\n",
      "Epoch 275: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9680 - loss: 0.0689 - val_accuracy: 0.9627 - val_loss: 0.0974\n",
      "Epoch 276/1000\n",
      "\u001b[1m947/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9640 - loss: 0.0771\n",
      "Epoch 276: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9640 - loss: 0.0770 - val_accuracy: 0.9654 - val_loss: 0.0911\n",
      "Epoch 277/1000\n",
      "\u001b[1m937/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9680 - loss: 0.0681\n",
      "Epoch 277: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9680 - loss: 0.0680 - val_accuracy: 0.9669 - val_loss: 0.0851\n",
      "Epoch 278/1000\n",
      "\u001b[1m942/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9658 - loss: 0.0749\n",
      "Epoch 278: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9658 - loss: 0.0749 - val_accuracy: 0.9671 - val_loss: 0.0868\n",
      "Epoch 279/1000\n",
      "\u001b[1m935/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9699 - loss: 0.0690\n",
      "Epoch 279: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9698 - loss: 0.0690 - val_accuracy: 0.9708 - val_loss: 0.0878\n",
      "Epoch 280/1000\n",
      "\u001b[1m927/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9696 - loss: 0.0648\n",
      "Epoch 280: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9696 - loss: 0.0649 - val_accuracy: 0.9630 - val_loss: 0.0947\n",
      "Epoch 281/1000\n",
      "\u001b[1m930/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9694 - loss: 0.0647\n",
      "Epoch 281: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9693 - loss: 0.0648 - val_accuracy: 0.9670 - val_loss: 0.0870\n",
      "Epoch 282/1000\n",
      "\u001b[1m933/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9683 - loss: 0.0670\n",
      "Epoch 282: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9683 - loss: 0.0671 - val_accuracy: 0.9495 - val_loss: 0.1423\n",
      "Epoch 283/1000\n",
      "\u001b[1m932/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9640 - loss: 0.0819\n",
      "Epoch 283: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9640 - loss: 0.0818 - val_accuracy: 0.9664 - val_loss: 0.0852\n",
      "Epoch 284/1000\n",
      "\u001b[1m938/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9673 - loss: 0.0656\n",
      "Epoch 284: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9673 - loss: 0.0656 - val_accuracy: 0.9680 - val_loss: 0.0848\n",
      "Epoch 285/1000\n",
      "\u001b[1m934/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9635 - loss: 0.0852\n",
      "Epoch 285: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9635 - loss: 0.0851 - val_accuracy: 0.9621 - val_loss: 0.0917\n",
      "Epoch 286/1000\n",
      "\u001b[1m935/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9670 - loss: 0.0673\n",
      "Epoch 286: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9670 - loss: 0.0673 - val_accuracy: 0.9603 - val_loss: 0.0934\n",
      "Epoch 287/1000\n",
      "\u001b[1m929/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9680 - loss: 0.0691\n",
      "Epoch 287: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9680 - loss: 0.0690 - val_accuracy: 0.9662 - val_loss: 0.0879\n",
      "Epoch 288/1000\n",
      "\u001b[1m938/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9646 - loss: 0.0736\n",
      "Epoch 288: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9646 - loss: 0.0735 - val_accuracy: 0.9642 - val_loss: 0.0910\n",
      "Epoch 289/1000\n",
      "\u001b[1m941/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9689 - loss: 0.0674\n",
      "Epoch 289: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9689 - loss: 0.0674 - val_accuracy: 0.9574 - val_loss: 0.1256\n",
      "Epoch 290/1000\n",
      "\u001b[1m941/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9681 - loss: 0.0689\n",
      "Epoch 290: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9681 - loss: 0.0689 - val_accuracy: 0.9640 - val_loss: 0.0979\n",
      "Epoch 291/1000\n",
      "\u001b[1m941/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9693 - loss: 0.0625\n",
      "Epoch 291: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9693 - loss: 0.0625 - val_accuracy: 0.9623 - val_loss: 0.0889\n",
      "Epoch 292/1000\n",
      "\u001b[1m946/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9689 - loss: 0.0659\n",
      "Epoch 292: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9689 - loss: 0.0659 - val_accuracy: 0.9616 - val_loss: 0.0942\n",
      "Epoch 293/1000\n",
      "\u001b[1m947/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9693 - loss: 0.0671\n",
      "Epoch 293: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9693 - loss: 0.0671 - val_accuracy: 0.9569 - val_loss: 0.1037\n",
      "Epoch 294/1000\n",
      "\u001b[1m935/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9666 - loss: 0.0715\n",
      "Epoch 294: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9666 - loss: 0.0715 - val_accuracy: 0.9628 - val_loss: 0.0961\n",
      "Epoch 295/1000\n",
      "\u001b[1m939/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9701 - loss: 0.0656\n",
      "Epoch 295: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9701 - loss: 0.0656 - val_accuracy: 0.9667 - val_loss: 0.0851\n",
      "Epoch 296/1000\n",
      "\u001b[1m945/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9697 - loss: 0.0634\n",
      "Epoch 296: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9697 - loss: 0.0634 - val_accuracy: 0.9556 - val_loss: 0.1212\n",
      "Epoch 297/1000\n",
      "\u001b[1m926/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9643 - loss: 0.0754\n",
      "Epoch 297: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9643 - loss: 0.0753 - val_accuracy: 0.9663 - val_loss: 0.0858\n",
      "Epoch 298/1000\n",
      "\u001b[1m936/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9659 - loss: 0.0722\n",
      "Epoch 298: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9659 - loss: 0.0721 - val_accuracy: 0.9686 - val_loss: 0.0860\n",
      "Epoch 299/1000\n",
      "\u001b[1m930/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9673 - loss: 0.0703\n",
      "Epoch 299: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9672 - loss: 0.0703 - val_accuracy: 0.9654 - val_loss: 0.0875\n",
      "Epoch 300/1000\n",
      "\u001b[1m935/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9689 - loss: 0.0640\n",
      "Epoch 300: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9689 - loss: 0.0641 - val_accuracy: 0.9657 - val_loss: 0.0889\n",
      "Epoch 301/1000\n",
      "\u001b[1m941/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9692 - loss: 0.0642\n",
      "Epoch 301: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9692 - loss: 0.0642 - val_accuracy: 0.9642 - val_loss: 0.0861\n",
      "Epoch 302/1000\n",
      "\u001b[1m934/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9666 - loss: 0.0721\n",
      "Epoch 302: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9667 - loss: 0.0721 - val_accuracy: 0.9641 - val_loss: 0.0910\n",
      "Epoch 303/1000\n",
      "\u001b[1m945/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9627 - loss: 0.0768\n",
      "Epoch 303: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9627 - loss: 0.0768 - val_accuracy: 0.9436 - val_loss: 0.1303\n",
      "Epoch 304/1000\n",
      "\u001b[1m939/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9641 - loss: 0.0801\n",
      "Epoch 304: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9641 - loss: 0.0801 - val_accuracy: 0.9670 - val_loss: 0.0867\n",
      "Epoch 305/1000\n",
      "\u001b[1m945/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9659 - loss: 0.0744\n",
      "Epoch 305: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9659 - loss: 0.0743 - val_accuracy: 0.9564 - val_loss: 0.1221\n",
      "Epoch 306/1000\n",
      "\u001b[1m939/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9673 - loss: 0.0679\n",
      "Epoch 306: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9673 - loss: 0.0679 - val_accuracy: 0.9574 - val_loss: 0.1150\n",
      "Epoch 307/1000\n",
      "\u001b[1m947/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9686 - loss: 0.0632\n",
      "Epoch 307: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9686 - loss: 0.0632 - val_accuracy: 0.9570 - val_loss: 0.1333\n",
      "Epoch 308/1000\n",
      "\u001b[1m935/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9644 - loss: 0.0810\n",
      "Epoch 308: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9645 - loss: 0.0809 - val_accuracy: 0.9637 - val_loss: 0.0856\n",
      "Epoch 309/1000\n",
      "\u001b[1m941/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9693 - loss: 0.0647\n",
      "Epoch 309: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9693 - loss: 0.0647 - val_accuracy: 0.9675 - val_loss: 0.0845\n",
      "Epoch 310/1000\n",
      "\u001b[1m935/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9641 - loss: 0.0866\n",
      "Epoch 310: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9641 - loss: 0.0865 - val_accuracy: 0.9713 - val_loss: 0.0932\n",
      "Epoch 311/1000\n",
      "\u001b[1m943/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9691 - loss: 0.0648\n",
      "Epoch 311: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9691 - loss: 0.0649 - val_accuracy: 0.9714 - val_loss: 0.0879\n",
      "Epoch 312/1000\n",
      "\u001b[1m942/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9704 - loss: 0.0659\n",
      "Epoch 312: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9704 - loss: 0.0659 - val_accuracy: 0.9623 - val_loss: 0.1009\n",
      "Epoch 313/1000\n",
      "\u001b[1m934/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9646 - loss: 0.0725\n",
      "Epoch 313: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9646 - loss: 0.0724 - val_accuracy: 0.9614 - val_loss: 0.1018\n",
      "Epoch 314/1000\n",
      "\u001b[1m935/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9683 - loss: 0.0658\n",
      "Epoch 314: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9683 - loss: 0.0658 - val_accuracy: 0.9697 - val_loss: 0.0879\n",
      "Epoch 315/1000\n",
      "\u001b[1m938/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9637 - loss: 0.0768\n",
      "Epoch 315: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9638 - loss: 0.0767 - val_accuracy: 0.9688 - val_loss: 0.0878\n",
      "Epoch 316/1000\n",
      "\u001b[1m934/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9671 - loss: 0.0687\n",
      "Epoch 316: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9671 - loss: 0.0687 - val_accuracy: 0.9540 - val_loss: 0.1124\n",
      "Epoch 317/1000\n",
      "\u001b[1m929/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9688 - loss: 0.0647\n",
      "Epoch 317: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9688 - loss: 0.0648 - val_accuracy: 0.9626 - val_loss: 0.1040\n",
      "Epoch 318/1000\n",
      "\u001b[1m932/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9675 - loss: 0.0698\n",
      "Epoch 318: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9675 - loss: 0.0698 - val_accuracy: 0.9559 - val_loss: 0.1257\n",
      "Epoch 319/1000\n",
      "\u001b[1m933/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9687 - loss: 0.0700\n",
      "Epoch 319: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9687 - loss: 0.0700 - val_accuracy: 0.9599 - val_loss: 0.1086\n",
      "Epoch 320/1000\n",
      "\u001b[1m940/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9680 - loss: 0.0687\n",
      "Epoch 320: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9680 - loss: 0.0687 - val_accuracy: 0.9636 - val_loss: 0.0899\n",
      "Epoch 321/1000\n",
      "\u001b[1m930/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9655 - loss: 0.0769\n",
      "Epoch 321: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9656 - loss: 0.0768 - val_accuracy: 0.9619 - val_loss: 0.0999\n",
      "Epoch 322/1000\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9639 - loss: 0.0787\n",
      "Epoch 322: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9639 - loss: 0.0787 - val_accuracy: 0.9619 - val_loss: 0.0928\n",
      "Epoch 323/1000\n",
      "\u001b[1m944/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9643 - loss: 0.0782\n",
      "Epoch 323: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9643 - loss: 0.0782 - val_accuracy: 0.9652 - val_loss: 0.0911\n",
      "Epoch 324/1000\n",
      "\u001b[1m933/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9668 - loss: 0.0721\n",
      "Epoch 324: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9668 - loss: 0.0721 - val_accuracy: 0.9649 - val_loss: 0.0923\n",
      "Epoch 325/1000\n",
      "\u001b[1m941/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9684 - loss: 0.0697\n",
      "Epoch 325: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9684 - loss: 0.0697 - val_accuracy: 0.9712 - val_loss: 0.0866\n",
      "Epoch 326/1000\n",
      "\u001b[1m931/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9670 - loss: 0.0686\n",
      "Epoch 326: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9671 - loss: 0.0685 - val_accuracy: 0.9658 - val_loss: 0.0988\n",
      "Epoch 327/1000\n",
      "\u001b[1m933/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9688 - loss: 0.0677\n",
      "Epoch 327: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9688 - loss: 0.0677 - val_accuracy: 0.9680 - val_loss: 0.0864\n",
      "Epoch 328/1000\n",
      "\u001b[1m941/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9698 - loss: 0.0616\n",
      "Epoch 328: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9698 - loss: 0.0616 - val_accuracy: 0.9648 - val_loss: 0.0868\n",
      "Epoch 329/1000\n",
      "\u001b[1m944/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9646 - loss: 0.0763\n",
      "Epoch 329: val_loss did not improve from 0.07857\n",
      "\u001b[1m948/948\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9646 - loss: 0.0763 - val_accuracy: 0.9658 - val_loss: 0.0960\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9720 - loss: 0.0813\n",
      "Test Accuracy: 96.95%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Load dataset (replace with your DNP3 flow data)\n",
    "df = combined_df.copy()\n",
    "\n",
    "# Preprocessing\n",
    "X = df.drop(\"Label\", axis=1).values\n",
    "y = pd.get_dummies(df[\"Label\"]).values  # One-hot encoding\n",
    "\n",
    "# Normalization to [0,1] range\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "# DNN Architecture\n",
    "dnn_model = Sequential(\n",
    "    [\n",
    "        Dense(90, activation=\"relu\", input_shape=(X_train.shape[1],)),\n",
    "        Dense(90, activation=\"relu\"),\n",
    "        Dense(90, activation=\"relu\"),\n",
    "        Dense(90, activation=\"relu\"),\n",
    "        Dense(90, activation=\"relu\"),\n",
    "        Dense(90, activation=\"relu\"),\n",
    "        Dense(90, activation=\"relu\"),\n",
    "        Dense(90, activation=\"relu\"),\n",
    "        Dense(90, activation=\"relu\"),\n",
    "        Dense(y_train.shape[1], activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Compile model\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "dnn_model.compile(\n",
    "    optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Training\n",
    "history = dnn_model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=32,\n",
    "    verbose=1,\n",
    "    validation_data=(X_test, y_test),\n",
    "    shuffle=True,\n",
    "    callbacks=[\n",
    "        EarlyStopping(monitor=\"val_loss\", patience=100, restore_best_weights=True),\n",
    "        ModelCheckpoint(\n",
    "            \"dnp3_best_model.h5\", monitor=\"val_loss\", save_best_only=True, verbose=1\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Evaluation\n",
    "loss, accuracy = dnn_model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False,  True, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False,  True],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       ...,\n",
       "       [False, False, False, ..., False, False,  True],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [ True, False, False, ..., False, False, False]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "# --- Plotting Metrics ---\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Accuracy plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history[\"accuracy\"], label=\"Train Accuracy\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"Validation Accuracy\")\n",
    "plt.title(\"Model Accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "# Loss plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history[\"loss\"], label=\"Train Loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "plt.title(\"Model Loss\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m316/316\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "F1 Score (macro): 0.9285, Accuracy: 0.9695\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# load the best model\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "dnn_model = load_model(\"dnp3_best_model.h5\")\n",
    "\n",
    "# Predict class probabilities for the test set\n",
    "y_pred_prob = dnn_model.predict(X_test)\n",
    "# Convert probabilities to class indices\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Calculate macro-averaged F1 score for multi-class classification\n",
    "f1 = f1_score(y_true, y_pred, average=\"macro\")\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "print(f\"F1 Score (macro): {f1:.4f}, Accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: torch.Size([32, 95]), Labels: torch.Size([32, 9])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        labels_key: str = \"Label\",\n",
    "        split: str = \"train\",\n",
    "        random_state: int = 42,\n",
    "        max_data: int = -1,\n",
    "        train_size: float = 0.75,\n",
    "    ):\n",
    "        self.train_size = train_size\n",
    "        self.df = df\n",
    "        class_names = df[labels_key].unique()\n",
    "        class_names.sort()\n",
    "        self.class_names = class_names\n",
    "        self.class_encoder = {name: i for i, name in enumerate(class_names)}\n",
    "\n",
    "        self.df = self.df.sample(\n",
    "            frac=1.0, random_state=random_state, replace=False\n",
    "        ).reset_index(drop=True)\n",
    "\n",
    "        if max_data > 0:\n",
    "            self.df = self.df.iloc[:max_data]\n",
    "\n",
    "        self.labels = self.df[labels_key].values\n",
    "        self.features = self.df.drop(columns=[labels_key]).values\n",
    "\n",
    "        self.scaler = MinMaxScaler()\n",
    "        self.features = self.scaler.fit_transform(self.features)\n",
    "\n",
    "        self.split = split\n",
    "        self.random_state = random_state\n",
    "        self._split_data()\n",
    "        self._one_hot_encode_labels()\n",
    "\n",
    "    def _split_data(self):\n",
    "        if self.split == \"train\":\n",
    "            self.features = self.features[: int(len(self.features) * self.train_size)]\n",
    "            self.labels = self.labels[: int(len(self.labels) * self.train_size)]\n",
    "        else:\n",
    "            self.features = self.features[int(len(self.features) * self.train_size) :]\n",
    "            self.labels = self.labels[int(len(self.labels) * self.train_size) :]\n",
    "\n",
    "    def _one_hot_encode_labels(self):\n",
    "        labels = np.zeros((self.labels.shape[0], len(self.class_names)))\n",
    "        for i, label in enumerate(self.labels):\n",
    "            labels[i, self.class_encoder[label]] = 1\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx == len(self.labels) - 1:\n",
    "            idxs = np.arange(len(self.labels))\n",
    "            np.random.shuffle(idxs)\n",
    "            self.features = self.features[idxs]\n",
    "            self.labels = self.labels[idxs]\n",
    "\n",
    "        return torch.from_numpy(self.features[idx]).to(torch.float32), torch.from_numpy(\n",
    "            self.labels[idx]\n",
    "        ).to(torch.float32)\n",
    "\n",
    "\n",
    "df = combined_df.copy()\n",
    "# df = oversample_class(df, \"Label\")\n",
    "max_data = -1\n",
    "train_dataset = CustomDataset(df, split=\"train\", max_data=max_data)\n",
    "test_dataset = CustomDataset(df, split=\"test\", max_data=max_data)\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "for features, labels in train_loader:\n",
    "    print(f\"Features: {features.shape}, Labels: {labels.shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-18 23:09:26.221\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [0/1000], Train Loss: 0.0047, Train Acc: 0.6301, Test Loss: 0.0047, Test Acc: 0.6301, Max Acc: 0.6301 @ 0 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:09:31.957\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [1/1000], Train Loss: 0.0044, Train Acc: 0.5883, Test Loss: 0.0044, Test Acc: 0.5883, Max Acc: 0.6301 @ 0 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:09:37.699\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [2/1000], Train Loss: 0.0043, Train Acc: 0.6118, Test Loss: 0.0043, Test Acc: 0.6118, Max Acc: 0.6301 @ 0 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:09:43.378\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [3/1000], Train Loss: 0.0041, Train Acc: 0.6734, Test Loss: 0.0041, Test Acc: 0.6734, Max Acc: 0.6734 @ 3 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:09:48.823\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [4/1000], Train Loss: 0.0039, Train Acc: 0.6821, Test Loss: 0.0039, Test Acc: 0.6821, Max Acc: 0.6821 @ 4 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:09:54.290\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [5/1000], Train Loss: 0.0037, Train Acc: 0.7253, Test Loss: 0.0037, Test Acc: 0.7253, Max Acc: 0.7253 @ 5 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:10:00.132\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [6/1000], Train Loss: 0.0045, Train Acc: 0.6248, Test Loss: 0.0045, Test Acc: 0.6248, Max Acc: 0.7253 @ 5 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:10:05.830\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [7/1000], Train Loss: 0.0034, Train Acc: 0.7348, Test Loss: 0.0034, Test Acc: 0.7348, Max Acc: 0.7348 @ 7 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:10:11.415\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [8/1000], Train Loss: 0.0030, Train Acc: 0.7698, Test Loss: 0.0030, Test Acc: 0.7698, Max Acc: 0.7698 @ 8 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:10:17.313\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [9/1000], Train Loss: 0.0029, Train Acc: 0.7515, Test Loss: 0.0029, Test Acc: 0.7515, Max Acc: 0.7698 @ 8 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:10:23.038\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [10/1000], Train Loss: 0.0029, Train Acc: 0.7643, Test Loss: 0.0029, Test Acc: 0.7643, Max Acc: 0.7698 @ 8 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:10:28.648\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [11/1000], Train Loss: 0.0031, Train Acc: 0.7521, Test Loss: 0.0031, Test Acc: 0.7521, Max Acc: 0.7698 @ 8 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:10:34.158\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [12/1000], Train Loss: 0.0030, Train Acc: 0.7629, Test Loss: 0.0030, Test Acc: 0.7629, Max Acc: 0.7698 @ 8 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:10:39.696\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [13/1000], Train Loss: 0.0028, Train Acc: 0.7846, Test Loss: 0.0028, Test Acc: 0.7846, Max Acc: 0.7846 @ 13 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:10:45.112\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [14/1000], Train Loss: 0.0027, Train Acc: 0.7866, Test Loss: 0.0027, Test Acc: 0.7866, Max Acc: 0.7866 @ 14 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:10:50.549\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [15/1000], Train Loss: 0.0027, Train Acc: 0.7808, Test Loss: 0.0027, Test Acc: 0.7808, Max Acc: 0.7866 @ 14 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:10:56.096\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [16/1000], Train Loss: 0.0027, Train Acc: 0.7791, Test Loss: 0.0027, Test Acc: 0.7791, Max Acc: 0.7866 @ 14 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:11:01.552\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [17/1000], Train Loss: 0.0033, Train Acc: 0.7338, Test Loss: 0.0033, Test Acc: 0.7338, Max Acc: 0.7866 @ 14 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:11:07.064\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [18/1000], Train Loss: 0.0027, Train Acc: 0.7804, Test Loss: 0.0027, Test Acc: 0.7804, Max Acc: 0.7866 @ 14 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:11:12.563\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [19/1000], Train Loss: 0.0027, Train Acc: 0.7823, Test Loss: 0.0027, Test Acc: 0.7823, Max Acc: 0.7866 @ 14 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:11:18.051\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [20/1000], Train Loss: 0.0030, Train Acc: 0.7541, Test Loss: 0.0030, Test Acc: 0.7541, Max Acc: 0.7866 @ 14 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:11:23.735\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [21/1000], Train Loss: 0.0026, Train Acc: 0.7837, Test Loss: 0.0026, Test Acc: 0.7837, Max Acc: 0.7866 @ 14 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:11:29.256\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [22/1000], Train Loss: 0.0027, Train Acc: 0.7756, Test Loss: 0.0027, Test Acc: 0.7756, Max Acc: 0.7866 @ 14 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:11:34.458\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [23/1000], Train Loss: 0.0027, Train Acc: 0.7803, Test Loss: 0.0027, Test Acc: 0.7803, Max Acc: 0.7866 @ 14 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:11:39.625\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [24/1000], Train Loss: 0.0026, Train Acc: 0.7804, Test Loss: 0.0026, Test Acc: 0.7804, Max Acc: 0.7866 @ 14 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:11:44.855\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [25/1000], Train Loss: 0.0026, Train Acc: 0.7972, Test Loss: 0.0026, Test Acc: 0.7972, Max Acc: 0.7972 @ 25 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:11:49.981\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [26/1000], Train Loss: 0.0026, Train Acc: 0.7824, Test Loss: 0.0026, Test Acc: 0.7824, Max Acc: 0.7972 @ 25 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:11:55.255\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [27/1000], Train Loss: 0.0027, Train Acc: 0.7701, Test Loss: 0.0027, Test Acc: 0.7701, Max Acc: 0.7972 @ 25 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:12:00.974\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [28/1000], Train Loss: 0.0025, Train Acc: 0.7763, Test Loss: 0.0025, Test Acc: 0.7763, Max Acc: 0.7972 @ 25 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:12:06.217\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [29/1000], Train Loss: 0.0027, Train Acc: 0.7615, Test Loss: 0.0027, Test Acc: 0.7615, Max Acc: 0.7972 @ 25 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:12:11.526\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [30/1000], Train Loss: 0.0026, Train Acc: 0.7867, Test Loss: 0.0026, Test Acc: 0.7867, Max Acc: 0.7972 @ 25 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:12:17.279\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [31/1000], Train Loss: 0.0024, Train Acc: 0.8146, Test Loss: 0.0024, Test Acc: 0.8146, Max Acc: 0.8146 @ 31 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:12:22.955\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [32/1000], Train Loss: 0.0037, Train Acc: 0.7155, Test Loss: 0.0037, Test Acc: 0.7155, Max Acc: 0.8146 @ 31 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:12:28.755\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [33/1000], Train Loss: 0.0024, Train Acc: 0.8026, Test Loss: 0.0024, Test Acc: 0.8026, Max Acc: 0.8146 @ 31 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:12:34.059\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [34/1000], Train Loss: 0.0028, Train Acc: 0.7708, Test Loss: 0.0028, Test Acc: 0.7708, Max Acc: 0.8146 @ 31 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:12:39.734\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [35/1000], Train Loss: 0.0024, Train Acc: 0.8250, Test Loss: 0.0024, Test Acc: 0.8250, Max Acc: 0.8250 @ 35 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:12:45.684\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [36/1000], Train Loss: 0.0023, Train Acc: 0.8149, Test Loss: 0.0023, Test Acc: 0.8149, Max Acc: 0.8250 @ 35 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:12:51.419\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [37/1000], Train Loss: 0.0024, Train Acc: 0.8169, Test Loss: 0.0024, Test Acc: 0.8169, Max Acc: 0.8250 @ 35 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:12:57.128\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [38/1000], Train Loss: 0.0022, Train Acc: 0.8411, Test Loss: 0.0022, Test Acc: 0.8411, Max Acc: 0.8411 @ 38 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:13:02.549\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [39/1000], Train Loss: 0.0025, Train Acc: 0.7791, Test Loss: 0.0025, Test Acc: 0.7791, Max Acc: 0.8411 @ 38 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:13:07.842\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [40/1000], Train Loss: 0.0022, Train Acc: 0.7965, Test Loss: 0.0022, Test Acc: 0.7965, Max Acc: 0.8411 @ 38 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:13:13.150\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [41/1000], Train Loss: 0.0021, Train Acc: 0.8315, Test Loss: 0.0021, Test Acc: 0.8315, Max Acc: 0.8411 @ 38 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:13:18.339\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [42/1000], Train Loss: 0.0022, Train Acc: 0.8210, Test Loss: 0.0022, Test Acc: 0.8210, Max Acc: 0.8411 @ 38 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:13:23.510\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [43/1000], Train Loss: 0.0020, Train Acc: 0.8527, Test Loss: 0.0020, Test Acc: 0.8527, Max Acc: 0.8527 @ 43 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:13:28.775\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [44/1000], Train Loss: 0.0023, Train Acc: 0.8080, Test Loss: 0.0023, Test Acc: 0.8080, Max Acc: 0.8527 @ 43 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:13:34.127\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [45/1000], Train Loss: 0.0020, Train Acc: 0.8412, Test Loss: 0.0020, Test Acc: 0.8412, Max Acc: 0.8527 @ 43 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:13:39.438\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [46/1000], Train Loss: 0.0022, Train Acc: 0.8259, Test Loss: 0.0022, Test Acc: 0.8259, Max Acc: 0.8527 @ 43 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:13:44.669\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [47/1000], Train Loss: 0.0020, Train Acc: 0.8392, Test Loss: 0.0020, Test Acc: 0.8392, Max Acc: 0.8527 @ 43 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:13:49.984\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [48/1000], Train Loss: 0.0024, Train Acc: 0.7998, Test Loss: 0.0024, Test Acc: 0.7998, Max Acc: 0.8527 @ 43 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:13:55.321\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [49/1000], Train Loss: 0.0020, Train Acc: 0.8412, Test Loss: 0.0020, Test Acc: 0.8412, Max Acc: 0.8527 @ 43 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:14:00.819\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [50/1000], Train Loss: 0.0019, Train Acc: 0.8546, Test Loss: 0.0019, Test Acc: 0.8546, Max Acc: 0.8546 @ 50 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:14:06.220\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [51/1000], Train Loss: 0.0022, Train Acc: 0.8425, Test Loss: 0.0022, Test Acc: 0.8425, Max Acc: 0.8546 @ 50 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:14:11.768\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [52/1000], Train Loss: 0.0020, Train Acc: 0.8401, Test Loss: 0.0020, Test Acc: 0.8401, Max Acc: 0.8546 @ 50 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:14:17.400\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [53/1000], Train Loss: 0.0020, Train Acc: 0.8414, Test Loss: 0.0020, Test Acc: 0.8414, Max Acc: 0.8546 @ 50 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:14:22.848\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [54/1000], Train Loss: 0.0019, Train Acc: 0.8476, Test Loss: 0.0019, Test Acc: 0.8476, Max Acc: 0.8546 @ 50 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:14:28.240\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [55/1000], Train Loss: 0.0020, Train Acc: 0.8134, Test Loss: 0.0020, Test Acc: 0.8134, Max Acc: 0.8546 @ 50 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:14:33.655\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [56/1000], Train Loss: 0.0019, Train Acc: 0.8546, Test Loss: 0.0019, Test Acc: 0.8546, Max Acc: 0.8546 @ 50 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:14:39.136\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [57/1000], Train Loss: 0.0018, Train Acc: 0.8724, Test Loss: 0.0018, Test Acc: 0.8724, Max Acc: 0.8724 @ 57 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:14:44.553\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [58/1000], Train Loss: 0.0017, Train Acc: 0.8892, Test Loss: 0.0017, Test Acc: 0.8892, Max Acc: 0.8892 @ 58 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:14:49.956\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [59/1000], Train Loss: 0.0019, Train Acc: 0.8573, Test Loss: 0.0019, Test Acc: 0.8573, Max Acc: 0.8892 @ 58 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:14:55.563\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [60/1000], Train Loss: 0.0019, Train Acc: 0.8661, Test Loss: 0.0019, Test Acc: 0.8661, Max Acc: 0.8892 @ 58 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:15:01.086\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [61/1000], Train Loss: 0.0021, Train Acc: 0.8353, Test Loss: 0.0021, Test Acc: 0.8353, Max Acc: 0.8892 @ 58 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:15:06.587\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [62/1000], Train Loss: 0.0021, Train Acc: 0.8239, Test Loss: 0.0021, Test Acc: 0.8239, Max Acc: 0.8892 @ 58 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:15:12.199\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [63/1000], Train Loss: 0.0018, Train Acc: 0.8619, Test Loss: 0.0018, Test Acc: 0.8619, Max Acc: 0.8892 @ 58 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:15:17.917\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [64/1000], Train Loss: 0.0016, Train Acc: 0.8917, Test Loss: 0.0016, Test Acc: 0.8917, Max Acc: 0.8917 @ 64 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:15:23.384\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [65/1000], Train Loss: 0.0016, Train Acc: 0.8962, Test Loss: 0.0016, Test Acc: 0.8962, Max Acc: 0.8962 @ 65 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:15:29.044\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [66/1000], Train Loss: 0.0017, Train Acc: 0.8800, Test Loss: 0.0017, Test Acc: 0.8800, Max Acc: 0.8962 @ 65 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:15:34.645\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [67/1000], Train Loss: 0.0018, Train Acc: 0.8766, Test Loss: 0.0018, Test Acc: 0.8766, Max Acc: 0.8962 @ 65 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:15:40.287\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [68/1000], Train Loss: 0.0018, Train Acc: 0.8638, Test Loss: 0.0018, Test Acc: 0.8638, Max Acc: 0.8962 @ 65 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:15:45.887\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [69/1000], Train Loss: 0.0015, Train Acc: 0.9033, Test Loss: 0.0015, Test Acc: 0.9033, Max Acc: 0.9033 @ 69 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:15:51.068\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [70/1000], Train Loss: 0.0017, Train Acc: 0.8813, Test Loss: 0.0017, Test Acc: 0.8813, Max Acc: 0.9033 @ 69 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:15:56.254\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [71/1000], Train Loss: 0.0017, Train Acc: 0.8802, Test Loss: 0.0017, Test Acc: 0.8802, Max Acc: 0.9033 @ 69 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:16:01.449\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [72/1000], Train Loss: 0.0021, Train Acc: 0.8681, Test Loss: 0.0021, Test Acc: 0.8681, Max Acc: 0.9033 @ 69 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:16:06.691\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [73/1000], Train Loss: 0.0014, Train Acc: 0.9089, Test Loss: 0.0014, Test Acc: 0.9089, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:16:11.899\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [74/1000], Train Loss: 0.0016, Train Acc: 0.8961, Test Loss: 0.0016, Test Acc: 0.8961, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:16:16.874\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [75/1000], Train Loss: 0.0014, Train Acc: 0.9053, Test Loss: 0.0014, Test Acc: 0.9053, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:16:22.247\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [76/1000], Train Loss: 0.1181, Train Acc: 0.5838, Test Loss: 0.1181, Test Acc: 0.5838, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:16:28.501\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [77/1000], Train Loss: 0.1166, Train Acc: 0.6260, Test Loss: 0.1166, Test Acc: 0.6260, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:16:36.802\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [78/1000], Train Loss: 0.1153, Train Acc: 0.6391, Test Loss: 0.1153, Test Acc: 0.6391, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:16:44.227\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [79/1000], Train Loss: 0.1128, Train Acc: 0.6403, Test Loss: 0.1128, Test Acc: 0.6403, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:16:49.977\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [80/1000], Train Loss: 0.1127, Train Acc: 0.6364, Test Loss: 0.1127, Test Acc: 0.6364, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:16:56.077\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [81/1000], Train Loss: 0.1123, Train Acc: 0.6532, Test Loss: 0.1123, Test Acc: 0.6532, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:17:01.359\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [82/1000], Train Loss: 0.1123, Train Acc: 0.6520, Test Loss: 0.1123, Test Acc: 0.6520, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:17:06.584\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [83/1000], Train Loss: 0.1123, Train Acc: 0.6481, Test Loss: 0.1123, Test Acc: 0.6481, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:17:12.030\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [84/1000], Train Loss: 0.1121, Train Acc: 0.6522, Test Loss: 0.1121, Test Acc: 0.6522, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:17:17.499\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [85/1000], Train Loss: 0.1124, Train Acc: 0.6366, Test Loss: 0.1124, Test Acc: 0.6366, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:17:22.694\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [86/1000], Train Loss: 0.1125, Train Acc: 0.6396, Test Loss: 0.1125, Test Acc: 0.6396, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:17:27.938\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [87/1000], Train Loss: 0.1125, Train Acc: 0.6324, Test Loss: 0.1125, Test Acc: 0.6324, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:17:33.395\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [88/1000], Train Loss: 0.1121, Train Acc: 0.6482, Test Loss: 0.1121, Test Acc: 0.6482, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:17:38.917\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [89/1000], Train Loss: 0.1122, Train Acc: 0.6399, Test Loss: 0.1122, Test Acc: 0.6399, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:17:44.168\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [90/1000], Train Loss: 0.1122, Train Acc: 0.6429, Test Loss: 0.1122, Test Acc: 0.6429, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:17:49.303\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [91/1000], Train Loss: 0.1121, Train Acc: 0.6466, Test Loss: 0.1121, Test Acc: 0.6466, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:17:54.427\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [92/1000], Train Loss: 0.1121, Train Acc: 0.6460, Test Loss: 0.1121, Test Acc: 0.6460, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:17:59.575\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [93/1000], Train Loss: 0.1130, Train Acc: 0.6142, Test Loss: 0.1130, Test Acc: 0.6142, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:18:04.809\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [94/1000], Train Loss: 0.1119, Train Acc: 0.6522, Test Loss: 0.1119, Test Acc: 0.6522, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:18:10.010\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [95/1000], Train Loss: 0.1119, Train Acc: 0.6519, Test Loss: 0.1119, Test Acc: 0.6519, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:18:15.217\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [96/1000], Train Loss: 0.1117, Train Acc: 0.6324, Test Loss: 0.1117, Test Acc: 0.6324, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:18:20.317\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [97/1000], Train Loss: 0.1119, Train Acc: 0.6506, Test Loss: 0.1119, Test Acc: 0.6506, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:18:25.436\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [98/1000], Train Loss: 0.1116, Train Acc: 0.6441, Test Loss: 0.1116, Test Acc: 0.6441, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:18:30.658\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [99/1000], Train Loss: 0.1111, Train Acc: 0.6498, Test Loss: 0.1111, Test Acc: 0.6498, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:18:35.833\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [100/1000], Train Loss: 0.1109, Train Acc: 0.6511, Test Loss: 0.1109, Test Acc: 0.6511, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:18:40.986\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [101/1000], Train Loss: 0.1101, Train Acc: 0.6542, Test Loss: 0.1101, Test Acc: 0.6542, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:18:46.050\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [102/1000], Train Loss: 0.1107, Train Acc: 0.6325, Test Loss: 0.1107, Test Acc: 0.6325, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:18:51.195\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [103/1000], Train Loss: 0.1014, Train Acc: 0.6533, Test Loss: 0.1014, Test Acc: 0.6533, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:18:56.339\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [104/1000], Train Loss: 0.1011, Train Acc: 0.6695, Test Loss: 0.1011, Test Acc: 0.6695, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:19:01.476\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [105/1000], Train Loss: 0.1013, Train Acc: 0.6578, Test Loss: 0.1013, Test Acc: 0.6578, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:19:06.542\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [106/1000], Train Loss: 0.1011, Train Acc: 0.6594, Test Loss: 0.1011, Test Acc: 0.6594, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:19:11.642\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [107/1000], Train Loss: 0.1010, Train Acc: 0.6732, Test Loss: 0.1010, Test Acc: 0.6732, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:19:16.666\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [108/1000], Train Loss: 0.0985, Train Acc: 0.6757, Test Loss: 0.0985, Test Acc: 0.6757, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:19:21.780\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [109/1000], Train Loss: 0.0901, Train Acc: 0.6758, Test Loss: 0.0901, Test Acc: 0.6758, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:19:26.901\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [110/1000], Train Loss: 0.0877, Train Acc: 0.6681, Test Loss: 0.0877, Test Acc: 0.6681, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:19:32.055\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [111/1000], Train Loss: 0.0906, Train Acc: 0.6653, Test Loss: 0.0906, Test Acc: 0.6653, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:19:37.286\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [112/1000], Train Loss: 0.0739, Train Acc: 0.6649, Test Loss: 0.0739, Test Acc: 0.6649, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:19:42.541\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [113/1000], Train Loss: 0.0659, Train Acc: 0.6746, Test Loss: 0.0659, Test Acc: 0.6746, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:19:48.068\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [114/1000], Train Loss: 0.0605, Train Acc: 0.6691, Test Loss: 0.0605, Test Acc: 0.6691, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:19:53.619\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [115/1000], Train Loss: 0.0474, Train Acc: 0.6426, Test Loss: 0.0474, Test Acc: 0.6426, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:19:59.066\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [116/1000], Train Loss: 0.0021, Train Acc: 0.8265, Test Loss: 0.0021, Test Acc: 0.8265, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:20:05.102\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [117/1000], Train Loss: 0.0019, Train Acc: 0.8495, Test Loss: 0.0019, Test Acc: 0.8495, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:20:10.968\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [118/1000], Train Loss: 0.0020, Train Acc: 0.8462, Test Loss: 0.0020, Test Acc: 0.8462, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:20:16.312\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [119/1000], Train Loss: 0.0018, Train Acc: 0.8652, Test Loss: 0.0018, Test Acc: 0.8652, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:20:21.796\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [120/1000], Train Loss: 0.0019, Train Acc: 0.8589, Test Loss: 0.0019, Test Acc: 0.8589, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:20:26.944\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [121/1000], Train Loss: 0.0019, Train Acc: 0.8413, Test Loss: 0.0019, Test Acc: 0.8413, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:20:32.101\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [122/1000], Train Loss: 0.0018, Train Acc: 0.8574, Test Loss: 0.0018, Test Acc: 0.8574, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:20:37.208\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [123/1000], Train Loss: 0.0018, Train Acc: 0.8496, Test Loss: 0.0018, Test Acc: 0.8496, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:20:42.025\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [124/1000], Train Loss: 0.0020, Train Acc: 0.8351, Test Loss: 0.0020, Test Acc: 0.8351, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:20:46.752\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [125/1000], Train Loss: 0.0018, Train Acc: 0.8548, Test Loss: 0.0018, Test Acc: 0.8548, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:20:51.462\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [126/1000], Train Loss: 0.0018, Train Acc: 0.8585, Test Loss: 0.0018, Test Acc: 0.8585, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:20:56.203\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [127/1000], Train Loss: 0.0018, Train Acc: 0.8494, Test Loss: 0.0018, Test Acc: 0.8494, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:21:01.216\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [128/1000], Train Loss: 0.0018, Train Acc: 0.8703, Test Loss: 0.0018, Test Acc: 0.8703, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:21:06.153\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [129/1000], Train Loss: 0.0018, Train Acc: 0.8710, Test Loss: 0.0018, Test Acc: 0.8710, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:21:11.220\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [130/1000], Train Loss: 0.0018, Train Acc: 0.8507, Test Loss: 0.0018, Test Acc: 0.8507, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:21:16.863\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [131/1000], Train Loss: 0.0016, Train Acc: 0.8902, Test Loss: 0.0016, Test Acc: 0.8902, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:21:22.176\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [132/1000], Train Loss: 0.0017, Train Acc: 0.8661, Test Loss: 0.0017, Test Acc: 0.8661, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:21:27.508\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [133/1000], Train Loss: 0.0015, Train Acc: 0.8949, Test Loss: 0.0015, Test Acc: 0.8949, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:21:33.056\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [134/1000], Train Loss: 0.0018, Train Acc: 0.8515, Test Loss: 0.0018, Test Acc: 0.8515, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:21:38.765\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [135/1000], Train Loss: 0.0015, Train Acc: 0.8999, Test Loss: 0.0015, Test Acc: 0.8999, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:21:44.441\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [136/1000], Train Loss: 0.0015, Train Acc: 0.8898, Test Loss: 0.0015, Test Acc: 0.8898, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:21:50.183\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [137/1000], Train Loss: 0.0017, Train Acc: 0.8782, Test Loss: 0.0017, Test Acc: 0.8782, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:21:55.399\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [138/1000], Train Loss: 0.0015, Train Acc: 0.9012, Test Loss: 0.0015, Test Acc: 0.9012, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:22:00.656\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [139/1000], Train Loss: 0.0015, Train Acc: 0.8869, Test Loss: 0.0015, Test Acc: 0.8869, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:22:05.844\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [140/1000], Train Loss: 0.0028, Train Acc: 0.7758, Test Loss: 0.0028, Test Acc: 0.7758, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:22:11.279\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [141/1000], Train Loss: 0.0016, Train Acc: 0.8998, Test Loss: 0.0016, Test Acc: 0.8998, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:22:16.533\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [142/1000], Train Loss: 0.0015, Train Acc: 0.8932, Test Loss: 0.0015, Test Acc: 0.8932, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:22:22.077\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [143/1000], Train Loss: 0.0017, Train Acc: 0.8662, Test Loss: 0.0017, Test Acc: 0.8662, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:22:27.427\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [144/1000], Train Loss: 0.0015, Train Acc: 0.8774, Test Loss: 0.0015, Test Acc: 0.8774, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:22:32.945\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [145/1000], Train Loss: 0.0017, Train Acc: 0.8699, Test Loss: 0.0017, Test Acc: 0.8699, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:22:38.405\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [146/1000], Train Loss: 0.0015, Train Acc: 0.9000, Test Loss: 0.0015, Test Acc: 0.9000, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:22:43.893\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [147/1000], Train Loss: 0.0015, Train Acc: 0.8934, Test Loss: 0.0015, Test Acc: 0.8934, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:22:49.369\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [148/1000], Train Loss: 0.0015, Train Acc: 0.8996, Test Loss: 0.0015, Test Acc: 0.8996, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:22:54.814\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [149/1000], Train Loss: 0.0015, Train Acc: 0.8921, Test Loss: 0.0015, Test Acc: 0.8921, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:23:00.368\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [150/1000], Train Loss: 0.0016, Train Acc: 0.8925, Test Loss: 0.0016, Test Acc: 0.8925, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:23:05.818\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [151/1000], Train Loss: 0.0013, Train Acc: 0.9089, Test Loss: 0.0013, Test Acc: 0.9089, Max Acc: 0.9089 @ 73 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:23:11.426\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [152/1000], Train Loss: 0.0014, Train Acc: 0.9096, Test Loss: 0.0014, Test Acc: 0.9096, Max Acc: 0.9096 @ 152 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:23:16.812\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [153/1000], Train Loss: 0.0013, Train Acc: 0.9172, Test Loss: 0.0013, Test Acc: 0.9172, Max Acc: 0.9172 @ 153 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:23:22.322\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [154/1000], Train Loss: 0.0028, Train Acc: 0.8340, Test Loss: 0.0028, Test Acc: 0.8340, Max Acc: 0.9172 @ 153 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:23:27.759\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [155/1000], Train Loss: 0.0012, Train Acc: 0.9226, Test Loss: 0.0012, Test Acc: 0.9226, Max Acc: 0.9226 @ 155 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:23:33.159\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [156/1000], Train Loss: 0.0012, Train Acc: 0.9228, Test Loss: 0.0012, Test Acc: 0.9228, Max Acc: 0.9228 @ 156 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:23:38.542\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [157/1000], Train Loss: 0.0012, Train Acc: 0.9187, Test Loss: 0.0012, Test Acc: 0.9187, Max Acc: 0.9228 @ 156 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:23:43.992\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [158/1000], Train Loss: 0.0010, Train Acc: 0.9325, Test Loss: 0.0010, Test Acc: 0.9325, Max Acc: 0.9325 @ 158 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:23:49.397\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [159/1000], Train Loss: 0.0012, Train Acc: 0.9311, Test Loss: 0.0012, Test Acc: 0.9311, Max Acc: 0.9325 @ 158 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:23:54.770\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [160/1000], Train Loss: 0.0010, Train Acc: 0.9399, Test Loss: 0.0010, Test Acc: 0.9399, Max Acc: 0.9399 @ 160 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:23:59.997\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [161/1000], Train Loss: 0.0012, Train Acc: 0.9184, Test Loss: 0.0012, Test Acc: 0.9184, Max Acc: 0.9399 @ 160 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:24:05.262\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [162/1000], Train Loss: 0.0010, Train Acc: 0.9372, Test Loss: 0.0010, Test Acc: 0.9372, Max Acc: 0.9399 @ 160 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:24:10.769\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [163/1000], Train Loss: 0.0012, Train Acc: 0.9204, Test Loss: 0.0012, Test Acc: 0.9204, Max Acc: 0.9399 @ 160 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:24:16.130\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [164/1000], Train Loss: 0.0009, Train Acc: 0.9425, Test Loss: 0.0009, Test Acc: 0.9425, Max Acc: 0.9425 @ 164 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:24:21.486\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [165/1000], Train Loss: 0.0009, Train Acc: 0.9458, Test Loss: 0.0009, Test Acc: 0.9458, Max Acc: 0.9458 @ 165 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:24:26.869\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [166/1000], Train Loss: 0.0008, Train Acc: 0.9490, Test Loss: 0.0008, Test Acc: 0.9490, Max Acc: 0.9490 @ 166 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:24:32.244\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [167/1000], Train Loss: 0.0012, Train Acc: 0.9238, Test Loss: 0.0012, Test Acc: 0.9238, Max Acc: 0.9490 @ 166 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:24:37.905\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [168/1000], Train Loss: 0.0008, Train Acc: 0.9436, Test Loss: 0.0008, Test Acc: 0.9436, Max Acc: 0.9490 @ 166 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:24:43.758\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [169/1000], Train Loss: 0.0012, Train Acc: 0.9207, Test Loss: 0.0012, Test Acc: 0.9207, Max Acc: 0.9490 @ 166 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:24:49.344\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [170/1000], Train Loss: 0.0008, Train Acc: 0.9602, Test Loss: 0.0008, Test Acc: 0.9602, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:24:54.865\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [171/1000], Train Loss: 0.0008, Train Acc: 0.9571, Test Loss: 0.0008, Test Acc: 0.9571, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:25:00.182\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [172/1000], Train Loss: 0.0008, Train Acc: 0.9602, Test Loss: 0.0008, Test Acc: 0.9602, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:25:05.510\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [173/1000], Train Loss: 0.0010, Train Acc: 0.9431, Test Loss: 0.0010, Test Acc: 0.9431, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:25:10.585\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [174/1000], Train Loss: 0.0018, Train Acc: 0.9061, Test Loss: 0.0018, Test Acc: 0.9061, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:25:15.398\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [175/1000], Train Loss: 0.0008, Train Acc: 0.9445, Test Loss: 0.0008, Test Acc: 0.9445, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:25:20.307\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [176/1000], Train Loss: 0.0008, Train Acc: 0.9549, Test Loss: 0.0008, Test Acc: 0.9549, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:25:25.756\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [177/1000], Train Loss: 0.0016, Train Acc: 0.9097, Test Loss: 0.0016, Test Acc: 0.9097, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:25:31.379\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [178/1000], Train Loss: 0.0007, Train Acc: 0.9522, Test Loss: 0.0007, Test Acc: 0.9522, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:25:36.739\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [179/1000], Train Loss: 0.0007, Train Acc: 0.9527, Test Loss: 0.0007, Test Acc: 0.9527, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:25:41.816\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [180/1000], Train Loss: 0.0010, Train Acc: 0.9505, Test Loss: 0.0010, Test Acc: 0.9505, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:25:46.954\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [181/1000], Train Loss: 0.0008, Train Acc: 0.9428, Test Loss: 0.0008, Test Acc: 0.9428, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:25:52.485\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [182/1000], Train Loss: 0.0132, Train Acc: 0.8442, Test Loss: 0.0132, Test Acc: 0.8442, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:25:57.782\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [183/1000], Train Loss: 0.0124, Train Acc: 0.8799, Test Loss: 0.0124, Test Acc: 0.8799, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:26:03.107\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [184/1000], Train Loss: 0.4497, Train Acc: 0.3498, Test Loss: 0.4497, Test Acc: 0.3498, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:26:08.432\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [185/1000], Train Loss: 0.4520, Train Acc: 0.3496, Test Loss: 0.4520, Test Acc: 0.3496, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:26:13.864\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [186/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:26:19.485\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [187/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:26:25.159\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [188/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:26:30.849\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [189/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:26:36.471\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [190/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:26:42.018\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [191/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:26:47.567\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [192/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:26:53.140\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [193/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:26:58.637\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [194/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:27:03.999\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [195/1000], Train Loss: 0.5934, Train Acc: 0.1462, Test Loss: 0.5934, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:27:09.550\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [196/1000], Train Loss: 0.5934, Train Acc: 0.1463, Test Loss: 0.5934, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:27:14.931\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [197/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:27:20.469\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [198/1000], Train Loss: 0.5934, Train Acc: 0.1463, Test Loss: 0.5934, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:27:25.936\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [199/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:27:31.321\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [200/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:27:36.817\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [201/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:27:42.346\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [202/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:27:47.633\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [203/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:27:52.868\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [204/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:27:58.162\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [205/1000], Train Loss: 0.5934, Train Acc: 0.1462, Test Loss: 0.5934, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:28:03.735\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [206/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:28:09.813\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [207/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:28:15.882\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [208/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:28:21.620\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [209/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:28:27.611\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [210/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:28:33.685\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [211/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:28:39.598\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [212/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:28:45.053\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [213/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:28:50.574\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [214/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:28:56.111\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [215/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:29:01.678\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [216/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:29:07.127\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [217/1000], Train Loss: 0.5931, Train Acc: 0.1464, Test Loss: 0.5931, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:29:12.514\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [218/1000], Train Loss: 0.5933, Train Acc: 0.1462, Test Loss: 0.5933, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:29:18.418\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [219/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:29:23.745\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [220/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:29:29.101\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [221/1000], Train Loss: 0.5933, Train Acc: 0.1462, Test Loss: 0.5933, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:29:34.690\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [222/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:29:40.126\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [223/1000], Train Loss: 0.5934, Train Acc: 0.1462, Test Loss: 0.5934, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:29:45.051\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [224/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:29:50.312\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [225/1000], Train Loss: 0.5931, Train Acc: 0.1464, Test Loss: 0.5931, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:29:55.359\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [226/1000], Train Loss: 0.5934, Train Acc: 0.1462, Test Loss: 0.5934, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:30:01.348\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [227/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:30:06.422\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [228/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:30:11.540\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [229/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:30:17.587\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [230/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:30:23.147\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [231/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:30:28.847\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [232/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:30:34.213\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [233/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:30:39.425\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [234/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:30:44.667\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [235/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:30:50.315\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [236/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:30:55.751\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [237/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:31:01.246\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [238/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:31:07.156\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [239/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:31:13.337\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [240/1000], Train Loss: 0.5934, Train Acc: 0.1463, Test Loss: 0.5934, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:31:18.777\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [241/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:31:23.969\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [242/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:31:29.199\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [243/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:31:34.518\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [244/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:31:40.078\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [245/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:31:45.548\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [246/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:31:50.824\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [247/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:31:56.156\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [248/1000], Train Loss: 0.5934, Train Acc: 0.1462, Test Loss: 0.5934, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:32:01.863\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [249/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:32:08.076\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [250/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:32:13.487\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [251/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:32:18.733\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [252/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:32:23.943\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [253/1000], Train Loss: 0.5934, Train Acc: 0.1462, Test Loss: 0.5934, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:32:29.129\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [254/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:32:34.321\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [255/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:32:39.613\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [256/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:32:44.830\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [257/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:32:50.092\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [258/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:32:55.339\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [259/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:33:00.629\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [260/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:33:05.979\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [261/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:33:11.237\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [262/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:33:16.443\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [263/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:33:21.688\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [264/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:33:26.907\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [265/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:33:32.143\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [266/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:33:37.354\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [267/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:33:42.606\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [268/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:33:47.780\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [269/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:33:53.035\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [270/1000], Train Loss: 0.5933, Train Acc: 0.1462, Test Loss: 0.5933, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:33:58.424\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [271/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:34:03.514\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [272/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:34:09.072\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [273/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:34:14.564\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [274/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:34:20.002\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [275/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:34:25.455\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [276/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:34:30.808\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [277/1000], Train Loss: 0.5934, Train Acc: 0.1462, Test Loss: 0.5934, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:34:35.890\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [278/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:34:41.206\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [279/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:34:46.295\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [280/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:34:51.488\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [281/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:34:56.609\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [282/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:35:01.767\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [283/1000], Train Loss: 0.5934, Train Acc: 0.1462, Test Loss: 0.5934, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:35:06.873\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [284/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:35:12.082\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [285/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:35:17.308\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [286/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:35:22.413\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [287/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:35:27.568\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [288/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:35:32.681\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [289/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:35:37.867\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [290/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:35:42.979\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [291/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:35:48.152\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [292/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:35:53.319\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [293/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:35:58.510\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [294/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:36:03.633\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [295/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:36:08.857\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [296/1000], Train Loss: 0.5934, Train Acc: 0.1462, Test Loss: 0.5934, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:36:14.103\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [297/1000], Train Loss: 0.5934, Train Acc: 0.1463, Test Loss: 0.5934, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:36:19.467\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [298/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:36:24.785\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [299/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:36:30.005\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [300/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:36:35.238\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [301/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:36:40.438\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [302/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:36:45.633\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [303/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:36:50.904\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [304/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:36:56.078\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [305/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:37:01.313\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [306/1000], Train Loss: 0.5934, Train Acc: 0.1462, Test Loss: 0.5934, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:37:06.485\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [307/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:37:11.761\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [308/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:37:16.936\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [309/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:37:22.214\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [310/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:37:27.381\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [311/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:37:32.644\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [312/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:37:37.838\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [313/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:37:43.143\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [314/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:37:48.351\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [315/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:37:53.584\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [316/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:37:58.752\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [317/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:38:04.161\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [318/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:38:09.354\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [319/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:38:14.601\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [320/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:38:19.635\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [321/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:38:25.089\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [322/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:38:30.597\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [323/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:38:36.101\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [324/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:38:41.564\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [325/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:38:46.967\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [326/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:38:52.165\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [327/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:38:57.425\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [328/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:39:02.540\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [329/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:39:07.818\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [330/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:39:13.054\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [331/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:39:18.287\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [332/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:39:23.498\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [333/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:39:28.710\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [334/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:39:33.943\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [335/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:39:39.262\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [336/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:39:44.426\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [337/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:39:49.627\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [338/1000], Train Loss: 0.5933, Train Acc: 0.1462, Test Loss: 0.5933, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:39:54.776\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [339/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:39:59.957\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [340/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:40:05.129\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [341/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:40:10.376\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [342/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:40:15.591\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [343/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:40:20.832\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [344/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:40:26.184\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [345/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:40:31.332\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [346/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:40:36.526\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [347/1000], Train Loss: 0.5934, Train Acc: 0.1462, Test Loss: 0.5934, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:40:41.693\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [348/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:40:46.904\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [349/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:40:52.056\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [350/1000], Train Loss: 0.5931, Train Acc: 0.1464, Test Loss: 0.5931, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:40:57.286\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [351/1000], Train Loss: 0.5934, Train Acc: 0.1462, Test Loss: 0.5934, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:41:02.494\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [352/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:41:07.700\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [353/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:41:12.912\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [354/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:41:18.135\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [355/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:41:23.307\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [356/1000], Train Loss: 0.5933, Train Acc: 0.1462, Test Loss: 0.5933, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:41:28.491\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [357/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:41:33.646\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [358/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:41:38.812\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [359/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:41:43.951\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [360/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:41:49.174\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [361/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:41:54.353\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [362/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:41:59.545\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [363/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:42:04.664\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [364/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:42:09.849\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [365/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:42:14.991\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [366/1000], Train Loss: 0.5931, Train Acc: 0.1464, Test Loss: 0.5931, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:42:20.196\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [367/1000], Train Loss: 0.5933, Train Acc: 0.1462, Test Loss: 0.5933, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:42:25.352\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [368/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:42:30.440\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [369/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:42:35.625\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [370/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:42:41.114\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [371/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:42:46.541\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [372/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:42:52.046\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [373/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:42:57.466\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [374/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:43:02.618\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [375/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:43:07.795\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [376/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:43:12.980\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [377/1000], Train Loss: 0.5934, Train Acc: 0.1463, Test Loss: 0.5934, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:43:18.120\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [378/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:43:23.244\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [379/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:43:28.372\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [380/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:43:33.546\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [381/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:43:38.698\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [382/1000], Train Loss: 0.5934, Train Acc: 0.1462, Test Loss: 0.5934, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:43:43.909\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [383/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:43:49.035\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [384/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:43:54.289\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [385/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:43:59.473\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [386/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:44:04.660\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [387/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:44:09.801\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [388/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:44:14.998\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [389/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:44:20.141\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [390/1000], Train Loss: 0.5934, Train Acc: 0.1462, Test Loss: 0.5934, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:44:25.343\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [391/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:44:30.506\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [392/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:44:35.710\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [393/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:44:40.850\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [394/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:44:46.095\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [395/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:44:51.246\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [396/1000], Train Loss: 0.5934, Train Acc: 0.1462, Test Loss: 0.5934, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:44:56.438\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [397/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:45:01.632\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [398/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:45:06.808\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [399/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:45:11.967\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [400/1000], Train Loss: 0.5934, Train Acc: 0.1462, Test Loss: 0.5934, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:45:17.165\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [401/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:45:22.327\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [402/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:45:27.710\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [403/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:45:32.869\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [404/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:45:38.059\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [405/1000], Train Loss: 0.5934, Train Acc: 0.1463, Test Loss: 0.5934, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:45:43.209\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [406/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:45:48.446\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [407/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:45:53.608\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [408/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:45:58.791\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [409/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:46:03.969\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [410/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:46:09.182\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [411/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:46:14.327\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [412/1000], Train Loss: 0.5934, Train Acc: 0.1462, Test Loss: 0.5934, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:46:19.517\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [413/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:46:24.675\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [414/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:46:29.842\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [415/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:46:35.016\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [416/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:46:40.235\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [417/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:46:45.277\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [418/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:46:50.755\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [419/1000], Train Loss: 0.5933, Train Acc: 0.1462, Test Loss: 0.5933, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:46:56.231\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [420/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:47:01.668\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [421/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:47:07.169\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [422/1000], Train Loss: 0.5933, Train Acc: 0.1462, Test Loss: 0.5933, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:47:12.495\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [423/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:47:17.607\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [424/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:47:22.833\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [425/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:47:27.924\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [426/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:47:33.071\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [427/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:47:38.302\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [428/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:47:43.503\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [429/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:47:48.685\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [430/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:47:53.911\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [431/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:47:59.087\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [432/1000], Train Loss: 0.5934, Train Acc: 0.1462, Test Loss: 0.5934, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:48:04.343\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [433/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:48:09.527\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [434/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:48:14.740\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [435/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:48:19.939\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [436/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:48:25.204\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [437/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:48:30.341\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [438/1000], Train Loss: 0.5934, Train Acc: 0.1462, Test Loss: 0.5934, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:48:35.600\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [439/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:48:40.766\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [440/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:48:46.018\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [441/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:48:51.182\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [442/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:48:56.509\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [443/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:49:01.740\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [444/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:49:06.885\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [445/1000], Train Loss: 0.5933, Train Acc: 0.1462, Test Loss: 0.5933, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:49:12.097\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [446/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:49:17.219\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [447/1000], Train Loss: 0.5933, Train Acc: 0.1462, Test Loss: 0.5933, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:49:22.379\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [448/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:49:27.537\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [449/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:49:32.734\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [450/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:49:37.923\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [451/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:49:43.119\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [452/1000], Train Loss: 0.5934, Train Acc: 0.1462, Test Loss: 0.5934, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:49:48.293\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [453/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:49:53.471\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [454/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:49:58.627\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [455/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:50:03.812\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [456/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:50:09.242\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [457/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:50:14.380\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [458/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:50:19.583\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [459/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:50:24.750\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [460/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:50:29.928\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [461/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:50:35.100\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [462/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:50:40.318\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [463/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:50:45.482\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [464/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:50:50.694\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [465/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:50:55.713\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [466/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:51:00.556\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [467/1000], Train Loss: 0.5933, Train Acc: 0.1462, Test Loss: 0.5933, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:51:05.959\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [468/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:51:11.364\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [469/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:51:16.798\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [470/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:51:22.215\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [471/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:51:27.609\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [472/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:51:32.760\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [473/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:51:37.879\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [474/1000], Train Loss: 0.5934, Train Acc: 0.1462, Test Loss: 0.5934, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:51:43.030\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [475/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:51:48.176\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [476/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:51:53.364\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [477/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:51:58.525\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [478/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:52:03.745\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [479/1000], Train Loss: 0.5933, Train Acc: 0.1462, Test Loss: 0.5933, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:52:08.890\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [480/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:52:14.111\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [481/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:52:19.341\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [482/1000], Train Loss: 0.5933, Train Acc: 0.1462, Test Loss: 0.5933, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:52:24.522\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [483/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:52:29.735\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [484/1000], Train Loss: 0.5933, Train Acc: 0.1462, Test Loss: 0.5933, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:52:34.926\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [485/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:52:40.159\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [486/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:52:45.323\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [487/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:52:50.526\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [488/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:52:55.683\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [489/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:53:00.907\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [490/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:53:06.103\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [491/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:53:11.344\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [492/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:53:16.475\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [493/1000], Train Loss: 0.5934, Train Acc: 0.1462, Test Loss: 0.5934, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:53:21.663\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [494/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:53:26.874\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [495/1000], Train Loss: 0.5933, Train Acc: 0.1462, Test Loss: 0.5933, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:53:32.044\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [496/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:53:37.304\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [497/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:53:42.460\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [498/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:53:47.729\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [499/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:53:52.895\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [500/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:53:58.115\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [501/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:54:03.270\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [502/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:54:08.482\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [503/1000], Train Loss: 0.5931, Train Acc: 0.1464, Test Loss: 0.5931, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:54:13.673\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [504/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:54:18.904\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [505/1000], Train Loss: 0.5933, Train Acc: 0.1462, Test Loss: 0.5933, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:54:24.065\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [506/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:54:29.246\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [507/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:54:34.411\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [508/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:54:39.612\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [509/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:54:44.795\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [510/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:54:49.985\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [511/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:54:55.183\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [512/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:55:00.386\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [513/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:55:05.513\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [514/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:55:10.755\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [515/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:55:16.205\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [516/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:55:21.671\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [517/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:55:27.110\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [518/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:55:32.550\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [519/1000], Train Loss: 0.5934, Train Acc: 0.1462, Test Loss: 0.5934, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:55:37.925\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [520/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:55:43.059\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [521/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:55:48.263\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [522/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:55:53.389\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [523/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:55:58.586\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [524/1000], Train Loss: 0.5933, Train Acc: 0.1462, Test Loss: 0.5933, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:56:03.801\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [525/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:56:09.032\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [526/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:56:14.235\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [527/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:56:19.459\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [528/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:56:24.638\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [529/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:56:29.827\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [530/1000], Train Loss: 0.5933, Train Acc: 0.1462, Test Loss: 0.5933, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:56:35.052\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [531/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:56:40.205\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [532/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:56:45.406\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [533/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:56:50.582\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [534/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:56:55.797\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [535/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:57:00.968\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [536/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:57:06.195\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [537/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:57:11.375\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [538/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:57:16.608\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [539/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:57:21.791\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [540/1000], Train Loss: 0.5934, Train Acc: 0.1462, Test Loss: 0.5934, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:57:27.016\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [541/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:57:32.193\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [542/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:57:37.402\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [543/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:57:42.578\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [544/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:57:47.779\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [545/1000], Train Loss: 0.5934, Train Acc: 0.1463, Test Loss: 0.5934, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:57:52.937\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [546/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:57:58.112\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [547/1000], Train Loss: 0.5934, Train Acc: 0.1462, Test Loss: 0.5934, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:58:03.264\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [548/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:58:08.453\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [549/1000], Train Loss: 0.5931, Train Acc: 0.1464, Test Loss: 0.5931, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:58:13.666\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [550/1000], Train Loss: 0.5934, Train Acc: 0.1462, Test Loss: 0.5934, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:58:18.885\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [551/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:58:24.037\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [552/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:58:29.243\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [553/1000], Train Loss: 0.5934, Train Acc: 0.1462, Test Loss: 0.5934, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:58:34.410\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [554/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:58:39.639\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [555/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:58:44.790\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [556/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:58:50.024\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [557/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:58:55.257\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [558/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:59:00.466\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [559/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:59:05.619\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [560/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:59:10.815\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [561/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:59:15.976\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [562/1000], Train Loss: 0.5934, Train Acc: 0.1462, Test Loss: 0.5934, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:59:21.218\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [563/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:59:26.194\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [564/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:59:31.649\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [565/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:59:37.059\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [566/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:59:42.523\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [567/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:59:47.947\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [568/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:59:53.114\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [569/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-18 23:59:58.228\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [570/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:00:03.424\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [571/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:00:08.533\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [572/1000], Train Loss: 0.5933, Train Acc: 0.1462, Test Loss: 0.5933, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:00:13.712\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [573/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:00:18.968\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [574/1000], Train Loss: 0.5933, Train Acc: 0.1462, Test Loss: 0.5933, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:00:24.102\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [575/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:00:29.315\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [576/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:00:34.521\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [577/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:00:39.665\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [578/1000], Train Loss: 0.5933, Train Acc: 0.1462, Test Loss: 0.5933, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:00:44.887\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [579/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:00:50.077\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [580/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:00:55.329\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [581/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:01:00.533\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [582/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:01:05.784\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [583/1000], Train Loss: 0.5934, Train Acc: 0.1462, Test Loss: 0.5934, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:01:10.936\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [584/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:01:16.179\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [585/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:01:21.555\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [586/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:01:26.810\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [587/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:01:31.997\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [588/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:01:37.198\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [589/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:01:42.384\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [590/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:01:47.648\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [591/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:01:52.792\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [592/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:01:58.060\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [593/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:02:03.249\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [594/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:02:08.473\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [595/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:02:13.660\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [596/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:02:18.878\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [597/1000], Train Loss: 0.5933, Train Acc: 0.1462, Test Loss: 0.5933, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:02:24.056\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [598/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:02:29.310\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [599/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:02:34.532\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [600/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:02:39.748\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [601/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:02:44.942\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [602/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:02:50.141\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [603/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:02:55.323\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [604/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:03:00.561\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [605/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:03:05.743\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [606/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:03:10.984\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [607/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:03:16.137\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [608/1000], Train Loss: 0.5934, Train Acc: 0.1463, Test Loss: 0.5934, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:03:21.364\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [609/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:03:26.544\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [610/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:03:31.784\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [611/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:03:36.819\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [612/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:03:42.342\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [613/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:03:47.841\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [614/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:03:53.395\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [615/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:03:58.807\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [616/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:04:03.928\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [617/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:04:09.132\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [618/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:04:14.308\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [619/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:04:19.493\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [620/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:04:24.677\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [621/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:04:29.907\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [622/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:04:35.133\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [623/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:04:40.396\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [624/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:04:45.636\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [625/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:04:50.825\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [626/1000], Train Loss: 0.5934, Train Acc: 0.1462, Test Loss: 0.5934, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:04:56.075\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [627/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:05:01.286\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [628/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:05:06.513\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [629/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:05:11.779\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [630/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:05:16.967\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [631/1000], Train Loss: 0.5931, Train Acc: 0.1464, Test Loss: 0.5931, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:05:22.191\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [632/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:05:27.382\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [633/1000], Train Loss: 0.5933, Train Acc: 0.1462, Test Loss: 0.5933, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:05:32.629\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [634/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:05:37.804\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [635/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:05:43.039\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [636/1000], Train Loss: 0.5933, Train Acc: 0.1462, Test Loss: 0.5933, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:05:48.212\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [637/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:05:53.423\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [638/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:05:58.585\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [639/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:06:03.995\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [640/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:06:09.205\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [641/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:06:14.439\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [642/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:06:19.646\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [643/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:06:24.884\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [644/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:06:30.300\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [645/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:06:35.572\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [646/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:06:40.779\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [647/1000], Train Loss: 0.5934, Train Acc: 0.1462, Test Loss: 0.5934, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:06:46.013\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [648/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:06:51.261\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [649/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:06:56.526\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [650/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:07:01.712\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [651/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:07:06.951\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [652/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:07:12.133\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [653/1000], Train Loss: 0.5933, Train Acc: 0.1462, Test Loss: 0.5933, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:07:17.374\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [654/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:07:22.582\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [655/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:07:27.780\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [656/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:07:32.978\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [657/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:07:38.214\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [658/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:07:43.259\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [659/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:07:48.673\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [660/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:07:54.222\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [661/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:07:59.670\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [662/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:08:05.200\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [663/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:08:10.370\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [664/1000], Train Loss: 0.5933, Train Acc: 0.1462, Test Loss: 0.5933, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:08:15.567\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [665/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:08:20.720\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [666/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:08:25.891\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [667/1000], Train Loss: 0.5934, Train Acc: 0.1463, Test Loss: 0.5934, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:08:30.993\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [668/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:08:36.283\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [669/1000], Train Loss: 0.5934, Train Acc: 0.1462, Test Loss: 0.5934, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:08:41.484\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [670/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:08:46.742\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [671/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:08:52.001\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [672/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:08:57.300\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [673/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:09:02.524\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [674/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:09:07.719\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [675/1000], Train Loss: 0.5933, Train Acc: 0.1464, Test Loss: 0.5933, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:09:12.946\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [676/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:09:18.114\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [677/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:09:23.313\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [678/1000], Train Loss: 0.5934, Train Acc: 0.1462, Test Loss: 0.5934, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:09:28.482\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [679/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:09:33.695\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [680/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:09:38.903\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [681/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:09:44.133\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [682/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:09:49.303\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [683/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:09:54.534\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [684/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:09:59.708\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [685/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:10:04.927\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [686/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:10:10.228\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [687/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:10:15.470\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [688/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:10:20.896\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [689/1000], Train Loss: 0.5933, Train Acc: 0.1462, Test Loss: 0.5933, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:10:26.103\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [690/1000], Train Loss: 0.5931, Train Acc: 0.1464, Test Loss: 0.5931, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:10:31.351\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [691/1000], Train Loss: 0.5934, Train Acc: 0.1462, Test Loss: 0.5934, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:10:36.559\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [692/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:10:41.863\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [693/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:10:47.075\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [694/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:10:52.295\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [695/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:10:57.531\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [696/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:11:02.745\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [697/1000], Train Loss: 0.5933, Train Acc: 0.1462, Test Loss: 0.5933, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:11:07.941\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [698/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:11:13.226\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [699/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:11:18.508\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [700/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:11:23.724\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [701/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:11:28.895\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [702/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:11:34.088\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [703/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:11:39.286\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [704/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:11:44.517\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [705/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:11:49.805\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [706/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:11:54.563\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [707/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:11:59.996\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [708/1000], Train Loss: 0.5933, Train Acc: 0.1462, Test Loss: 0.5933, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:12:05.458\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [709/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:12:10.927\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [710/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:12:16.238\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [711/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:12:21.410\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [712/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:12:26.561\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [713/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:12:31.786\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [714/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:12:36.965\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [715/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:12:42.121\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [716/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:12:47.330\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [717/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:12:52.526\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [718/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:12:57.750\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [719/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:13:02.956\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [720/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:13:08.156\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [721/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:13:13.403\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [722/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:13:18.550\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [723/1000], Train Loss: 0.5934, Train Acc: 0.1462, Test Loss: 0.5934, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:13:23.732\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [724/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:13:28.913\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [725/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:13:34.162\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [726/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:13:39.354\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [727/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:13:44.528\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [728/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:13:49.761\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [729/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:13:54.997\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [730/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:14:00.222\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [731/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:14:05.399\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [732/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:14:10.657\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [733/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:14:15.846\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [734/1000], Train Loss: 0.5934, Train Acc: 0.1462, Test Loss: 0.5934, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:14:21.050\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [735/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:14:26.262\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [736/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:14:31.424\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [737/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:14:36.584\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [738/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:14:41.789\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [739/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:14:47.004\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [740/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:14:52.197\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [741/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:14:57.390\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [742/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:15:02.564\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [743/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:15:07.779\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [744/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:15:13.039\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [745/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:15:18.243\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [746/1000], Train Loss: 0.5933, Train Acc: 0.1464, Test Loss: 0.5933, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:15:23.451\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [747/1000], Train Loss: 0.5933, Train Acc: 0.1462, Test Loss: 0.5933, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:15:28.631\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [748/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:15:33.849\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [749/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:15:39.036\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [750/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:15:44.248\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [751/1000], Train Loss: 0.5933, Train Acc: 0.1462, Test Loss: 0.5933, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:15:49.438\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [752/1000], Train Loss: 0.5934, Train Acc: 0.1463, Test Loss: 0.5934, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:15:54.827\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [753/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:15:59.846\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [754/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:16:05.127\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [755/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:16:10.579\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [756/1000], Train Loss: 0.5934, Train Acc: 0.1462, Test Loss: 0.5934, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:16:16.014\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [757/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:16:21.467\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [758/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:16:26.718\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [759/1000], Train Loss: 0.5933, Train Acc: 0.1464, Test Loss: 0.5933, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:16:31.882\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [760/1000], Train Loss: 0.5934, Train Acc: 0.1462, Test Loss: 0.5934, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:16:37.048\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [761/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:16:42.233\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [762/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:16:47.402\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [763/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:16:52.522\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [764/1000], Train Loss: 0.5933, Train Acc: 0.1462, Test Loss: 0.5933, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:16:57.712\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [765/1000], Train Loss: 0.5933, Train Acc: 0.1464, Test Loss: 0.5933, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:17:02.923\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [766/1000], Train Loss: 0.5934, Train Acc: 0.1462, Test Loss: 0.5934, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:17:08.094\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [767/1000], Train Loss: 0.5931, Train Acc: 0.1464, Test Loss: 0.5931, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:17:13.346\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [768/1000], Train Loss: 0.5933, Train Acc: 0.1462, Test Loss: 0.5933, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:17:18.527\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [769/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:17:23.739\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [770/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:17:28.901\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [771/1000], Train Loss: 0.5931, Train Acc: 0.1464, Test Loss: 0.5931, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:17:34.108\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [772/1000], Train Loss: 0.5934, Train Acc: 0.1462, Test Loss: 0.5934, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:17:39.299\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [773/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:17:44.517\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [774/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:17:49.689\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [775/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:17:54.917\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [776/1000], Train Loss: 0.5931, Train Acc: 0.1464, Test Loss: 0.5931, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:18:00.128\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [777/1000], Train Loss: 0.5933, Train Acc: 0.1462, Test Loss: 0.5933, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:18:05.354\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [778/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:18:10.547\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [779/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:18:15.766\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [780/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:18:20.945\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [781/1000], Train Loss: 0.5933, Train Acc: 0.1462, Test Loss: 0.5933, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:18:26.131\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [782/1000], Train Loss: 0.5931, Train Acc: 0.1464, Test Loss: 0.5931, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:18:31.313\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [783/1000], Train Loss: 0.5933, Train Acc: 0.1462, Test Loss: 0.5933, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:18:36.554\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [784/1000], Train Loss: 0.5931, Train Acc: 0.1464, Test Loss: 0.5931, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:18:41.791\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [785/1000], Train Loss: 0.5934, Train Acc: 0.1462, Test Loss: 0.5934, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:18:46.985\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [786/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:18:52.161\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [787/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:18:57.497\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [788/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:19:02.640\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [789/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:19:07.853\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [790/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:19:13.097\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [791/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:19:18.323\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [792/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:19:23.504\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [793/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:19:28.731\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [794/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:19:33.893\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [795/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:19:39.102\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [796/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:19:44.427\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [797/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:19:49.714\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [798/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:19:54.976\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [799/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:20:00.222\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [800/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:20:05.448\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [801/1000], Train Loss: 0.5933, Train Acc: 0.1462, Test Loss: 0.5933, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:20:10.567\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [802/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:20:15.949\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [803/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:20:21.441\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [804/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:20:26.940\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [805/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:20:32.495\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [806/1000], Train Loss: 0.5934, Train Acc: 0.1462, Test Loss: 0.5934, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:20:37.587\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [807/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:20:42.723\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [808/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:20:47.823\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [809/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:20:53.008\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [810/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:20:58.123\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [811/1000], Train Loss: 0.5934, Train Acc: 0.1462, Test Loss: 0.5934, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:21:03.551\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [812/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:21:08.800\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [813/1000], Train Loss: 0.5934, Train Acc: 0.1462, Test Loss: 0.5934, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:21:13.964\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [814/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:21:19.165\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [815/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:21:24.326\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [816/1000], Train Loss: 0.5934, Train Acc: 0.1462, Test Loss: 0.5934, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:21:29.565\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [817/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:21:34.921\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [818/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:21:40.152\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [819/1000], Train Loss: 0.5934, Train Acc: 0.1462, Test Loss: 0.5934, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:21:45.350\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [820/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:21:50.530\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [821/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:21:55.734\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [822/1000], Train Loss: 0.5933, Train Acc: 0.1462, Test Loss: 0.5933, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:22:00.881\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [823/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:22:06.099\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [824/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:22:11.333\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [825/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:22:16.490\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [826/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:22:21.711\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [827/1000], Train Loss: 0.5933, Train Acc: 0.1464, Test Loss: 0.5933, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:22:26.862\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [828/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:22:32.056\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [829/1000], Train Loss: 0.5933, Train Acc: 0.1462, Test Loss: 0.5933, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:22:37.262\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [830/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:22:42.479\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [831/1000], Train Loss: 0.5933, Train Acc: 0.1462, Test Loss: 0.5933, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:22:47.613\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [832/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:22:52.806\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [833/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:22:57.983\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [834/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:23:03.102\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [835/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:23:08.283\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [836/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:23:13.471\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [837/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:23:18.689\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [838/1000], Train Loss: 0.5931, Train Acc: 0.1464, Test Loss: 0.5931, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:23:23.811\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [839/1000], Train Loss: 0.5933, Train Acc: 0.1462, Test Loss: 0.5933, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:23:28.988\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [840/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:23:34.139\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [841/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:23:39.322\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [842/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:23:44.493\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [843/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:23:49.710\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [844/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:23:54.909\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [845/1000], Train Loss: 0.5933, Train Acc: 0.1462, Test Loss: 0.5933, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:24:00.134\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [846/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:24:05.274\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [847/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:24:10.452\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [848/1000], Train Loss: 0.5934, Train Acc: 0.1463, Test Loss: 0.5934, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:24:15.610\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [849/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:24:20.656\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [850/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:24:26.151\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [851/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:24:31.656\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [852/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:24:37.077\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [853/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:24:42.473\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [854/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:24:47.578\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [855/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:24:52.692\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [856/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:24:57.776\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [857/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:25:02.922\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [858/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:25:08.010\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [859/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:25:13.287\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [860/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:25:18.429\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [861/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:25:23.607\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [862/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:25:28.754\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [863/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:25:33.956\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [864/1000], Train Loss: 0.5933, Train Acc: 0.1462, Test Loss: 0.5933, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:25:39.151\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [865/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:25:44.301\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [866/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:25:49.529\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [867/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:25:54.757\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [868/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:25:59.968\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [869/1000], Train Loss: 0.5934, Train Acc: 0.1462, Test Loss: 0.5934, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:26:05.172\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [870/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:26:10.360\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [871/1000], Train Loss: 0.5933, Train Acc: 0.1462, Test Loss: 0.5933, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:26:15.559\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [872/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:26:20.771\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [873/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:26:26.140\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [874/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:26:31.411\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [875/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:26:36.597\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [876/1000], Train Loss: 0.5934, Train Acc: 0.1462, Test Loss: 0.5934, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:26:41.743\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [877/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:26:47.008\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [878/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:26:52.220\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [879/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:26:57.447\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [880/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:27:02.633\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [881/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:27:07.856\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [882/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:27:13.018\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [883/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:27:18.236\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [884/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:27:23.424\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [885/1000], Train Loss: 0.5934, Train Acc: 0.1462, Test Loss: 0.5934, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:27:28.640\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [886/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:27:33.846\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [887/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:27:39.037\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [888/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:27:44.181\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [889/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:27:49.398\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [890/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:27:54.577\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [891/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:27:59.859\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [892/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:28:05.048\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [893/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:28:10.283\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [894/1000], Train Loss: 0.5934, Train Acc: 0.1462, Test Loss: 0.5934, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:28:15.445\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [895/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:28:20.629\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [896/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:28:25.824\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [897/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:28:30.812\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [898/1000], Train Loss: 0.5933, Train Acc: 0.1462, Test Loss: 0.5933, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:28:36.161\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [899/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:28:41.651\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [900/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:28:47.091\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [901/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:28:52.520\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [902/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:28:57.752\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [903/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:29:02.941\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [904/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:29:08.129\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [905/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:29:13.267\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [906/1000], Train Loss: 0.5934, Train Acc: 0.1463, Test Loss: 0.5934, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:29:18.461\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [907/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:29:23.717\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [908/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:29:28.957\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [909/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:29:34.088\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [910/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:29:39.281\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [911/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:29:44.424\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [912/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:29:49.616\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [913/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:29:54.831\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [914/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:30:00.016\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [915/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:30:05.211\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [916/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:30:10.393\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [917/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:30:15.606\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [918/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:30:20.846\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [919/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:30:26.005\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [920/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:30:31.261\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [921/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:30:36.485\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [922/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:30:41.684\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [923/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:30:46.839\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [924/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:30:52.060\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [925/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:30:57.184\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [926/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:31:02.410\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [927/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:31:07.527\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [928/1000], Train Loss: 0.5933, Train Acc: 0.1462, Test Loss: 0.5933, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:31:12.733\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [929/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:31:17.928\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [930/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:31:23.289\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [931/1000], Train Loss: 0.5934, Train Acc: 0.1462, Test Loss: 0.5934, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:31:28.425\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [932/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:31:33.621\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [933/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:31:38.776\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [934/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:31:43.955\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [935/1000], Train Loss: 0.5933, Train Acc: 0.1462, Test Loss: 0.5933, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:31:49.121\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [936/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:31:54.331\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [937/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:31:59.459\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [938/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:32:04.674\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [939/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:32:09.860\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [940/1000], Train Loss: 0.5934, Train Acc: 0.1462, Test Loss: 0.5934, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:32:15.127\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [941/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:32:20.295\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [942/1000], Train Loss: 0.5934, Train Acc: 0.1462, Test Loss: 0.5934, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:32:25.475\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [943/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:32:30.617\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [944/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:32:35.847\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [945/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:32:40.872\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [946/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:32:46.280\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [947/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:32:51.726\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [948/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:32:57.205\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [949/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:33:02.571\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [950/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:33:07.736\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [951/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:33:12.883\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [952/1000], Train Loss: 0.5933, Train Acc: 0.1462, Test Loss: 0.5933, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:33:17.985\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [953/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:33:23.119\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [954/1000], Train Loss: 0.5931, Train Acc: 0.1464, Test Loss: 0.5931, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:33:28.238\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [955/1000], Train Loss: 0.5934, Train Acc: 0.1462, Test Loss: 0.5934, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:33:33.416\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [956/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:33:38.628\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [957/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:33:43.783\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [958/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:33:48.987\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [959/1000], Train Loss: 0.5933, Train Acc: 0.1462, Test Loss: 0.5933, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:33:54.354\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [960/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:33:59.564\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [961/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:34:04.688\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [962/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:34:09.870\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [963/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:34:15.025\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [964/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:34:20.194\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [965/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:34:25.349\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [966/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:34:30.547\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [967/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:34:35.690\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [968/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:34:40.874\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [969/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:34:46.020\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [970/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:34:51.207\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [971/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:34:56.344\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [972/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:35:01.497\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [973/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:35:06.619\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [974/1000], Train Loss: 0.5934, Train Acc: 0.1462, Test Loss: 0.5934, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:35:12.027\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [975/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:35:17.237\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [976/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:35:22.420\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [977/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:35:27.547\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [978/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:35:32.721\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [979/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:35:37.878\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [980/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:35:43.066\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [981/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:35:48.202\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [982/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:35:53.352\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [983/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:35:58.491\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [984/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:36:03.685\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [985/1000], Train Loss: 0.5934, Train Acc: 0.1463, Test Loss: 0.5934, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:36:08.852\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [986/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:36:14.068\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [987/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:36:19.177\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [988/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:36:24.331\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [989/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:36:29.430\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [990/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:36:34.618\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [991/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:36:39.912\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [992/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:36:45.213\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [993/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:36:50.184\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [994/1000], Train Loss: 0.5933, Train Acc: 0.1462, Test Loss: 0.5933, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:36:55.596\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [995/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:37:00.971\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [996/1000], Train Loss: 0.5932, Train Acc: 0.1463, Test Loss: 0.5932, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:37:06.367\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [997/1000], Train Loss: 0.5933, Train Acc: 0.1463, Test Loss: 0.5933, Test Acc: 0.1463, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:37:11.701\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [998/1000], Train Loss: 0.5932, Train Acc: 0.1464, Test Loss: 0.5932, Test Acc: 0.1464, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n",
      "\u001b[32m2025-05-19 00:37:16.790\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mEpoch [999/1000], Train Loss: 0.5933, Train Acc: 0.1462, Test Loss: 0.5933, Test Acc: 0.1462, Max Acc: 0.9602 @ 170 epoch\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# --- Define the DNN model ---\n",
    "class DNP3DNN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(DNP3DNN, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 90),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(90, 90),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(90, 90),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(90, 90),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(90, 90),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(90, 90),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(90, 90),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(90, 90),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(90, 90),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(90, output_dim),\n",
    "            nn.Softmax(dim=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "max_data = -100\n",
    "train_dataset = CustomDataset(df, split=\"train\", max_data=max_data)\n",
    "test_dataset = CustomDataset(df, split=\"test\", max_data=max_data)\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "input_dim = train_dataset.features.shape[1]\n",
    "output_dim = train_dataset.labels.shape[1]\n",
    "model = DNP3DNN(input_dim, output_dim)\n",
    "model.to(device)\n",
    "\n",
    "# --- Training setup ---\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "num_epochs = 1000\n",
    "log_every = 1\n",
    "# --- Training loop ---\n",
    "train_losses = []\n",
    "train_accs = []\n",
    "\n",
    "test_losses = []\n",
    "test_accs = []\n",
    "max_acc = 0.0\n",
    "max_epoch = 0\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    acc = 0.0\n",
    "    for features, labels in train_loader:\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(features)\n",
    "\n",
    "        acc += (\n",
    "            (torch.argmax(outputs, dim=1) == torch.argmax(labels, dim=1)).float().sum()\n",
    "        )\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    loss = running_loss / len(train_loader.dataset)\n",
    "    acc /= len(train_loader.dataset)\n",
    "    train_losses.append(loss)\n",
    "    train_accs.append(acc)\n",
    "\n",
    "    # --- Evaluation ---\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    acc = 0.0\n",
    "    with torch.no_grad():\n",
    "        for features, labels in test_loader:\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            outputs = model(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "            acc += (\n",
    "                (torch.argmax(outputs, dim=1) == torch.argmax(labels, dim=1))\n",
    "                .float()\n",
    "                .sum()\n",
    "            )\n",
    "    loss = running_loss / len(test_loader.dataset)\n",
    "    acc /= len(test_loader.dataset)\n",
    "    if acc > max_acc:\n",
    "        max_acc = acc\n",
    "        max_epoch = epoch\n",
    "        torch.save(model.state_dict(), \"dnp3_dnn_best_model.pth\")\n",
    "    test_losses.append(loss)\n",
    "    test_accs.append(acc)\n",
    "    if epoch % log_every == 0:\n",
    "        logger.info(\n",
    "            f\"Epoch [{epoch}/{num_epochs}], \"\n",
    "            f\"Train Loss: {loss:.4f}, Train Acc: {acc:.4f}, \"\n",
    "            f\"Test Loss: {loss:.4f}, Test Acc: {acc:.4f}, \"\n",
    "            f\"Max Acc: {max_acc:.4f} @ {max_epoch} epoch\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-19 08:11:36.547\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mTest Accuracy: 0.9602\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score (macro): 0.9128811147313686\n",
      "F1 Score (weighted): 0.9602131655810506\n"
     ]
    }
   ],
   "source": [
    "# F1 score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "best_model = DNP3DNN(input_dim, output_dim)\n",
    "best_model.load_state_dict(torch.load(\"dnp3_dnn_best_model.pth\", map_location=device))\n",
    "\n",
    "f1 = 0.0\n",
    "acc = 0.0\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for features, labels in test_loader:\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        outputs = best_model.to(device)(features)\n",
    "        acc += (\n",
    "            (torch.argmax(outputs, dim=1) == torch.argmax(labels, dim=1)).float().sum()\n",
    "        )\n",
    "\n",
    "        y_true.extend(torch.argmax(labels, dim=1).cpu().numpy().tolist())\n",
    "        y_pred.extend(torch.argmax(outputs, dim=1).cpu().numpy().tolist())\n",
    "\n",
    "    acc /= len(test_loader.dataset)\n",
    "    f1_macro = f1_score(y_true, y_pred, average=\"macro\")\n",
    "    f1_weighted = f1_score(y_true, y_pred, average=\"weighted\")\n",
    "\n",
    "    print(\"F1 Score (macro):\", f1_macro)\n",
    "    print(\"F1 Score (weighted):\", f1_weighted)\n",
    "    logger.info(f\"Test Accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score (macro): 0.912880719107735\n",
      "F1 Score (weighted): 0.9602131603368186\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
